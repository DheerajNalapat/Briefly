2025-08-22 09:43:08,647 - __main__ - INFO - Briefly Bot logging initialized
2025-08-22 09:43:08,647 - __main__ - INFO - üöÄ Briefly Bot - AI/ML News Aggregator
2025-08-22 09:43:08,647 - __main__ - INFO - ==================================================
2025-08-22 09:43:08,647 - __main__ - INFO - üìÖ Started at: 2025-08-22 09:43:08
2025-08-22 09:43:08,647 - __main__ - INFO - üîß Dry run: No
2025-08-22 09:43:08,647 - __main__ - INFO - üìä Max articles: 8
2025-08-22 09:43:08,647 - __main__ - INFO - üß† LLM Provider: openai
2025-08-22 09:43:08,647 - __main__ - INFO - üì∫ Target channel: C09AUAZCQR1
2025-08-22 09:43:08,647 - __main__ - INFO - ==================================================
2025-08-22 09:43:08,647 - __main__ - INFO - üöÄ Starting Briefly Bot...
2025-08-22 09:43:08,647 - __main__ - INFO - ============================================================
2025-08-22 09:43:08,647 - __main__ - INFO - üîß Initializing components...
2025-08-22 09:43:08,647 - slackbot.collectors.base_collector - INFO - Initialized collector: API News Collector
2025-08-22 09:43:08,653 - slackbot.collectors.api_collector - INFO - Loaded 8 sources from /home/dheeraj/projects/NewsFinderBot/slackbot/collectors/sources/api_sources_config.yaml
2025-08-22 09:43:08,653 - slackbot.collectors.api_collector - INFO - NewsAPI client initialized successfully
2025-08-22 09:43:08,653 - slackbot.collectors.api_collector - INFO - ArXiv client available
2025-08-22 09:43:09,766 - slackbot.summarizer.tldr_summarizer - INFO - Initialized OpenAI TLDR summarizer with model: gpt-3.5-turbo
2025-08-22 09:43:09,821 - slackbot.summarizer.tldr_summarizer - INFO - Initialized Gemini fallback with model: gemini-1.5-flash
2025-08-22 09:43:09,913 - slack_bolt.App - DEBUG - Sending a request - url: https://slack.com/api/auth.test, query_params: {}, body_params: {}, files: {}, json_body: None, headers: {'Content-Type': 'application/x-www-form-urlencoded', 'Authorization': '(redacted)', 'User-Agent': 'Bolt/1.23.0 Python/3.11.13 slackclient/3.36.0 Linux/6.8.0-65-generic'}
2025-08-22 09:43:10,388 - slack_bolt.App - DEBUG - Received the following response - status: 200, headers: {'date': 'Fri, 22 Aug 2025 04:13:10 GMT', 'server': 'Apache', 'vary': 'Accept-Encoding', 'x-slack-req-id': 'df31514d1b0f686b4131536192645806', 'x-content-type-options': 'nosniff', 'x-xss-protection': '0', 'pragma': 'no-cache', 'cache-control': 'private, no-cache, no-store, must-revalidate', 'expires': 'Sat, 26 Jul 1997 05:00:00 GMT', 'content-type': 'application/json; charset=utf-8', 'x-oauth-scopes': 'chat:write,files:write', 'access-control-expose-headers': 'x-slack-req-id, retry-after', 'access-control-allow-headers': 'slack-route, x-slack-version-ts, x-b3-traceid, x-b3-spanid, x-b3-parentspanid, x-b3-sampled, x-b3-flags', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'referrer-policy': 'no-referrer', 'x-slack-unique-id': 'aKfuVjP45Atrf1B5KVlTqAAAEDg', 'x-slack-backend': 'r', 'access-control-allow-origin': '*', 'content-length': '208', 'via': '1.1 slack-prod.tinyspeck.com, envoy-www-iad-sbodxmsw,envoy-edge-bom-qcuehsyv', 'x-envoy-attempt-count': '1', 'x-envoy-upstream-service-time': '251', 'x-backend': 'main_normal main_canary_with_overflow main_control_with_overflow', 'x-server': 'slack-www-hhvm-main-iad-shcz', 'x-slack-shared-secret-outcome': 'no-match', 'x-edge-backend': 'envoy-www', 'timing-allow-origin': '*', 'x-slack-edge-shared-secret-outcome': 'no-match', 'connection': 'close'}, body: {"ok":true,"url":"https:\/\/keyvaluesystems.slack.com\/","team":"KeyValue Software Systems","user":"briefly","team_id":"T4LJBDMDY","user_id":"U09BG266092","bot_id":"B09BG26606Q","is_enterprise_install":false}
2025-08-22 09:43:10,388 - slackbot.slack.publisher - INFO - Slack publisher initialized successfully
2025-08-22 09:43:10,388 - __main__ - INFO - ‚úÖ All components initialized successfully
2025-08-22 09:43:10,388 - __main__ - INFO - 
üì∞ Step 2: Collecting News
2025-08-22 09:43:10,388 - __main__ - INFO - ----------------------------------------
2025-08-22 09:43:10,388 - __main__ - INFO - üîç Starting news collection...
2025-08-22 09:43:13,305 - slackbot.collectors.api_collector - INFO - Fetched 20 papers from ArXiv AI Papers
2025-08-22 09:43:14,693 - slackbot.collectors.api_collector - INFO - Fetched 5 papers from ArXiv Computer Vision
2025-08-22 09:43:15,557 - slackbot.collectors.api_collector - INFO - Fetched 2 papers from ArXiv NLP Papers
2025-08-22 09:43:28,737 - slackbot.collectors.api_collector - ERROR - Error fetching from ArXiv ArXiv Robotics: Page of results was unexpectedly empty (https://export.arxiv.org/api/query?search_query=robotics+OR+autonomous+systems+OR+robot+learning&id_list=&sortBy=submittedDate&sortOrder=descending&start=1&max_results=100)
2025-08-22 09:43:28,738 - slackbot.collectors.api_collector - INFO - NewsAPI params for Tech News AI: {'q': 'AI', 'category': 'technology', 'language': 'en', 'country': 'us', 'page_size': 15}
2025-08-22 09:43:30,096 - slackbot.collectors.api_collector - INFO - NewsAPI response for Tech News AI: status=ok, totalResults=2, articles=1
2025-08-22 09:43:30,096 - slackbot.collectors.api_collector - INFO - Fetched 1 articles from Tech News AI
2025-08-22 09:43:30,096 - slackbot.collectors.api_collector - INFO - NewsAPI params for Business AI News: {'q': 'AI', 'category': 'business', 'language': 'en', 'country': 'us', 'page_size': 10}
2025-08-22 09:43:31,137 - slackbot.collectors.api_collector - INFO - NewsAPI response for Business AI News: status=ok, totalResults=19, articles=9
2025-08-22 09:43:31,137 - slackbot.collectors.api_collector - INFO - Fetched 9 articles from Business AI News
2025-08-22 09:43:31,138 - slackbot.collectors.api_collector - INFO - NewsAPI params for Science AI News: {'q': 'AI', 'category': 'science', 'language': 'en', 'country': 'us', 'page_size': 10}
2025-08-22 09:43:31,917 - slackbot.collectors.api_collector - INFO - NewsAPI response for Science AI News: status=ok, totalResults=20, articles=10
2025-08-22 09:43:31,917 - slackbot.collectors.api_collector - INFO - Fetched 10 articles from Science AI News
2025-08-22 09:43:31,918 - slackbot.collectors.api_collector - INFO - NewsAPI params for Health AI News: {'q': 'AI', 'category': 'health', 'language': 'en', 'country': 'us', 'page_size': 10}
2025-08-22 09:43:32,365 - slackbot.collectors.api_collector - INFO - NewsAPI response for Health AI News: status=ok, totalResults=24, articles=9
2025-08-22 09:43:32,365 - slackbot.collectors.api_collector - INFO - Fetched 9 articles from Health AI News
2025-08-22 09:43:32,365 - slackbot.collectors.api_collector - INFO - Limited results to 20 items (balanced: 10 ArXiv, 10 NewsAPI)
2025-08-22 09:43:32,365 - slackbot.collectors.api_collector - INFO - Collected 20 total items from API News Collector
2025-08-22 09:43:32,366 - __main__ - INFO - üìä Limited collection to 8 articles (balanced: 4 ArXiv, 4 NewsAPI)
2025-08-22 09:43:32,366 - __main__ - INFO - ‚úÖ Successfully collected 8 articles
2025-08-22 09:43:32,366 - __main__ - INFO -   1. Scaling Group Inference for Diverse and High-Quality Generat...
2025-08-22 09:43:32,366 - __main__ - INFO -      Source: ArXiv AI Papers (arxiv)
2025-08-22 09:43:32,366 - __main__ - INFO -      Category: Research Papers
2025-08-22 09:43:32,366 - __main__ - INFO -   2. Visual Autoregressive Modeling for Instruction-Guided Image ...
2025-08-22 09:43:32,366 - __main__ - INFO -      Source: ArXiv AI Papers (arxiv)
2025-08-22 09:43:32,366 - __main__ - INFO -      Category: Research Papers
2025-08-22 09:43:32,366 - __main__ - INFO -   3. SceneGen: Single-Image 3D Scene Generation in One Feedforwar...
2025-08-22 09:43:32,366 - __main__ - INFO -      Source: ArXiv AI Papers (arxiv)
2025-08-22 09:43:32,366 - __main__ - INFO -      Category: Research Papers
2025-08-22 09:43:32,366 - __main__ - INFO - 
üß† Step 3: Creating TLDR Summaries
2025-08-22 09:43:32,366 - __main__ - INFO - ----------------------------------------
2025-08-22 09:43:32,367 - __main__ - INFO - üß† Starting TLDR summarization...
2025-08-22 09:43:32,367 - __main__ - INFO -   Processing 1/8: Scaling Group Inference for Diverse and High-Quali...
2025-08-22 09:43:32,402 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-bb17ee1a-2046-4771-9760-37d3ce888916', 'json_data': {'messages': [{'content': 'You are an expert AI news analyst creating TLDR summaries. Focus on the key facts, why it matters, and make it engaging for busy professionals. Keep it concise and actionable.', 'role': 'system'}, {'content': 'Create a TLDR summary for this article:\n\nTitle: Scaling Group Inference for Diverse and High-Quality Generation\nContent: Generative models typically sample outputs independently, and recent\ninference-time guidance and scaling algorithms focus on improving the quality\nof individual samples. However, in real-world applications, users are often\npresented with a set of multiple images (e.g., 4-8) for each prompt, where\nindependent sampling tends to lead to redundant results, limiting user choices\nand hindering idea exploration. In this work, we introduce a scalable group\ninference method that improves both the diversity and quality of a group of\nsamples. We formulate group inference as a quadratic integer assignment\nproblem: candidate outputs are modeled as graph nodes, and a subset is selected\nto optimize sample quality (unary term) while maximizing group diversity\n(binary term). To substantially improve runtime efficiency, we progressively\nprune the candidate set using intermediate predictions, allowing our method to\nscale up to large candidate sets. Extensive experiments show that our method\nsignificantly improves group diversity and quality compared to independent\nsampling baselines and recent inference algorithms. Our framework generalizes\nacross a wide range of tasks, including text-to-image, image-to-image, image\nprompting, and video generation, enabling generative models to treat multiple\noutputs as cohesive groups rather than independent samples.\n\nThe output should be formatted as a JSON instance that conforms to the JSON schema below.\n\nAs an example, for the schema {"properties": {"foo": {"title": "Foo", "description": "a list of strings", "type": "array", "items": {"type": "string"}}}, "required": ["foo"]}\nthe object {"foo": ["bar", "baz"]} is a well-formatted instance of the schema. The object {"properties": {"foo": ["bar", "baz"]}} is not well-formatted.\n\nHere is the output schema:\n```\n{"description": "Structured TLDR output for individual articles.", "properties": {"tldr": {"description": "2-3 sentence TLDR summary of the article", "title": "Tldr", "type": "string"}, "key_facts": {"description": "3-5 key facts or takeaways", "items": {"type": "string"}, "title": "Key Facts", "type": "array"}, "why_matters": {"description": "1-2 sentences explaining why this matters to AI/ML professionals", "title": "Why Matters", "type": "string"}, "reading_time": {"description": "Estimated reading time (e.g., \'2 min read\')", "title": "Reading Time", "type": "string"}, "difficulty": {"description": "Content difficulty level: \'Beginner\', \'Intermediate\', or \'Advanced\'", "title": "Difficulty", "type": "string"}}, "required": ["tldr", "key_facts", "why_matters", "reading_time", "difficulty"]}\n```', 'role': 'user'}], 'model': 'gpt-3.5-turbo', 'max_completion_tokens': 2048, 'stream': False, 'temperature': 0.3}}
2025-08-22 09:43:32,408 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-08-22 09:43:32,408 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
2025-08-22 09:43:32,437 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x743b2c51f750>
2025-08-22 09:43:32,437 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x743b2fb11520> server_hostname='api.openai.com' timeout=None
2025-08-22 09:43:32,470 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x743b2c4e7350>
2025-08-22 09:43:32,470 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-08-22 09:43:32,470 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-08-22 09:43:32,470 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-08-22 09:43:32,470 - httpcore.http11 - DEBUG - send_request_body.complete
2025-08-22 09:43:32,470 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-08-22 09:43:35,875 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 22 Aug 2025 04:13:35 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'keyvalue-rtv23o'), (b'openai-processing-ms', b'2147'), (b'openai-project', b'proj_whQdFja0l3II6fu7PPtC7wv5'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'2248'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'50000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'49999268'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'0s'), (b'x-request-id', b'req_b3aee614f2984ef78d10623e7e331f6e'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=joq5xQLVXI8RsJ3JedYIFzV7Qxb9BHm.hDp3ixwz67o-1755836015-1.0.1.1-doF.BV6JiJ8JqLq6rNQ2ZJIYBr3Mc2vmDQdShccbEPMpIcE54RKNbwH03M4fP8FVl3UGcJxKXZCt3pmTxoFHnUMmcFKqn3zrwNdZyRjXBXU; path=/; expires=Fri, 22-Aug-25 04:43:35 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=N5C35yPtdVgwk1XbfScuRtPy9jgiU699ipF2kDGih3Y-1755836015904-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'972f89c648bfb5bf-MAA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-08-22 09:43:35,876 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-22 09:43:35,877 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-08-22 09:43:35,877 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-08-22 09:43:35,878 - httpcore.http11 - DEBUG - response_closed.started
2025-08-22 09:43:35,878 - httpcore.http11 - DEBUG - response_closed.complete
2025-08-22 09:43:35,878 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Fri, 22 Aug 2025 04:13:35 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'keyvalue-rtv23o'), ('openai-processing-ms', '2147'), ('openai-project', 'proj_whQdFja0l3II6fu7PPtC7wv5'), ('openai-version', '2020-10-01'), ('x-envoy-upstream-service-time', '2248'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '50000000'), ('x-ratelimit-remaining-requests', '9999'), ('x-ratelimit-remaining-tokens', '49999268'), ('x-ratelimit-reset-requests', '6ms'), ('x-ratelimit-reset-tokens', '0s'), ('x-request-id', 'req_b3aee614f2984ef78d10623e7e331f6e'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=joq5xQLVXI8RsJ3JedYIFzV7Qxb9BHm.hDp3ixwz67o-1755836015-1.0.1.1-doF.BV6JiJ8JqLq6rNQ2ZJIYBr3Mc2vmDQdShccbEPMpIcE54RKNbwH03M4fP8FVl3UGcJxKXZCt3pmTxoFHnUMmcFKqn3zrwNdZyRjXBXU; path=/; expires=Fri, 22-Aug-25 04:43:35 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=N5C35yPtdVgwk1XbfScuRtPy9jgiU699ipF2kDGih3Y-1755836015904-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '972f89c648bfb5bf-MAA'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')])
2025-08-22 09:43:35,879 - openai._base_client - DEBUG - request_id: req_b3aee614f2984ef78d10623e7e331f6e
2025-08-22 09:43:35,909 - __main__ - INFO -     ‚úÖ Summary created using gpt-3.5-turbo
2025-08-22 09:43:35,909 - __main__ - INFO -   Processing 2/8: Visual Autoregressive Modeling for Instruction-Gui...
2025-08-22 09:43:35,911 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-34d81a4c-bda9-4a38-b4c8-94d8b139e26c', 'json_data': {'messages': [{'content': 'You are an expert AI news analyst creating TLDR summaries. Focus on the key facts, why it matters, and make it engaging for busy professionals. Keep it concise and actionable.', 'role': 'system'}, {'content': 'Create a TLDR summary for this article:\n\nTitle: Visual Autoregressive Modeling for Instruction-Guided Image Editing\nContent: Recent advances in diffusion models have brought remarkable visual fidelity\nto instruction-guided image editing. However, their global denoising process\ninherently entangles the edited region with the entire image context, leading\nto unintended spurious modifications and compromised adherence to editing\ninstructions. In contrast, autoregressive models offer a distinct paradigm by\nformulating image synthesis as a sequential process over discrete visual\ntokens. Their causal and compositional mechanism naturally circumvents the\nadherence challenges of diffusion-based methods. In this paper, we present\nVAREdit, a visual autoregressive (VAR) framework that reframes image editing as\na next-scale prediction problem. Conditioned on source image features and text\ninstructions, VAREdit generates multi-scale target features to achieve precise\nedits. A core challenge in this paradigm is how to effectively condition the\nsource image tokens. We observe that finest-scale source features cannot\neffectively guide the prediction of coarser target features. To bridge this\ngap, we introduce a Scale-Aligned Reference (SAR) module, which injects\nscale-matched conditioning information into the first self-attention layer.\nVAREdit demonstrates significant advancements in both editing adherence and\nefficiency. On standard benchmarks, it outperforms leading diffusion-based\nmethods by 30\\%+ higher GPT-Balance score. Moreover, it completes a\n$512\\times512$ editing in 1.2 seconds, making it 2.2$\\times$ faster than the\nsimilarly sized UltraEdit. The models are available at\nhttps://github.com/HiDream-ai/VAREdit.\n\nThe output should be formatted as a JSON instance that conforms to the JSON schema below.\n\nAs an example, for the schema {"properties": {"foo": {"title": "Foo", "description": "a list of strings", "type": "array", "items": {"type": "string"}}}, "required": ["foo"]}\nthe object {"foo": ["bar", "baz"]} is a well-formatted instance of the schema. The object {"properties": {"foo": ["bar", "baz"]}} is not well-formatted.\n\nHere is the output schema:\n```\n{"description": "Structured TLDR output for individual articles.", "properties": {"tldr": {"description": "2-3 sentence TLDR summary of the article", "title": "Tldr", "type": "string"}, "key_facts": {"description": "3-5 key facts or takeaways", "items": {"type": "string"}, "title": "Key Facts", "type": "array"}, "why_matters": {"description": "1-2 sentences explaining why this matters to AI/ML professionals", "title": "Why Matters", "type": "string"}, "reading_time": {"description": "Estimated reading time (e.g., \'2 min read\')", "title": "Reading Time", "type": "string"}, "difficulty": {"description": "Content difficulty level: \'Beginner\', \'Intermediate\', or \'Advanced\'", "title": "Difficulty", "type": "string"}}, "required": ["tldr", "key_facts", "why_matters", "reading_time", "difficulty"]}\n```', 'role': 'user'}], 'model': 'gpt-3.5-turbo', 'max_completion_tokens': 2048, 'stream': False, 'temperature': 0.3}}
2025-08-22 09:43:35,912 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-08-22 09:43:35,912 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-08-22 09:43:35,912 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-08-22 09:43:35,912 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-08-22 09:43:35,913 - httpcore.http11 - DEBUG - send_request_body.complete
2025-08-22 09:43:35,913 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-08-22 09:43:38,507 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 22 Aug 2025 04:13:38 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'keyvalue-rtv23o'), (b'openai-processing-ms', b'1704'), (b'openai-project', b'proj_whQdFja0l3II6fu7PPtC7wv5'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'1787'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'50000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'49999205'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'0s'), (b'x-request-id', b'req_19e912bc97744b03bfb607625e786e6b'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'972f89dbd963b5bf-MAA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-08-22 09:43:38,507 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-22 09:43:38,508 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-08-22 09:43:38,508 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-08-22 09:43:38,509 - httpcore.http11 - DEBUG - response_closed.started
2025-08-22 09:43:38,509 - httpcore.http11 - DEBUG - response_closed.complete
2025-08-22 09:43:38,509 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 22 Aug 2025 04:13:38 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'keyvalue-rtv23o', 'openai-processing-ms': '1704', 'openai-project': 'proj_whQdFja0l3II6fu7PPtC7wv5', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '1787', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '50000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '49999205', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '0s', 'x-request-id': 'req_19e912bc97744b03bfb607625e786e6b', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '972f89dbd963b5bf-MAA', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-08-22 09:43:38,510 - openai._base_client - DEBUG - request_id: req_19e912bc97744b03bfb607625e786e6b
2025-08-22 09:43:38,529 - __main__ - INFO -     ‚úÖ Summary created using gpt-3.5-turbo
2025-08-22 09:43:38,529 - __main__ - INFO -   Processing 3/8: SceneGen: Single-Image 3D Scene Generation in One ...
2025-08-22 09:43:38,533 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-a9a5e8bc-922b-4b43-8b74-73979f4d3bd9', 'json_data': {'messages': [{'content': 'You are an expert AI news analyst creating TLDR summaries. Focus on the key facts, why it matters, and make it engaging for busy professionals. Keep it concise and actionable.', 'role': 'system'}, {'content': 'Create a TLDR summary for this article:\n\nTitle: SceneGen: Single-Image 3D Scene Generation in One Feedforward Pass\nContent: 3D content generation has recently attracted significant research interest\ndue to its applications in VR/AR and embodied AI. In this work, we address the\nchallenging task of synthesizing multiple 3D assets within a single scene\nimage. Concretely, our contributions are fourfold: (i) we present SceneGen, a\nnovel framework that takes a scene image and corresponding object masks as\ninput, simultaneously producing multiple 3D assets with geometry and texture.\nNotably, SceneGen operates with no need for optimization or asset retrieval;\n(ii) we introduce a novel feature aggregation module that integrates local and\nglobal scene information from visual and geometric encoders within the feature\nextraction module. Coupled with a position head, this enables the generation of\n3D assets and their relative spatial positions in a single feedforward pass;\n(iii) we demonstrate SceneGen\'s direct extensibility to multi-image input\nscenarios. Despite being trained solely on single-image inputs, our\narchitectural design enables improved generation performance with multi-image\ninputs; and (iv) extensive quantitative and qualitative evaluations confirm the\nefficiency and robust generation abilities of our approach. We believe this\nparadigm offers a novel solution for high-quality 3D content generation,\npotentially advancing its practical applications in downstream tasks. The code\nand model will be publicly available at: https://mengmouxu.github.io/SceneGen.\n\nThe output should be formatted as a JSON instance that conforms to the JSON schema below.\n\nAs an example, for the schema {"properties": {"foo": {"title": "Foo", "description": "a list of strings", "type": "array", "items": {"type": "string"}}}, "required": ["foo"]}\nthe object {"foo": ["bar", "baz"]} is a well-formatted instance of the schema. The object {"properties": {"foo": ["bar", "baz"]}} is not well-formatted.\n\nHere is the output schema:\n```\n{"description": "Structured TLDR output for individual articles.", "properties": {"tldr": {"description": "2-3 sentence TLDR summary of the article", "title": "Tldr", "type": "string"}, "key_facts": {"description": "3-5 key facts or takeaways", "items": {"type": "string"}, "title": "Key Facts", "type": "array"}, "why_matters": {"description": "1-2 sentences explaining why this matters to AI/ML professionals", "title": "Why Matters", "type": "string"}, "reading_time": {"description": "Estimated reading time (e.g., \'2 min read\')", "title": "Reading Time", "type": "string"}, "difficulty": {"description": "Content difficulty level: \'Beginner\', \'Intermediate\', or \'Advanced\'", "title": "Difficulty", "type": "string"}}, "required": ["tldr", "key_facts", "why_matters", "reading_time", "difficulty"]}\n```', 'role': 'user'}], 'model': 'gpt-3.5-turbo', 'max_completion_tokens': 2048, 'stream': False, 'temperature': 0.3}}
2025-08-22 09:43:38,534 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-08-22 09:43:38,535 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-08-22 09:43:38,535 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-08-22 09:43:38,536 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-08-22 09:43:38,536 - httpcore.http11 - DEBUG - send_request_body.complete
2025-08-22 09:43:38,536 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-08-22 09:43:41,282 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 22 Aug 2025 04:13:41 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'keyvalue-rtv23o'), (b'openai-processing-ms', b'2112'), (b'openai-project', b'proj_whQdFja0l3II6fu7PPtC7wv5'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'2213'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'50000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'49999243'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'0s'), (b'x-request-id', b'req_1f4eeee153f34b8db3f66a34daad09f6'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'972f89ec2d52b5bf-MAA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-08-22 09:43:41,283 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-22 09:43:41,284 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-08-22 09:43:41,285 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-08-22 09:43:41,285 - httpcore.http11 - DEBUG - response_closed.started
2025-08-22 09:43:41,285 - httpcore.http11 - DEBUG - response_closed.complete
2025-08-22 09:43:41,286 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 22 Aug 2025 04:13:41 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'keyvalue-rtv23o', 'openai-processing-ms': '2112', 'openai-project': 'proj_whQdFja0l3II6fu7PPtC7wv5', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '2213', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '50000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '49999243', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '0s', 'x-request-id': 'req_1f4eeee153f34b8db3f66a34daad09f6', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '972f89ec2d52b5bf-MAA', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-08-22 09:43:41,286 - openai._base_client - DEBUG - request_id: req_1f4eeee153f34b8db3f66a34daad09f6
2025-08-22 09:43:41,311 - __main__ - INFO -     ‚úÖ Summary created using gpt-3.5-turbo
2025-08-22 09:43:41,311 - __main__ - INFO -   Processing 4/8: ATLAS: Decoupling Skeletal and Shape Parameters fo...
2025-08-22 09:43:41,315 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-c3e9f8ed-8b3b-4b4f-a4ea-321552473dc0', 'json_data': {'messages': [{'content': 'You are an expert AI news analyst creating TLDR summaries. Focus on the key facts, why it matters, and make it engaging for busy professionals. Keep it concise and actionable.', 'role': 'system'}, {'content': 'Create a TLDR summary for this article:\n\nTitle: ATLAS: Decoupling Skeletal and Shape Parameters for Expressive Parametric Human Modeling\nContent: Parametric body models offer expressive 3D representation of humans across a\nwide range of poses, shapes, and facial expressions, typically derived by\nlearning a basis over registered 3D meshes. However, existing human mesh\nmodeling approaches struggle to capture detailed variations across diverse body\nposes and shapes, largely due to limited training data diversity and\nrestrictive modeling assumptions. Moreover, the common paradigm first optimizes\nthe external body surface using a linear basis, then regresses internal\nskeletal joints from surface vertices. This approach introduces problematic\ndependencies between internal skeleton and outer soft tissue, limiting direct\ncontrol over body height and bone lengths. To address these issues, we present\nATLAS, a high-fidelity body model learned from 600k high-resolution scans\ncaptured using 240 synchronized cameras. Unlike previous methods, we explicitly\ndecouple the shape and skeleton bases by grounding our mesh representation in\nthe human skeleton. This decoupling enables enhanced shape expressivity,\nfine-grained customization of body attributes, and keypoint fitting independent\nof external soft-tissue characteristics. ATLAS outperforms existing methods by\nfitting unseen subjects in diverse poses more accurately, and quantitative\nevaluations show that our non-linear pose correctives more effectively capture\ncomplex poses compared to linear models.\n\nThe output should be formatted as a JSON instance that conforms to the JSON schema below.\n\nAs an example, for the schema {"properties": {"foo": {"title": "Foo", "description": "a list of strings", "type": "array", "items": {"type": "string"}}}, "required": ["foo"]}\nthe object {"foo": ["bar", "baz"]} is a well-formatted instance of the schema. The object {"properties": {"foo": ["bar", "baz"]}} is not well-formatted.\n\nHere is the output schema:\n```\n{"description": "Structured TLDR output for individual articles.", "properties": {"tldr": {"description": "2-3 sentence TLDR summary of the article", "title": "Tldr", "type": "string"}, "key_facts": {"description": "3-5 key facts or takeaways", "items": {"type": "string"}, "title": "Key Facts", "type": "array"}, "why_matters": {"description": "1-2 sentences explaining why this matters to AI/ML professionals", "title": "Why Matters", "type": "string"}, "reading_time": {"description": "Estimated reading time (e.g., \'2 min read\')", "title": "Reading Time", "type": "string"}, "difficulty": {"description": "Content difficulty level: \'Beginner\', \'Intermediate\', or \'Advanced\'", "title": "Difficulty", "type": "string"}}, "required": ["tldr", "key_facts", "why_matters", "reading_time", "difficulty"]}\n```', 'role': 'user'}], 'model': 'gpt-3.5-turbo', 'max_completion_tokens': 2048, 'stream': False, 'temperature': 0.3}}
2025-08-22 09:43:41,316 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-08-22 09:43:41,316 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-08-22 09:43:41,317 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-08-22 09:43:41,317 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-08-22 09:43:41,317 - httpcore.http11 - DEBUG - send_request_body.complete
2025-08-22 09:43:41,317 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-08-22 09:43:43,921 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 22 Aug 2025 04:13:43 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'keyvalue-rtv23o'), (b'openai-processing-ms', b'1438'), (b'openai-project', b'proj_whQdFja0l3II6fu7PPtC7wv5'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'1571'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'50000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'49999247'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'0s'), (b'x-request-id', b'req_2816ae736a1d4c8ea3268d19940d3b59'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'972f89fd8d35b5bf-MAA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-08-22 09:43:43,921 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-22 09:43:43,922 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-08-22 09:43:43,930 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-08-22 09:43:43,930 - httpcore.http11 - DEBUG - response_closed.started
2025-08-22 09:43:43,931 - httpcore.http11 - DEBUG - response_closed.complete
2025-08-22 09:43:43,931 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 22 Aug 2025 04:13:43 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'keyvalue-rtv23o', 'openai-processing-ms': '1438', 'openai-project': 'proj_whQdFja0l3II6fu7PPtC7wv5', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '1571', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '50000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '49999247', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '0s', 'x-request-id': 'req_2816ae736a1d4c8ea3268d19940d3b59', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '972f89fd8d35b5bf-MAA', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-08-22 09:43:43,931 - openai._base_client - DEBUG - request_id: req_2816ae736a1d4c8ea3268d19940d3b59
2025-08-22 09:43:43,947 - __main__ - INFO -     ‚úÖ Summary created using gpt-3.5-turbo
2025-08-22 09:43:43,947 - __main__ - INFO -   Processing 5/8: Today is your last chance to grab a PS5 before Son...
2025-08-22 09:43:43,951 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-f591b9d6-705c-424b-9afe-ac8bc5636010', 'json_data': {'messages': [{'content': 'You are an expert AI news analyst creating TLDR summaries. Focus on the key facts, why it matters, and make it engaging for busy professionals. Keep it concise and actionable.', 'role': 'system'}, {'content': 'Create a TLDR summary for this article:\n\nTitle: Today is your last chance to grab a PS5 before Sony‚Äôs price hikes go into effect - The Verge\nContent: <ul><li></li><li></li><li></li></ul>\r\nEvery PlayStation 5 model is about to get $50 more expensive because of tariffs. \r\nEvery PlayStation 5 model is about to get $50 more expensive because of tariff‚Ä¶ [+3505 chars]\n\nThe output should be formatted as a JSON instance that conforms to the JSON schema below.\n\nAs an example, for the schema {"properties": {"foo": {"title": "Foo", "description": "a list of strings", "type": "array", "items": {"type": "string"}}}, "required": ["foo"]}\nthe object {"foo": ["bar", "baz"]} is a well-formatted instance of the schema. The object {"properties": {"foo": ["bar", "baz"]}} is not well-formatted.\n\nHere is the output schema:\n```\n{"description": "Structured TLDR output for individual articles.", "properties": {"tldr": {"description": "2-3 sentence TLDR summary of the article", "title": "Tldr", "type": "string"}, "key_facts": {"description": "3-5 key facts or takeaways", "items": {"type": "string"}, "title": "Key Facts", "type": "array"}, "why_matters": {"description": "1-2 sentences explaining why this matters to AI/ML professionals", "title": "Why Matters", "type": "string"}, "reading_time": {"description": "Estimated reading time (e.g., \'2 min read\')", "title": "Reading Time", "type": "string"}, "difficulty": {"description": "Content difficulty level: \'Beginner\', \'Intermediate\', or \'Advanced\'", "title": "Difficulty", "type": "string"}}, "required": ["tldr", "key_facts", "why_matters", "reading_time", "difficulty"]}\n```', 'role': 'user'}], 'model': 'gpt-3.5-turbo', 'max_completion_tokens': 2048, 'stream': False, 'temperature': 0.3}}
2025-08-22 09:43:43,952 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-08-22 09:43:43,953 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-08-22 09:43:43,953 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-08-22 09:43:43,953 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-08-22 09:43:43,953 - httpcore.http11 - DEBUG - send_request_body.complete
2025-08-22 09:43:43,953 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-08-22 09:43:45,470 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 22 Aug 2025 04:13:45 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'keyvalue-rtv23o'), (b'openai-processing-ms', b'1067'), (b'openai-project', b'proj_whQdFja0l3II6fu7PPtC7wv5'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'1098'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'50000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'49999545'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'0s'), (b'x-request-id', b'req_9c415d750f174903b8f73e8c1c20a2f9'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'972f8a0e0c9eb5bf-MAA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-08-22 09:43:45,471 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-22 09:43:45,471 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-08-22 09:43:45,471 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-08-22 09:43:45,471 - httpcore.http11 - DEBUG - response_closed.started
2025-08-22 09:43:45,471 - httpcore.http11 - DEBUG - response_closed.complete
2025-08-22 09:43:45,472 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 22 Aug 2025 04:13:45 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'keyvalue-rtv23o', 'openai-processing-ms': '1067', 'openai-project': 'proj_whQdFja0l3II6fu7PPtC7wv5', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '1098', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '50000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '49999545', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '0s', 'x-request-id': 'req_9c415d750f174903b8f73e8c1c20a2f9', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '972f8a0e0c9eb5bf-MAA', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-08-22 09:43:45,472 - openai._base_client - DEBUG - request_id: req_9c415d750f174903b8f73e8c1c20a2f9
2025-08-22 09:43:45,485 - __main__ - INFO -     ‚úÖ Summary created using gpt-3.5-turbo
2025-08-22 09:43:45,485 - __main__ - INFO -   Processing 6/8: Exclusive | Meta Freezes AI Hiring After Blockbust...
2025-08-22 09:43:45,490 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-0ace544e-2c51-487f-91fe-ad37ccd7796c', 'json_data': {'messages': [{'content': 'You are an expert AI news analyst creating TLDR summaries. Focus on the key facts, why it matters, and make it engaging for busy professionals. Keep it concise and actionable.', 'role': 'system'}, {'content': 'Create a TLDR summary for this article:\n\nTitle: Exclusive | Meta Freezes AI Hiring After Blockbuster Spending Spree - The Wall Street Journal\nContent: None\n\nThe output should be formatted as a JSON instance that conforms to the JSON schema below.\n\nAs an example, for the schema {"properties": {"foo": {"title": "Foo", "description": "a list of strings", "type": "array", "items": {"type": "string"}}}, "required": ["foo"]}\nthe object {"foo": ["bar", "baz"]} is a well-formatted instance of the schema. The object {"properties": {"foo": ["bar", "baz"]}} is not well-formatted.\n\nHere is the output schema:\n```\n{"description": "Structured TLDR output for individual articles.", "properties": {"tldr": {"description": "2-3 sentence TLDR summary of the article", "title": "Tldr", "type": "string"}, "key_facts": {"description": "3-5 key facts or takeaways", "items": {"type": "string"}, "title": "Key Facts", "type": "array"}, "why_matters": {"description": "1-2 sentences explaining why this matters to AI/ML professionals", "title": "Why Matters", "type": "string"}, "reading_time": {"description": "Estimated reading time (e.g., \'2 min read\')", "title": "Reading Time", "type": "string"}, "difficulty": {"description": "Content difficulty level: \'Beginner\', \'Intermediate\', or \'Advanced\'", "title": "Difficulty", "type": "string"}}, "required": ["tldr", "key_facts", "why_matters", "reading_time", "difficulty"]}\n```', 'role': 'user'}], 'model': 'gpt-3.5-turbo', 'max_completion_tokens': 2048, 'stream': False, 'temperature': 0.3}}
2025-08-22 09:43:45,491 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-08-22 09:43:45,491 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-08-22 09:43:45,491 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-08-22 09:43:45,492 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-08-22 09:43:45,492 - httpcore.http11 - DEBUG - send_request_body.complete
2025-08-22 09:43:45,492 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-08-22 09:43:47,518 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 22 Aug 2025 04:13:47 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'keyvalue-rtv23o'), (b'openai-processing-ms', b'1196'), (b'openai-project', b'proj_whQdFja0l3II6fu7PPtC7wv5'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'1320'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'50000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'49999599'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'0s'), (b'x-request-id', b'req_d39ba7e1e912417da86e3c92b8e19bdd'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'972f8a17a84cb5bf-MAA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-08-22 09:43:47,518 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-22 09:43:47,519 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-08-22 09:43:47,519 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-08-22 09:43:47,519 - httpcore.http11 - DEBUG - response_closed.started
2025-08-22 09:43:47,520 - httpcore.http11 - DEBUG - response_closed.complete
2025-08-22 09:43:47,520 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 22 Aug 2025 04:13:47 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'keyvalue-rtv23o', 'openai-processing-ms': '1196', 'openai-project': 'proj_whQdFja0l3II6fu7PPtC7wv5', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '1320', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '50000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '49999599', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '0s', 'x-request-id': 'req_d39ba7e1e912417da86e3c92b8e19bdd', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '972f8a17a84cb5bf-MAA', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-08-22 09:43:47,520 - openai._base_client - DEBUG - request_id: req_d39ba7e1e912417da86e3c92b8e19bdd
2025-08-22 09:43:47,534 - __main__ - INFO -     ‚úÖ Summary created using gpt-3.5-turbo
2025-08-22 09:43:47,534 - __main__ - INFO -   Processing 7/8: China turns against Nvidia‚Äôs AI chip after ‚Äòinsult...
2025-08-22 09:43:47,538 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-733b5425-10b3-482e-8e99-71326da14392', 'json_data': {'messages': [{'content': 'You are an expert AI news analyst creating TLDR summaries. Focus on the key facts, why it matters, and make it engaging for busy professionals. Keep it concise and actionable.', 'role': 'system'}, {'content': 'Create a TLDR summary for this article:\n\nTitle: China turns against Nvidia‚Äôs AI chip after ‚Äòinsulting‚Äô Howard Lutnick remarks - Financial Times\nContent: Complete digital access to quality analysis and expert insights, complemented with our award-winning Weekend Print edition.\r\n<ul><li></li>Everything in Print<li></li>Weekday Print Edition<li></li>FT ‚Ä¶ [+202 chars]\n\nThe output should be formatted as a JSON instance that conforms to the JSON schema below.\n\nAs an example, for the schema {"properties": {"foo": {"title": "Foo", "description": "a list of strings", "type": "array", "items": {"type": "string"}}}, "required": ["foo"]}\nthe object {"foo": ["bar", "baz"]} is a well-formatted instance of the schema. The object {"properties": {"foo": ["bar", "baz"]}} is not well-formatted.\n\nHere is the output schema:\n```\n{"description": "Structured TLDR output for individual articles.", "properties": {"tldr": {"description": "2-3 sentence TLDR summary of the article", "title": "Tldr", "type": "string"}, "key_facts": {"description": "3-5 key facts or takeaways", "items": {"type": "string"}, "title": "Key Facts", "type": "array"}, "why_matters": {"description": "1-2 sentences explaining why this matters to AI/ML professionals", "title": "Why Matters", "type": "string"}, "reading_time": {"description": "Estimated reading time (e.g., \'2 min read\')", "title": "Reading Time", "type": "string"}, "difficulty": {"description": "Content difficulty level: \'Beginner\', \'Intermediate\', or \'Advanced\'", "title": "Difficulty", "type": "string"}}, "required": ["tldr", "key_facts", "why_matters", "reading_time", "difficulty"]}\n```', 'role': 'user'}], 'model': 'gpt-3.5-turbo', 'max_completion_tokens': 2048, 'stream': False, 'temperature': 0.3}}
2025-08-22 09:43:47,539 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-08-22 09:43:47,539 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-08-22 09:43:47,540 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-08-22 09:43:47,540 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-08-22 09:43:47,540 - httpcore.http11 - DEBUG - send_request_body.complete
2025-08-22 09:43:47,540 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-08-22 09:43:49,484 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 22 Aug 2025 04:13:49 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'keyvalue-rtv23o'), (b'openai-processing-ms', b'1028'), (b'openai-project', b'proj_whQdFja0l3II6fu7PPtC7wv5'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'1139'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'50000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'49999545'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'0s'), (b'x-request-id', b'req_fe9647876c0d470ca9be92a91615f13d'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'972f8a247e31b5bf-MAA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-08-22 09:43:49,485 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-22 09:43:49,485 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-08-22 09:43:49,490 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-08-22 09:43:49,491 - httpcore.http11 - DEBUG - response_closed.started
2025-08-22 09:43:49,491 - httpcore.http11 - DEBUG - response_closed.complete
2025-08-22 09:43:49,491 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 22 Aug 2025 04:13:49 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'keyvalue-rtv23o', 'openai-processing-ms': '1028', 'openai-project': 'proj_whQdFja0l3II6fu7PPtC7wv5', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '1139', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '50000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '49999545', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '0s', 'x-request-id': 'req_fe9647876c0d470ca9be92a91615f13d', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '972f8a247e31b5bf-MAA', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-08-22 09:43:49,492 - openai._base_client - DEBUG - request_id: req_fe9647876c0d470ca9be92a91615f13d
2025-08-22 09:43:49,507 - __main__ - INFO -     ‚úÖ Summary created using gpt-3.5-turbo
2025-08-22 09:43:49,507 - __main__ - INFO -   Processing 8/8: Trump housing regulator accuses Fed governor Cook ...
2025-08-22 09:43:49,512 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-6c62111a-2ae2-4332-a00a-b4e61b95c8f3', 'json_data': {'messages': [{'content': 'You are an expert AI news analyst creating TLDR summaries. Focus on the key facts, why it matters, and make it engaging for busy professionals. Keep it concise and actionable.', 'role': 'system'}, {'content': 'Create a TLDR summary for this article:\n\nTitle: Trump housing regulator accuses Fed governor Cook of mortgage fraud - Axios\nContent: Driving the news: Pulte, chair of the Federal Housing Finance Agency, posted on X a letter to the attorney general stating that it appears Cook "has falsified bank documents and property records to a‚Ä¶ [+2717 chars]\n\nThe output should be formatted as a JSON instance that conforms to the JSON schema below.\n\nAs an example, for the schema {"properties": {"foo": {"title": "Foo", "description": "a list of strings", "type": "array", "items": {"type": "string"}}}, "required": ["foo"]}\nthe object {"foo": ["bar", "baz"]} is a well-formatted instance of the schema. The object {"properties": {"foo": ["bar", "baz"]}} is not well-formatted.\n\nHere is the output schema:\n```\n{"description": "Structured TLDR output for individual articles.", "properties": {"tldr": {"description": "2-3 sentence TLDR summary of the article", "title": "Tldr", "type": "string"}, "key_facts": {"description": "3-5 key facts or takeaways", "items": {"type": "string"}, "title": "Key Facts", "type": "array"}, "why_matters": {"description": "1-2 sentences explaining why this matters to AI/ML professionals", "title": "Why Matters", "type": "string"}, "reading_time": {"description": "Estimated reading time (e.g., \'2 min read\')", "title": "Reading Time", "type": "string"}, "difficulty": {"description": "Content difficulty level: \'Beginner\', \'Intermediate\', or \'Advanced\'", "title": "Difficulty", "type": "string"}}, "required": ["tldr", "key_facts", "why_matters", "reading_time", "difficulty"]}\n```', 'role': 'user'}], 'model': 'gpt-3.5-turbo', 'max_completion_tokens': 2048, 'stream': False, 'temperature': 0.3}}
2025-08-22 09:43:49,513 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-08-22 09:43:49,514 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-08-22 09:43:49,514 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-08-22 09:43:49,514 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-08-22 09:43:49,515 - httpcore.http11 - DEBUG - send_request_body.complete
2025-08-22 09:43:49,515 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-08-22 09:43:51,553 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 22 Aug 2025 04:13:51 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'keyvalue-rtv23o'), (b'openai-processing-ms', b'1407'), (b'openai-project', b'proj_whQdFja0l3II6fu7PPtC7wv5'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'1508'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'50000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'49999550'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'0s'), (b'x-request-id', b'req_a372da1ceb344d5ba3afa5dee1e9606d'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'972f8a30cdd7b5bf-MAA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-08-22 09:43:51,554 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-22 09:43:51,554 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-08-22 09:43:51,560 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-08-22 09:43:51,561 - httpcore.http11 - DEBUG - response_closed.started
2025-08-22 09:43:51,561 - httpcore.http11 - DEBUG - response_closed.complete
2025-08-22 09:43:51,561 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 22 Aug 2025 04:13:51 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'keyvalue-rtv23o', 'openai-processing-ms': '1407', 'openai-project': 'proj_whQdFja0l3II6fu7PPtC7wv5', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '1508', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '50000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '49999550', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '0s', 'x-request-id': 'req_a372da1ceb344d5ba3afa5dee1e9606d', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '972f8a30cdd7b5bf-MAA', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-08-22 09:43:51,561 - openai._base_client - DEBUG - request_id: req_a372da1ceb344d5ba3afa5dee1e9606d
2025-08-22 09:43:51,570 - __main__ - INFO -     ‚úÖ Summary created using gpt-3.5-turbo
2025-08-22 09:43:51,570 - __main__ - INFO - ‚úÖ Successfully created 8 TLDR summaries
2025-08-22 09:43:51,570 - __main__ - INFO - 
üí¨ Step 4: Creating Slack Message
2025-08-22 09:43:51,570 - __main__ - INFO - ----------------------------------------
2025-08-22 09:43:51,570 - __main__ - INFO - üí¨ Creating Slack message...
2025-08-22 09:43:51,570 - __main__ - INFO - ‚úÖ Slack message created with 19 blocks
2025-08-22 09:43:51,570 - __main__ - INFO - 
üì§ Step 5: Publishing to Slack
2025-08-22 09:43:51,570 - __main__ - INFO - ----------------------------------------
2025-08-22 09:43:51,571 - __main__ - INFO - üì§ Publishing to Slack channel C09AUAZCQR1...
2025-08-22 09:43:51,571 - slack_bolt.App - DEBUG - Sending a request - url: https://slack.com/api/chat.postMessage, query_params: {}, body_params: {}, files: {}, json_body: {'channel': 'C09AUAZCQR1', 'text': 'üöÄ AI/ML News TLDR - 8 articles summarized', 'attachments': [], 'blocks': [{'type': 'header', 'text': {'type': 'plain_text', 'text': 'üöÄ AI/ML News TLDR - Daily Digest'}}, {'type': 'section', 'text': {'type': 'mrkdwn', 'text': "*Today's AI/ML News Summary*\nCollected 8 articles and created TLDR summaries."}}, {'type': 'divider'}, {'type': 'section', 'text': {'type': 'mrkdwn', 'text': '*1. Scaling Group Inference for Diverse and High-Quality Generation*\nIntroduces a scalable group inference method to enhance diversity and quality of generative model outputs. Formulates group inference as a quadratic integer assignment problem, improving runtime efficiency. Shows significant improvements in group diversity and quality across various generative tasks.\n<http://arxiv.org/abs/2508.15773v1|Read more>'}}, {'type': 'divider'}, {'type': 'section', 'text': {'type': 'mrkdwn', 'text': '*2. Visual Autoregressive Modeling for Instruction-Guided Image Editing*\nVAREdit introduces a visual autoregressive framework for precise image editing guided by text instructions, outperforming diffusion models by 30%+ in GPT-Balance score and achieving faster editing speeds.\n<http://arxiv.org/abs/2508.15772v1|Read more>'}}, {'type': 'divider'}, {'type': 'section', 'text': {'type': 'mrkdwn', 'text': '*3. SceneGen: Single-Image 3D Scene Generation in One Feedforward Pass*\nSceneGen is a framework for single-image 3D scene generation, producing multiple 3D assets with geometry and texture in one pass. It requires no optimization or asset retrieval and can handle multi-image inputs efficiently.\n<http://arxiv.org/abs/2508.15769v1|Read more>'}}, {'type': 'divider'}, {'type': 'section', 'text': {'type': 'mrkdwn', 'text': '*4. ATLAS: Decoupling Skeletal and Shape Parameters for Expressive Parametric Human Modeling*\nATLAS introduces a high-fidelity body model decoupling shape and skeleton parameters for better expressivity and customization. It outperforms existing methods in accurately fitting diverse poses.\n<http://arxiv.org/abs/2508.15767v1|Read more>'}}, {'type': 'divider'}, {'type': 'section', 'text': {'type': 'mrkdwn', 'text': '*5. Today is your last chance to grab a PS5 before Sony‚Äôs price hikes go into effect - The Verge*\nPS5 prices set to increase by $50 due to tariffs, act fast to buy before the hike. Last chance to grab a PS5 at current prices.\n<https://www.theverge.com/tech/763043/sony-playstation-5-ps5-tariff-price-increase-deal-sale|Read more>'}}, {'type': 'divider'}, {'type': 'section', 'text': {'type': 'mrkdwn', 'text': '*6. Exclusive | Meta Freezes AI Hiring After Blockbuster Spending Spree - The Wall Street Journal*\nMeta freezes AI hiring following significant spending, impacting recruitment in the tech industry.\n<https://www.wsj.com/tech/ai/meta-ai-hiring-freeze-fda6b3c4|Read more>'}}, {'type': 'divider'}, {'type': 'section', 'text': {'type': 'mrkdwn', 'text': "*7. China turns against Nvidia‚Äôs AI chip after ‚Äòinsulting‚Äô Howard Lutnick remarks - Financial Times*\nChina distances from Nvidia's AI chip due to offensive remarks by Howard Lutnick.\n<https://www.ft.com/content/b8e30c54-b71c-4113-8b3e-8f54bc36587d|Read more>"}}, {'type': 'divider'}, {'type': 'section', 'text': {'type': 'mrkdwn', 'text': '*8. Trump housing regulator accuses Fed governor Cook of mortgage fraud - Axios*\nTrump housing regulator accuses Fed governor Cook of mortgage fraud.\n<https://www.axios.com/2025/08/20/trump-pulte-cook-fed-mortgage-fraud|Read more>'}}, {'type': 'context', 'elements': [{'type': 'mrkdwn', 'text': 'üìä *8* articles summarized ‚Ä¢ Generated at 09:43:51'}]}]}, headers: {'Content-Type': 'application/json;charset=utf-8', 'Authorization': '(redacted)', 'User-Agent': 'Bolt/1.23.0 Python/3.11.13 slackclient/3.36.0 Linux/6.8.0-65-generic'}
2025-08-22 09:43:52,058 - slack_bolt.App - DEBUG - Received the following response - status: 200, headers: {'date': 'Fri, 22 Aug 2025 04:13:51 GMT', 'server': 'Apache', 'vary': 'Accept-Encoding', 'x-slack-req-id': '7d800defe5c62a8ee03a43626925d763', 'x-content-type-options': 'nosniff', 'x-xss-protection': '0', 'pragma': 'no-cache', 'cache-control': 'private, no-cache, no-store, must-revalidate', 'expires': 'Sat, 26 Jul 1997 05:00:00 GMT', 'content-type': 'application/json; charset=utf-8', 'x-accepted-oauth-scopes': 'chat:write', 'x-oauth-scopes': 'chat:write,files:write', 'access-control-expose-headers': 'x-slack-req-id, retry-after', 'access-control-allow-headers': 'slack-route, x-slack-version-ts, x-b3-traceid, x-b3-spanid, x-b3-parentspanid, x-b3-sampled, x-b3-flags', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'referrer-policy': 'no-referrer', 'x-slack-unique-id': 'aKfuf4OB3XzP7mkdEm1GZAAAEBQ', 'x-slack-backend': 'r', 'access-control-allow-origin': '*', 'content-length': '4800', 'via': '1.1 slack-prod.tinyspeck.com, envoy-www-iad-hzeiivbv,envoy-edge-bom-ekwlnkoy', 'x-envoy-attempt-count': '1', 'x-envoy-upstream-service-time': '333', 'x-backend': 'main_normal main_canary_with_overflow main_control_with_overflow', 'x-server': 'slack-www-hhvm-main-iad-gesf', 'x-slack-shared-secret-outcome': 'no-match', 'x-edge-backend': 'envoy-www', 'timing-allow-origin': '*', 'x-slack-edge-shared-secret-outcome': 'no-match', 'connection': 'close'}, body: {"ok":true,"channel":"C09AUAZCQR1","ts":"1755836031.949879","message":{"user":"U09BG266092","type":"message","ts":"1755836031.949879","bot_id":"B09BG26606Q","app_id":"A09BBRCFEV8","text":":rocket: AI\/ML News TLDR - 8 articles summarized","team":"T4LJBDMDY","bot_profile":{"id":"B09BG26606Q","app_id":"A09BBRCFEV8","user_id":"U09BG266092","name":"Briefly","icons":{"image_36":"https:\/\/avatars.slack-edge.com\/2025-08-21\/9399655186801_62917fdb062b1fa75b31_36.png","image_48":"https:\/\/avatars.slack-edge.com\/2025-08-21\/9399655186801_62917fdb062b1fa75b31_48.png","image_72":"https:\/\/avatars.slack-edge.com\/2025-08-21\/9399655186801_62917fdb062b1fa75b31_72.png"},"deleted":false,"updated":1755759762,"team_id":"T4LJBDMDY"},"blocks":[{"type":"header","block_id":"j3fyu","text":{"type":"plain_text","text":":rocket: AI\/ML News TLDR - Daily Digest","emoji":true}},{"type":"section","block_id":"OigAd","text":{"type":"mrkdwn","text":"*Today's AI\/ML News Summary*\nCollected 8 articles and created TLDR summaries.","verbatim":false}},{"type":"divider","block_id":"P4\/uy"},{"type":"section","block_id":"MeLf+","text":{"type":"mrkdwn","text":"*1. Scaling Group Inference for Diverse and High-Quality Generation*\nIntroduces a scalable group inference method to enhance diversity and quality of generative model outputs. Formulates group inference as a quadratic integer assignment problem, improving runtime efficiency. Shows significant improvements in group diversity and quality across various generative tasks.\n<http:\/\/arxiv.org\/abs\/2508.15773v1|Read more>","verbatim":false}},{"type":"divider","block_id":"\/Qqlm"},{"type":"section","block_id":"\/2VLJ","text":{"type":"mrkdwn","text":"*2. Visual Autoregressive Modeling for Instruction-Guided Image Editing*\nVAREdit introduces a visual autoregressive framework for precise image editing guided by text instructions, outperforming diffusion models by 30%+ in GPT-Balance score and achieving faster editing speeds.\n<http:\/\/arxiv.org\/abs\/2508.15772v1|Read more>","verbatim":false}},{"type":"divider","block_id":"Yyizt"},{"type":"section","block_id":"pI\/0i","text":{"type":"mrkdwn","text":"*3. SceneGen: Single-Image 3D Scene Generation in One Feedforward Pass*\nSceneGen is a framework for single-image 3D scene generation, producing multiple 3D assets with geometry and texture in one pass. It requires no optimization or asset retrieval and can handle multi-image inputs efficiently.\n<http:\/\/arxiv.org\/abs\/2508.15769v1|Read more>","verbatim":false}},{"type":"divider","block_id":"kqMJO"},{"type":"section","block_id":"KX5DS","text":{"type":"mrkdwn","text":"*4. ATLAS: Decoupling Skeletal and Shape Parameters for Expressive Parametric Human Modeling*\nATLAS introduces a high-fidelity body model decoupling shape and skeleton parameters for better expressivity and customization. It outperforms existing methods in accurately fitting diverse poses.\n<http:\/\/arxiv.org\/abs\/2508.15767v1|Read more>","verbatim":false}},{"type":"divider","block_id":"5lExZ"},{"type":"section","block_id":"+jUSR","text":{"type":"mrkdwn","text":"*5. Today is your last chance to grab a PS5 before Sony\u2019s price hikes go into effect - The Verge*\nPS5 prices set to increase by $50 due to tariffs, act fast to buy before the hike. Last chance to grab a PS5 at current prices.\n<https:\/\/www.theverge.com\/tech\/763043\/sony-playstation-5-ps5-tariff-price-increase-deal-sale|Read more>","verbatim":false}},{"type":"divider","block_id":"SdxHD"},{"type":"section","block_id":"ellav","text":{"type":"mrkdwn","text":"*6. Exclusive | Meta Freezes AI Hiring After Blockbuster Spending Spree - The Wall Street Journal*\nMeta freezes AI hiring following significant spending, impacting recruitment in the tech industry.\n<https:\/\/www.wsj.com\/tech\/ai\/meta-ai-hiring-freeze-fda6b3c4|Read more>","verbatim":false}},{"type":"divider","block_id":"5cp8W"},{"type":"section","block_id":"Nnxjj","text":{"type":"mrkdwn","text":"*7. China turns against Nvidia\u2019s AI chip after \u2018insulting\u2019 Howard Lutnick remarks - Financial Times*\nChina distances from Nvidia's AI chip due to offensive remarks by Howard Lutnick.\n<https:\/\/www.ft.com\/content\/b8e30c54-b71c-4113-8b3e-8f54bc36587d|Read more>","verbatim":false}},{"type":"divider","block_id":"H0pnz"},{"type":"section","block_id":"PCjM9","text":{"type":"mrkdwn","text":"*8. Trump housing regulator accuses Fed governor Cook of mortgage fraud - Axios*\nTrump housing regulator accuses Fed governor Cook of mortgage fraud.\n<https:\/\/www.axios.com\/2025\/08\/20\/trump-pulte-cook-fed-mortgage-fraud|Read more>","verbatim":false}},{"type":"context","block_id":"VvBI+","elements":[{"type":"mrkdwn","text":":bar_chart: *8* articles summarized \u2022 Generated at 09:43:51","verbatim":false}]}]}}
2025-08-22 09:43:52,059 - slackbot.slack.publisher - INFO - TLDR message published to C09AUAZCQR1
2025-08-22 09:43:52,059 - __main__ - INFO - üéâ Successfully published to Slack!
2025-08-22 09:43:52,060 - __main__ - INFO - üì∫ Channel: C09AUAZCQR1
2025-08-22 09:43:52,060 - __main__ - INFO - üÜî Message ID: None
2025-08-22 09:43:52,060 - __main__ - INFO - 
üéâ Briefly Bot completed successfully!
2025-08-22 09:43:52,060 - __main__ - INFO - üìä Summary:
2025-08-22 09:43:52,060 - __main__ - INFO -   ‚Ä¢ Articles collected: 8
2025-08-22 09:43:52,060 - __main__ - INFO -   ‚Ä¢ TLDR summaries created: 8
2025-08-22 09:43:52,061 - __main__ - INFO -   ‚Ä¢ Published to Slack: C09AUAZCQR1
2025-08-22 09:43:52,064 - __main__ - INFO - ‚úÖ Briefly Bot completed successfully
2025-08-22 09:43:52,209 - httpcore.connection - DEBUG - close.started
2025-08-22 09:43:52,213 - httpcore.connection - DEBUG - close.complete

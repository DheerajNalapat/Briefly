{
  "timestamp": "2025-08-19T08:08:03.779559",
  "total_items": 30,
  "sources_summary": {
    "arxiv": {
      "count": 30,
      "sources": [
        "ArXiv Computer Vision",
        "ArXiv AI Papers",
        "ArXiv NLP Papers"
      ]
    },
    "newsapi": {
      "count": 0,
      "sources": []
    }
  },
  "categories_summary": {
    "Research Papers": 20,
    "Computer Vision": 7,
    "Natural Language Processing": 3
  },
  "items": [
    {
      "title": "4DNeX: Feed-Forward 4D Generative Modeling Made Easy",
      "link": "http://arxiv.org/abs/2508.13154v1",
      "source": "ArXiv AI Papers",
      "source_type": "arxiv",
      "category": "Research Papers",
      "summary": "We present 4DNeX, the first feed-forward framework for generating 4D (i.e.,\ndynamic 3D) scene representations from a single image. In contrast to existing\nmethods that rely on computationally intensive optimization or require\nmulti-frame video inputs, 4DNeX enables efficient, end-to-end image-to-4D\ngeneration by fine-tuning a pretrained video diffusion model. Specifically, 1)\nto alleviate the scarcity of 4D data, we construct 4DNeX-10M, a large-scale\ndataset with high-quality 4D annotations generated using advanced\nreconstruction approaches. 2) we introduce a unified 6D video representation\nthat jointly models RGB and XYZ sequences, facilitating structured learning of\nboth appearance and geometry. 3) we propose a set of simple yet effective\nadaptation strategies to repurpose pretrained video diffusion models for 4D\nmodeling. 4DNeX produces high-quality dynamic point clouds that enable\nnovel-view video synthesis. Extensive experiments demonstrate that 4DNeX\noutperforms existing 4D generation methods in efficiency and generalizability,\noffering a scalable solution for image-to-4D modeling and laying the foundation\nfor generative 4D world models that simulate dynamic scene evolution.",
      "published_date": "2025-08-18",
      "content_hash": "0edea8c4f8b9e12643df714c181d4a2f",
      "api_data": {
        "authors": [
          "Zhaoxi Chen",
          "Tianqi Liu",
          "Long Zhuo",
          "Jiawei Ren",
          "Zeng Tao",
          "He Zhu",
          "Fangzhou Hong",
          "Liang Pan",
          "Ziwei Liu"
        ],
        "pdf_url": "http://arxiv.org/pdf/2508.13154v1",
        "journal_ref": null,
        "doi": null
      }
    },
    {
      "title": "RepreGuard: Detecting LLM-Generated Text by Revealing Hidden Representation Patterns",
      "link": "http://arxiv.org/abs/2508.13152v1",
      "source": "ArXiv AI Papers",
      "source_type": "arxiv",
      "category": "Research Papers",
      "summary": "Detecting content generated by large language models (LLMs) is crucial for\npreventing misuse and building trustworthy AI systems. Although existing\ndetection methods perform well, their robustness in out-of-distribution (OOD)\nscenarios is still lacking. In this paper, we hypothesize that, compared to\nfeatures used by existing detection methods, the internal representations of\nLLMs contain more comprehensive and raw features that can more effectively\ncapture and distinguish the statistical pattern differences between\nLLM-generated texts (LGT) and human-written texts (HWT). We validated this\nhypothesis across different LLMs and observed significant differences in neural\nactivation patterns when processing these two types of texts. Based on this, we\npropose RepreGuard, an efficient statistics-based detection method.\nSpecifically, we first employ a surrogate model to collect representation of\nLGT and HWT, and extract the distinct activation feature that can better\nidentify LGT. We can classify the text by calculating the projection score of\nthe text representations along this feature direction and comparing with a\nprecomputed threshold. Experimental results show that RepreGuard outperforms\nall baselines with average 94.92% AUROC on both in-distribution (ID) and OOD\nscenarios, while also demonstrating robust resilience to various text sizes and\nmainstream attacks. Data and code are publicly available at:\nhttps://github.com/NLP2CT/RepreGuard",
      "published_date": "2025-08-18",
      "content_hash": "00c15641e7b4a5f3cd530b6f0a2089b3",
      "api_data": {
        "authors": [
          "Xin Chen",
          "Junchao Wu",
          "Shu Yang",
          "Runzhe Zhan",
          "Zeyu Wu",
          "Ziyang Luo",
          "Di Wang",
          "Min Yang",
          "Lidia S. Chao",
          "Derek F. Wong"
        ],
        "pdf_url": "http://arxiv.org/pdf/2508.13152v1",
        "journal_ref": null,
        "doi": null
      }
    },
    {
      "title": "Manipulate-to-Navigate: Reinforcement Learning with Visual Affordances and Manipulability Priors",
      "link": "http://arxiv.org/abs/2508.13151v1",
      "source": "ArXiv AI Papers",
      "source_type": "arxiv",
      "category": "Research Papers",
      "summary": "Mobile manipulation in dynamic environments is challenging due to movable\nobstacles blocking the robot's path. Traditional methods, which treat\nnavigation and manipulation as separate tasks, often fail in such\n'manipulate-to-navigate' scenarios, as obstacles must be removed before\nnavigation. In these cases, active interaction with the environment is required\nto clear obstacles while ensuring sufficient space for movement. To address the\nmanipulate-to-navigate problem, we propose a reinforcement learning-based\napproach for learning manipulation actions that facilitate subsequent\nnavigation. Our method combines manipulability priors to focus the robot on\nhigh manipulability body positions with affordance maps for selecting\nhigh-quality manipulation actions. By focusing on feasible and meaningful\nactions, our approach reduces unnecessary exploration and allows the robot to\nlearn manipulation strategies more effectively. We present two new\nmanipulate-to-navigate simulation tasks called Reach and Door with the Boston\nDynamics Spot robot. The first task tests whether the robot can select a good\nhand position in the target area such that the robot base can move effectively\nforward while keeping the end effector position fixed. The second task requires\nthe robot to move a door aside in order to clear the navigation path. Both of\nthese tasks need first manipulation and then navigating the base forward.\nResults show that our method allows a robot to effectively interact with and\ntraverse dynamic environments. Finally, we transfer the learned policy to a\nreal Boston Dynamics Spot robot, which successfully performs the Reach task.",
      "published_date": "2025-08-18",
      "content_hash": "da6fa4307c1bc42148e44a8bcd10f00e",
      "api_data": {
        "authors": [
          "Yuying Zhang",
          "Joni Pajarinen"
        ],
        "pdf_url": "http://arxiv.org/pdf/2508.13151v1",
        "journal_ref": null,
        "doi": null
      }
    },
    {
      "title": "MDPO: Overcoming the Training-Inference Divide of Masked Diffusion Language Models",
      "link": "http://arxiv.org/abs/2508.13148v1",
      "source": "ArXiv AI Papers",
      "source_type": "arxiv",
      "category": "Research Papers",
      "summary": "Diffusion language models, as a promising alternative to traditional\nautoregressive (AR) models, enable faster generation and richer conditioning on\nbidirectional context. However, they suffer from a key discrepancy between\ntraining and inference: during inference, MDLMs progressively reveal the\nstructure of the generated sequence by producing fewer and fewer masked tokens,\nwhereas this structure is ignored in training as tokens are masked at random.\nAlthough this discrepancy between training and inference can lead to suboptimal\nperformance, it has been largely overlooked by previous works, leaving closing\nthis gap between the two stages an open problem. To address this, we frame the\nproblem of learning effective denoising trajectories as a sequential\ndecision-making problem and use the resulting framework to apply reinforcement\nlearning. We propose a novel Masked Diffusion Policy Optimization (MDPO) to\nexploit the Markov property diffusion possesses and explicitly train the model\nunder the same progressive refining schedule used at inference. MDPO matches\nthe performance of the previous state-of-the-art (SOTA) method with 60x fewer\ngradient updates, while achieving average improvements of 9.6% on MATH500 and\n54.2% on Countdown over SOTA when trained within the same number of weight\nupdates. Additionally, we improve the remasking strategy of MDLMs as a plug-in\ninference replacement to overcome the limitation that the model cannot refine\ntokens flexibly. This simple yet effective training-free strategy, what we\nrefer to as RCR, consistently improves performance and yields additional gains\nwhen combined with MDPO. Our findings establish great potential for\ninvestigating the discrepancy between pre-training and inference of MDLMs.\nCode: https://github.com/autonomousvision/mdpo. Project Page:\nhttps://cli212.github.io/MDPO/.",
      "published_date": "2025-08-18",
      "content_hash": "3e2e9f458a2f891268b0054d8cfb6849",
      "api_data": {
        "authors": [
          "Haoyu He",
          "Katrin Renz",
          "Yong Cao",
          "Andreas Geiger"
        ],
        "pdf_url": "http://arxiv.org/pdf/2508.13148v1",
        "journal_ref": null,
        "doi": null
      }
    },
    {
      "title": "Signal and Noise: A Framework for Reducing Uncertainty in Language Model Evaluation",
      "link": "http://arxiv.org/abs/2508.13144v1",
      "source": "ArXiv AI Papers",
      "source_type": "arxiv",
      "category": "Research Papers",
      "summary": "Developing large language models is expensive and involves making decisions\nwith small experiments, typically by evaluating on large, multi-task evaluation\nsuites. In this work, we analyze specific properties which make a benchmark\nmore reliable for such decisions, and interventions to design higher-quality\nevaluation benchmarks. We introduce two key metrics that show differences in\ncurrent benchmarks: signal, a benchmark's ability to separate better models\nfrom worse models, and noise, a benchmark's sensitivity to random variability\nbetween training steps. We demonstrate that benchmarks with a better\nsignal-to-noise ratio are more reliable when making decisions at small scale,\nand those with less noise have lower scaling law prediction error. These\nresults suggest that improving signal or noise will lead to more useful\nbenchmarks, so we introduce three interventions designed to directly affect\nsignal or noise. For example, we propose that switching to a metric that has\nbetter signal and noise (e.g., perplexity rather than accuracy) leads to better\nreliability and improved scaling law error. We also find that filtering noisy\nsubtasks, to improve an aggregate signal-to-noise ratio, leads to more reliable\nmulti-task evaluations. We also find that averaging the output of a model's\nintermediate checkpoints to reduce noise leads to consistent improvements. We\nconclude by recommending that those creating new benchmarks, or selecting which\nexisting benchmarks to use, aim for high signal and low noise. We use 30\nbenchmarks for these experiments, and 375 open-weight language models from 60M\nto 32B parameters, resulting in a new, publicly available dataset of 900K\nevaluation benchmark results, totaling 200M instances.",
      "published_date": "2025-08-18",
      "content_hash": "3536478fb7a2f0e89ac82efab27c5267",
      "api_data": {
        "authors": [
          "David Heineman",
          "Valentin Hofmann",
          "Ian Magnusson",
          "Yuling Gu",
          "Noah A. Smith",
          "Hannaneh Hajishirzi",
          "Kyle Lo",
          "Jesse Dodge"
        ],
        "pdf_url": "http://arxiv.org/pdf/2508.13144v1",
        "journal_ref": null,
        "doi": null
      }
    },
    {
      "title": "Exploring Autonomous Agents: A Closer Look at Why They Fail When Completing Tasks",
      "link": "http://arxiv.org/abs/2508.13143v1",
      "source": "ArXiv AI Papers",
      "source_type": "arxiv",
      "category": "Research Papers",
      "summary": "Autonomous agent systems powered by Large Language Models (LLMs) have\ndemonstrated promising capabilities in automating complex tasks. However,\ncurrent evaluations largely rely on success rates without systematically\nanalyzing the interactions, communication mechanisms, and failure causes within\nthese systems. To bridge this gap, we present a benchmark of 34 representative\nprogrammable tasks designed to rigorously assess autonomous agents. Using this\nbenchmark, we evaluate three popular open-source agent frameworks combined with\ntwo LLM backbones, observing a task completion rate of approximately 50%.\nThrough in-depth failure analysis, we develop a three-tier taxonomy of failure\ncauses aligned with task phases, highlighting planning errors, task execution\nissues, and incorrect response generation. Based on these insights, we propose\nactionable improvements to enhance agent planning and self-diagnosis\ncapabilities. Our failure taxonomy, together with mitigation advice, provides\nan empirical foundation for developing more robust and effective autonomous\nagent systems in the future.",
      "published_date": "2025-08-18",
      "content_hash": "eaf025b4d75bafacd932bf965dfb3239",
      "api_data": {
        "authors": [
          "Ruofan Lu",
          "Yichen Li",
          "Yintong Huo"
        ],
        "pdf_url": "http://arxiv.org/pdf/2508.13143v1",
        "journal_ref": null,
        "doi": null
      }
    },
    {
      "title": "Has GPT-5 Achieved Spatial Intelligence? An Empirical Study",
      "link": "http://arxiv.org/abs/2508.13142v1",
      "source": "ArXiv AI Papers",
      "source_type": "arxiv",
      "category": "Research Papers",
      "summary": "Multi-modal models have achieved remarkable progress in recent years.\nNevertheless, they continue to exhibit notable limitations in spatial\nunderstanding and reasoning, which are fundamental capabilities to achieving\nartificial general intelligence. With the recent release of GPT-5, allegedly\nthe most powerful AI model to date, it is timely to examine where the leading\nmodels stand on the path toward spatial intelligence. First, we propose a\ncomprehensive taxonomy of spatial tasks that unifies existing benchmarks and\ndiscuss the challenges in ensuring fair evaluation. We then evaluate\nstate-of-the-art proprietary and open-source models on eight key benchmarks, at\na cost exceeding one billion total tokens. Our empirical study reveals that (1)\nGPT-5 demonstrates unprecedented strength in spatial intelligence, yet (2)\nstill falls short of human performance across a broad spectrum of tasks.\nMoreover, we (3) identify the more challenging spatial intelligence problems\nfor multi-modal models, and (4) proprietary models do not exhibit a decisive\nadvantage when facing the most difficult problems. In addition, we conduct a\nqualitative evaluation across a diverse set of scenarios that are intuitive for\nhumans yet fail even the most advanced multi-modal models.",
      "published_date": "2025-08-18",
      "content_hash": "c07c15a12376eee6b58c92701ad9661e",
      "api_data": {
        "authors": [
          "Zhongang Cai",
          "Yubo Wang",
          "Qingping Sun",
          "Ruisi Wang",
          "Chenyang Gu",
          "Wanqi Yin",
          "Zhiqian Lin",
          "Zhitao Yang",
          "Chen Wei",
          "Xuanke Shi",
          "Kewang Deng",
          "Xiaoyang Han",
          "Zukai Chen",
          "Jiaqi Li",
          "Xiangyu Fan",
          "Hanming Deng",
          "Lewei Lu",
          "Bo Li",
          "Ziwei Liu",
          "Quan Wang",
          "Dahua Lin",
          "Lei Yang"
        ],
        "pdf_url": "http://arxiv.org/pdf/2508.13142v1",
        "journal_ref": null,
        "doi": null
      }
    },
    {
      "title": "OptimalThinkingBench: Evaluating Over and Underthinking in LLMs",
      "link": "http://arxiv.org/abs/2508.13141v1",
      "source": "ArXiv AI Papers",
      "source_type": "arxiv",
      "category": "Research Papers",
      "summary": "Thinking LLMs solve complex tasks at the expense of increased compute and\noverthinking on simpler problems, while non-thinking LLMs are faster and\ncheaper but underthink on harder reasoning problems. This has led to the\ndevelopment of separate thinking and non-thinking LLM variants, leaving the\nonus of selecting the optimal model for each query on the end user. In this\nwork, we introduce OptimalThinkingBench, a unified benchmark that jointly\nevaluates overthinking and underthinking in LLMs and also encourages the\ndevelopment of optimally-thinking models that balance performance and\nefficiency. Our benchmark comprises two sub-benchmarks: OverthinkingBench,\nfeaturing simple queries in 72 domains, and UnderthinkingBench, containing 11\nchallenging reasoning tasks. Using novel thinking-adjusted accuracy metrics, we\nperform extensive evaluation of 33 different thinking and non-thinking models\nand show that no model is able to optimally think on our benchmark. Thinking\nmodels often overthink for hundreds of tokens on the simplest user queries\nwithout improving performance. In contrast, large non-thinking models\nunderthink, often falling short of much smaller thinking models. We further\nexplore several methods to encourage optimal thinking, but find that these\napproaches often improve on one sub-benchmark at the expense of the other,\nhighlighting the need for better unified and optimal models in the future.",
      "published_date": "2025-08-18",
      "content_hash": "f6378ea31ad629101fdbc7e9f2b66efa",
      "api_data": {
        "authors": [
          "Pranjal Aggarwal",
          "Seungone Kim",
          "Jack Lanchantin",
          "Sean Welleck",
          "Jason Weston",
          "Ilia Kulikov",
          "Swarnadeep Saha"
        ],
        "pdf_url": "http://arxiv.org/pdf/2508.13141v1",
        "journal_ref": null,
        "doi": null
      }
    },
    {
      "title": "Human Digital Twin: Data, Models, Applications, and Challenges",
      "link": "http://arxiv.org/abs/2508.13138v1",
      "source": "ArXiv AI Papers",
      "source_type": "arxiv",
      "category": "Research Papers",
      "summary": "Human digital twins (HDTs) are dynamic, data-driven virtual representations\nof individuals, continuously updated with multimodal data to simulate, monitor,\nand predict health trajectories. By integrating clinical, physiological,\nbehavioral, and environmental inputs, HDTs enable personalized diagnostics,\ntreatment planning, and anomaly detection. This paper reviews current\napproaches to HDT modeling, with a focus on statistical and machine learning\ntechniques, including recent advances in anomaly detection and failure\nprediction. It also discusses data integration, computational methods, and\nethical, technological, and regulatory challenges in deploying HDTs for\nprecision healthcare.",
      "published_date": "2025-08-18",
      "content_hash": "5b31b8c3d75f2d1e125be4af552658b2",
      "api_data": {
        "authors": [
          "Rong Pan",
          "Hongyue Sun",
          "Xiaoyu Chen",
          "Giulia Pedrielli",
          "Jiapeng Huang"
        ],
        "pdf_url": "http://arxiv.org/pdf/2508.13138v1",
        "journal_ref": null,
        "doi": null
      }
    },
    {
      "title": "Training Machine Learning Models on Human Spatio-temporal Mobility Data: An Experimental Study [Experiment Paper]",
      "link": "http://arxiv.org/abs/2508.13135v1",
      "source": "ArXiv AI Papers",
      "source_type": "arxiv",
      "category": "Research Papers",
      "summary": "Individual-level human mobility prediction has emerged as a significant topic\nof research with applications in infectious disease monitoring, child, and\nelderly care. Existing studies predominantly focus on the microscopic aspects\nof human trajectories: such as predicting short-term trajectories or the next\nlocation visited, while offering limited attention to macro-level mobility\npatterns and the corresponding life routines. In this paper, we focus on an\nunderexplored problem in human mobility prediction: determining the best\npractices to train a machine learning model using historical data to forecast\nan individuals complete trajectory over the next days and weeks. In this\nexperiment paper, we undertake a comprehensive experimental analysis of diverse\nmodels, parameter configurations, and training strategies, accompanied by an\nin-depth examination of the statistical distribution inherent in human mobility\npatterns. Our empirical evaluations encompass both Long Short-Term Memory and\nTransformer-based architectures, and further investigate how incorporating\nindividual life patterns can enhance the effectiveness of the prediction. We\nshow that explicitly including semantic information such as day-of-the-week and\nuser-specific historical information can help the model better understand\nindividual patterns of life and improve predictions. Moreover, since the\nabsence of explicit user information is often missing due to user privacy, we\nshow that the sampling of users may exacerbate data skewness and result in a\nsubstantial loss in predictive accuracy. To mitigate data imbalance and\npreserve diversity, we apply user semantic clustering with stratified sampling\nto ensure that the sampled dataset remains representative. Our results further\nshow that small-batch stochastic gradient optimization improves model\nperformance, especially when human mobility training data is limited.",
      "published_date": "2025-08-18",
      "content_hash": "90de28ef238d38206e00e931b9dc32b9",
      "api_data": {
        "authors": [
          "Yueyang Liu",
          "Lance Kennedy",
          "Ruochen Kong",
          "Joon-Seok Kim",
          "Andreas Züfle"
        ],
        "pdf_url": "http://arxiv.org/pdf/2508.13135v1",
        "journal_ref": null,
        "doi": null
      }
    },
    {
      "title": "Improving Detection of Watermarked Language Models",
      "link": "http://arxiv.org/abs/2508.13131v1",
      "source": "ArXiv AI Papers",
      "source_type": "arxiv",
      "category": "Research Papers",
      "summary": "Watermarking has recently emerged as an effective strategy for detecting the\ngenerations of large language models (LLMs). The strength of a watermark\ntypically depends strongly on the entropy afforded by the language model and\nthe set of input prompts. However, entropy can be quite limited in practice,\nespecially for models that are post-trained, for example via instruction tuning\nor reinforcement learning from human feedback (RLHF), which makes detection\nbased on watermarking alone challenging. In this work, we investigate whether\ndetection can be improved by combining watermark detectors with non-watermark\nones. We explore a number of hybrid schemes that combine the two, observing\nperformance gains over either class of detector under a wide range of\nexperimental conditions.",
      "published_date": "2025-08-18",
      "content_hash": "7295fdcb0b9c92d58bf24e39291fd64b",
      "api_data": {
        "authors": [
          "Dara Bahri",
          "John Wieting"
        ],
        "pdf_url": "http://arxiv.org/pdf/2508.13131v1",
        "journal_ref": null,
        "doi": null
      }
    },
    {
      "title": "Spot the BlindSpots: Systematic Identification and Quantification of Fine-Grained LLM Biases in Contact Center Summaries",
      "link": "http://arxiv.org/abs/2508.13124v1",
      "source": "ArXiv AI Papers",
      "source_type": "arxiv",
      "category": "Research Papers",
      "summary": "Abstractive summarization is a core application in contact centers, where\nLarge Language Models (LLMs) generate millions of summaries of call transcripts\ndaily. Despite their apparent quality, it remains unclear whether LLMs\nsystematically under- or over-attend to specific aspects of the transcript,\npotentially introducing biases in the generated summary. While prior work has\nexamined social and positional biases, the specific forms of bias pertinent to\ncontact center operations - which we term Operational Bias - have remained\nunexplored. To address this gap, we introduce BlindSpot, a framework built upon\na taxonomy of 15 operational bias dimensions (e.g., disfluency, speaker, topic)\nfor the identification and quantification of these biases. BlindSpot leverages\nan LLM as a zero-shot classifier to derive categorical distributions for each\nbias dimension in a pair of transcript and its summary. The bias is then\nquantified using two metrics: Fidelity Gap (the JS Divergence between\ndistributions) and Coverage (the percentage of source labels omitted). Using\nBlindSpot, we conducted an empirical study with 2500 real call transcripts and\ntheir summaries generated by 20 LLMs of varying scales and families (e.g., GPT,\nLlama, Claude). Our analysis reveals that biases are systemic and present\nacross all evaluated models, regardless of size or family.",
      "published_date": "2025-08-18",
      "content_hash": "4ec43223f7ebff6725b2293395cfeaa1",
      "api_data": {
        "authors": [
          "Kawin Mayilvaghanan",
          "Siddhant Gupta",
          "Ayush Kumar"
        ],
        "pdf_url": "http://arxiv.org/pdf/2508.13124v1",
        "journal_ref": null,
        "doi": null
      }
    },
    {
      "title": "Bayesian Optimization-based Search for Agent Control in Automated Game Testing",
      "link": "http://arxiv.org/abs/2508.13121v1",
      "source": "ArXiv AI Papers",
      "source_type": "arxiv",
      "category": "Research Papers",
      "summary": "This work introduces an automated testing approach that employs agents\ncontrolling game characters to detect potential bugs within a game level.\nHarnessing the power of Bayesian Optimization (BO) to execute sample-efficient\nsearch, the method determines the next sampling point by analyzing the data\ncollected so far and calculates the data point that will maximize information\nacquisition. To support the BO process, we introduce a game testing-specific\nmodel built on top of a grid map, that features the smoothness and uncertainty\nestimation required by BO, however and most importantly, it does not suffer the\nscalability issues that traditional models carry. The experiments demonstrate\nthat the approach significantly improves map coverage capabilities in both time\nefficiency and exploration distribution.",
      "published_date": "2025-08-18",
      "content_hash": "2b3c804ea31bc062e3284539bf81ebc0",
      "api_data": {
        "authors": [
          "Carlos Celemin"
        ],
        "pdf_url": "http://arxiv.org/pdf/2508.13121v1",
        "journal_ref": "2024 IEEE Conference on Games (CoG), Milan, Italy, 2024, pp. 1-4",
        "doi": "10.1109/CoG60054.2024.10645653"
      }
    },
    {
      "title": "Choosing the Right Engine in the Virtual Reality Landscape",
      "link": "http://arxiv.org/abs/2508.13116v1",
      "source": "ArXiv AI Papers",
      "source_type": "arxiv",
      "category": "Research Papers",
      "summary": "Virtual reality (VR) development relies on game engines to provide real-time\nrendering, physics simulation, and interaction systems. Among the most widely\nused game engines, Unreal Engine and Unity dominate the industry, offering\ndistinct advantages in graphics rendering, performance optimization, usability,\nresource requirements, and scalability. This study presents a comprehensive\ncomparative analysis of both engines, evaluating their capabilities and\ntrade-offs through empirical assessments and real-world case studies of\nlarge-scale VR projects. The findings highlight key factors such as rendering\nfidelity, computational efficiency, cross-platform compatibility, and\ndevelopment workflows. These provide practical insights for selecting the most\nsuitable engine based on project-specific needs. Furthermore, emerging trends\nin artificial intelligence (AI)-driven enhancements, including Deep Learning\nSuper Sampling (DLSS) and large language models (LLMs), are explored to assess\ntheir impact on VR development workflows. By aligning engine capabilities with\ntechnical and creative requirements, developers can overcome performance\nbottlenecks, enhance immersion, and streamline optimization techniques.\n  This study serves as a valuable resource for VR developers, researchers, and\nindustry professionals, offering data-driven recommendations to navigate the\nevolving landscape of VR technology.",
      "published_date": "2025-08-18",
      "content_hash": "2dabaf0bde76dede7c7b27ad27102f41",
      "api_data": {
        "authors": [
          "Santiago Berrezueta-Guzman",
          "Stefan Wagner"
        ],
        "pdf_url": "http://arxiv.org/pdf/2508.13116v1",
        "journal_ref": null,
        "doi": null
      }
    },
    {
      "title": "Contrastive Representations for Temporal Reasoning",
      "link": "http://arxiv.org/abs/2508.13113v1",
      "source": "ArXiv AI Papers",
      "source_type": "arxiv",
      "category": "Research Papers",
      "summary": "In classical AI, perception relies on learning state-based representations,\nwhile planning, which can be thought of as temporal reasoning over action\nsequences, is typically achieved through search. We study whether such\nreasoning can instead emerge from representations that capture both perceptual\nand temporal structure. We show that standard temporal contrastive learning,\ndespite its popularity, often fails to capture temporal structure due to its\nreliance on spurious features. To address this, we introduce Combinatorial\nRepresentations for Temporal Reasoning (CRTR), a method that uses a negative\nsampling scheme to provably remove these spurious features and facilitate\ntemporal reasoning. CRTR achieves strong results on domains with complex\ntemporal structure, such as Sokoban and Rubik's Cube. In particular, for the\nRubik's Cube, CRTR learns representations that generalize across all initial\nstates and allow it to solve the puzzle using fewer search steps than BestFS,\nthough with longer solutions. To our knowledge, this is the first method that\nefficiently solves arbitrary Cube states using only learned representations,\nwithout relying on an external search algorithm.",
      "published_date": "2025-08-18",
      "content_hash": "dd48e3aa2500bc0fa5c790a213a37985",
      "api_data": {
        "authors": [
          "Alicja Ziarko",
          "Michal Bortkiewicz",
          "Michal Zawalski",
          "Benjamin Eysenbach",
          "Piotr Milos"
        ],
        "pdf_url": "http://arxiv.org/pdf/2508.13113v1",
        "journal_ref": null,
        "doi": null
      }
    },
    {
      "title": "Causally-Guided Pairwise Transformer -- Towards Foundational Digital Twins in Process Industry",
      "link": "http://arxiv.org/abs/2508.13111v1",
      "source": "ArXiv AI Papers",
      "source_type": "arxiv",
      "category": "Research Papers",
      "summary": "Foundational modelling of multi-dimensional time-series data in industrial\nsystems presents a central trade-off: channel-dependent (CD) models capture\nspecific cross-variable dynamics but lack robustness and adaptability as model\nlayers are commonly bound to the data dimensionality of the tackled use-case,\nwhile channel-independent (CI) models offer generality at the cost of modelling\nthe explicit interactions crucial for system-level predictive regression tasks.\nTo resolve this, we propose the Causally-Guided Pairwise Transformer (CGPT), a\nnovel architecture that integrates a known causal graph as an inductive bias.\nThe core of CGPT is built around a pairwise modeling paradigm, tackling the\nCD/CI conflict by decomposing the multidimensional data into pairs. The model\nuses channel-agnostic learnable layers where all parameter dimensions are\nindependent of the number of variables. CGPT enforces a CD information flow at\nthe pair-level and CI-like generalization across pairs. This approach\ndisentangles complex system dynamics and results in a highly flexible\narchitecture that ensures scalability and any-variate adaptability. We validate\nCGPT on a suite of synthetic and real-world industrial datasets on long-term\nand one-step forecasting tasks designed to simulate common industrial\ncomplexities. Results demonstrate that CGPT significantly outperforms both CI\nand CD baselines in predictive accuracy and shows competitive performance with\nend-to-end trained CD models while remaining agnostic to the problem\ndimensionality.",
      "published_date": "2025-08-18",
      "content_hash": "6ab8c63b288569da9c8b0a0768660cf5",
      "api_data": {
        "authors": [
          "Michael Mayr",
          "Georgios C. Chasparis"
        ],
        "pdf_url": "http://arxiv.org/pdf/2508.13111v1",
        "journal_ref": null,
        "doi": null
      }
    },
    {
      "title": "Precise Action-to-Video Generation Through Visual Action Prompts",
      "link": "http://arxiv.org/abs/2508.13104v1",
      "source": "ArXiv AI Papers",
      "source_type": "arxiv",
      "category": "Research Papers",
      "summary": "We present visual action prompts, a unified action representation for\naction-to-video generation of complex high-DoF interactions while maintaining\ntransferable visual dynamics across domains. Action-driven video generation\nfaces a precision-generality trade-off: existing methods using text, primitive\nactions, or coarse masks offer generality but lack precision, while\nagent-centric action signals provide precision at the cost of cross-domain\ntransferability. To balance action precision and dynamic transferability, we\npropose to \"render\" actions into precise visual prompts as domain-agnostic\nrepresentations that preserve both geometric precision and cross-domain\nadaptability for complex actions; specifically, we choose visual skeletons for\ntheir generality and accessibility. We propose robust pipelines to construct\nskeletons from two interaction-rich data sources - human-object interactions\n(HOI) and dexterous robotic manipulation - enabling cross-domain training of\naction-driven generative models. By integrating visual skeletons into\npretrained video generation models via lightweight fine-tuning, we enable\nprecise action control of complex interaction while preserving the learning of\ncross-domain dynamics. Experiments on EgoVid, RT-1 and DROID demonstrate the\neffectiveness of our proposed approach. Project page:\nhttps://zju3dv.github.io/VAP/.",
      "published_date": "2025-08-18",
      "content_hash": "34892a952ffbaf6400d1d61d862cde3f",
      "api_data": {
        "authors": [
          "Yuang Wang",
          "Chao Wen",
          "Haoyu Guo",
          "Sida Peng",
          "Minghan Qin",
          "Hujun Bao",
          "Xiaowei Zhou",
          "Ruizhen Hu"
        ],
        "pdf_url": "http://arxiv.org/pdf/2508.13104v1",
        "journal_ref": null,
        "doi": null
      }
    },
    {
      "title": "A Perfectly Truthful Calibration Measure",
      "link": "http://arxiv.org/abs/2508.13100v1",
      "source": "ArXiv AI Papers",
      "source_type": "arxiv",
      "category": "Research Papers",
      "summary": "Calibration requires that predictions are conditionally unbiased and,\ntherefore, reliably interpretable as probabilities. Calibration measures\nquantify how far a predictor is from perfect calibration. As introduced by\nHaghtalab et al. (2024), a calibration measure is truthful if it is minimized\nin expectation when a predictor outputs the ground-truth probabilities.\nAlthough predicting the true probabilities guarantees perfect calibration, in\nreality, when calibration is evaluated on a finite sample, predicting the truth\nis not guaranteed to minimize any known calibration measure. All known\ncalibration measures incentivize predictors to lie in order to appear more\ncalibrated on a finite sample. Such lack of truthfulness motivated Haghtalab et\nal. (2024) and Qiao and Zhao (2025) to construct approximately truthful\ncalibration measures in the sequential prediction setting, but no perfectly\ntruthful calibration measure was known to exist even in the more basic batch\nsetting.\n  We design a perfectly truthful calibration measure in the batch setting:\naveraged two-bin calibration error (ATB). In addition to being truthful, ATB is\nsound, complete, continuous, and quadratically related to two existing\ncalibration measures: the smooth calibration error (smCal) and the (lower)\ndistance to calibration (distCal). The simplicity in our definition of ATB\nmakes it efficient and straightforward to compute. ATB allows faster estimation\nalgorithms with significantly easier implementations than smCal and distCal,\nachieving improved running time and simplicity for the calibration testing\nproblem studied by Hu et al. (2024). We also introduce a general recipe for\nconstructing truthful measures, which proves the truthfulness of ATB as a\nspecial case and allows us to construct other truthful calibration measures\nsuch as quantile-binned l_2-ECE.",
      "published_date": "2025-08-18",
      "content_hash": "366e27be3779bdb81263c7d2374904e4",
      "api_data": {
        "authors": [
          "Jason Hartline",
          "Lunjia Hu",
          "Yifan Wu"
        ],
        "pdf_url": "http://arxiv.org/pdf/2508.13100v1",
        "journal_ref": null,
        "doi": null
      }
    },
    {
      "title": "Outlier Detection of Poisson-Distributed Targets Using a Seabed Sensor Network",
      "link": "http://arxiv.org/abs/2508.13099v1",
      "source": "ArXiv AI Papers",
      "source_type": "arxiv",
      "category": "Research Papers",
      "summary": "This paper presents a framework for classifying and detecting spatial\ncommission outliers in maritime environments using seabed acoustic sensor\nnetworks and log Gaussian Cox processes (LGCPs). By modeling target arrivals as\na mixture of normal and outlier processes, we estimate the probability that a\nnewly observed event is an outlier. We propose a second-order approximation of\nthis probability that incorporates both the mean and variance of the normal\nintensity function, providing improved classification accuracy compared to\nmean-only approaches. We analytically show that our method yields a tighter\nbound to the true probability using Jensen's inequality. To enhance detection,\nwe integrate a real-time, near-optimal sensor placement strategy that\ndynamically adjusts sensor locations based on the evolving outlier intensity.\nThe proposed framework is validated using real ship traffic data near Norfolk,\nVirginia, where numerical results demonstrate the effectiveness of our approach\nin improving both classification performance and outlier detection through\nsensor deployment.",
      "published_date": "2025-08-18",
      "content_hash": "539256fcc823884556f602b749c20944",
      "api_data": {
        "authors": [
          "Mingyu Kim",
          "Daniel Stilwell",
          "Jorge Jimenez"
        ],
        "pdf_url": "http://arxiv.org/pdf/2508.13099v1",
        "journal_ref": null,
        "doi": null
      }
    },
    {
      "title": "Denoising diffusion models for inverse design of inflatable structures with programmable deformations",
      "link": "http://arxiv.org/abs/2508.13097v1",
      "source": "ArXiv AI Papers",
      "source_type": "arxiv",
      "category": "Research Papers",
      "summary": "Programmable structures are systems whose undeformed geometries and material\nproperty distributions are deliberately designed to achieve prescribed deformed\nconfigurations under specific loading conditions. Inflatable structures are a\nprominent example, using internal pressurization to realize large, nonlinear\ndeformations in applications ranging from soft robotics and deployable\naerospace systems to biomedical devices and adaptive architecture. We present a\ngenerative design framework based on denoising diffusion probabilistic models\n(DDPMs) for the inverse design of elastic structures undergoing large,\nnonlinear deformations under pressure-driven actuation. The method formulates\nthe inverse design as a conditional generation task, using geometric\ndescriptors of target deformed states as inputs and outputting image-based\nrepresentations of the undeformed configuration. Representing these\nconfigurations as simple images is achieved by establishing a pre- and\npostprocessing pipeline that involves a fixed image processing, simulation\nsetup, and descriptor extraction methods. Numerical experiments with scalar and\nhigher-dimensional descriptors show that the framework can quickly produce\ndiverse undeformed configurations that achieve the desired deformations when\ninflated, enabling parallel exploration of viable design candidates while\naccommodating complex constraints.",
      "published_date": "2025-08-18",
      "content_hash": "1545c707e4e0f58502ffbb7a77e622e7",
      "api_data": {
        "authors": [
          "Sara Karimi",
          "Nikolaos N. Vlassis"
        ],
        "pdf_url": "http://arxiv.org/pdf/2508.13097v1",
        "journal_ref": null,
        "doi": null
      }
    },
    {
      "title": "IGFuse: Interactive 3D Gaussian Scene Reconstruction via Multi-Scans Fusion",
      "link": "http://arxiv.org/abs/2508.13153v1",
      "source": "ArXiv Computer Vision",
      "source_type": "arxiv",
      "category": "Computer Vision",
      "summary": "Reconstructing complete and interactive 3D scenes remains a fundamental\nchallenge in computer vision and robotics, particularly due to persistent\nobject occlusions and limited sensor coverage. Multiview observations from a\nsingle scene scan often fail to capture the full structural details. Existing\napproaches typically rely on multi stage pipelines, such as segmentation,\nbackground completion, and inpainting or require per-object dense scanning,\nboth of which are error-prone, and not easily scalable. We propose IGFuse, a\nnovel framework that reconstructs interactive Gaussian scene by fusing\nobservations from multiple scans, where natural object rearrangement between\ncaptures reveal previously occluded regions. Our method constructs segmentation\naware Gaussian fields and enforces bi-directional photometric and semantic\nconsistency across scans. To handle spatial misalignments, we introduce a\npseudo-intermediate scene state for unified alignment, alongside collaborative\nco-pruning strategies to refine geometry. IGFuse enables high fidelity\nrendering and object level scene manipulation without dense observations or\ncomplex pipelines. Extensive experiments validate the framework's strong\ngeneralization to novel scene configurations, demonstrating its effectiveness\nfor real world 3D reconstruction and real-to-simulation transfer. Our project\npage is available online.",
      "published_date": "2025-08-18",
      "content_hash": "816a7dd277c711cba325a8094e83061b",
      "api_data": {
        "authors": [
          "Wenhao Hu",
          "Zesheng Li",
          "Haonan Zhou",
          "Liu Liu",
          "Xuexiang Wen",
          "Zhizhong Su",
          "Xi Li",
          "Gaoang Wang"
        ],
        "pdf_url": "http://arxiv.org/pdf/2508.13153v1",
        "journal_ref": null,
        "doi": null
      }
    },
    {
      "title": "Driven-Dissipative Interpretation of Measurement-Induced State Transitions Beyond Semiclassical Predictions",
      "link": "http://arxiv.org/abs/2508.13150v1",
      "source": "ArXiv Computer Vision",
      "source_type": "arxiv",
      "category": "Computer Vision",
      "summary": "Dispersive readout plays a central role in superconducting quantum computing,\nenabling quantum nondemolition (QND) measurements of qubits through a coupled\nmicrowave resonator. However, under strong readout drives, multi-photon\nresonances can cause measurement-induced state transition (MIST), resulting in\nqubit leakage out of the computational subspace and compromising the QND\ncharacter. We present a driven-dissipative interpretation of MIST using a\nreduced quantum model that captures the dynamics and entanglement structure\nunderlying the breakdown of QND measurement, a feature inaccessible to previous\nsemiclassical treatments. A super-MIST regime under strong drive is uncovered,\ncharacterized by steady-state qubit inversion and slow relaxation beyond the\nsemiclassical Landau-Zener predictions. We further identify a transient readout\ncondition in which the resonator becomes highly populated while the qubit\nremains near its original state. These results are broadly applicable to\nsuperconducting qubits such as fluxonium and transmon, unveil the\nnonequilibrium dynamics of MIST, and highlight strongly driven regimes that can\nbe leveraged for measurement optimization.",
      "published_date": "2025-08-18",
      "content_hash": "567ce077258a667e2a66ead905f327cf",
      "api_data": {
        "authors": [
          "Bo-Syun Pan",
          "Yen-Hsiang Lin",
          "Chiao-Hsuan Wang"
        ],
        "pdf_url": "http://arxiv.org/pdf/2508.13150v1",
        "journal_ref": null,
        "doi": null
      }
    },
    {
      "title": "Motion2Motion: Cross-topology Motion Transfer with Sparse Correspondence",
      "link": "http://arxiv.org/abs/2508.13139v1",
      "source": "ArXiv Computer Vision",
      "source_type": "arxiv",
      "category": "Computer Vision",
      "summary": "This work studies the challenge of transfer animations between characters\nwhose skeletal topologies differ substantially. While many techniques have\nadvanced retargeting techniques in decades, transfer motions across diverse\ntopologies remains less-explored. The primary obstacle lies in the inherent\ntopological inconsistency between source and target skeletons, which restricts\nthe establishment of straightforward one-to-one bone correspondences. Besides,\nthe current lack of large-scale paired motion datasets spanning different\ntopological structures severely constrains the development of data-driven\napproaches. To address these limitations, we introduce Motion2Motion, a novel,\ntraining-free framework. Simply yet effectively, Motion2Motion works with only\none or a few example motions on the target skeleton, by accessing a sparse set\nof bone correspondences between the source and target skeletons. Through\ncomprehensive qualitative and quantitative evaluations, we demonstrate that\nMotion2Motion achieves efficient and reliable performance in both\nsimilar-skeleton and cross-species skeleton transfer scenarios. The practical\nutility of our approach is further evidenced by its successful integration in\ndownstream applications and user interfaces, highlighting its potential for\nindustrial applications. Code and data are available at\nhttps://lhchen.top/Motion2Motion.",
      "published_date": "2025-08-18",
      "content_hash": "f72eb37d688434ff20bc98cbc8abf948",
      "api_data": {
        "authors": [
          "Ling-Hao Chen",
          "Yuhong Zhang",
          "Zixin Yin",
          "Zhiyang Dou",
          "Xin Chen",
          "Jingbo Wang",
          "Taku Komura",
          "Lei Zhang"
        ],
        "pdf_url": "http://arxiv.org/pdf/2508.13139v1",
        "journal_ref": null,
        "doi": null
      }
    },
    {
      "title": "The ALPINE-CRISTAL-JWST survey: spatially resolved star formation relations at $z\\sim5$",
      "link": "http://arxiv.org/abs/2508.13136v1",
      "source": "ArXiv Computer Vision",
      "source_type": "arxiv",
      "category": "Computer Vision",
      "summary": "Star formation governs galaxy evolution, shaping stellar mass assembly and\ngas consumption across cosmic time. The Kennicutt-Schmidt (KS) relation,\nlinking star formation rate (SFR) and gas surface densities, is fundamental to\nunderstand star formation regulation, yet remains poorly constrained at $z > 2$\ndue to observational limitations and uncertainties in locally calibrated gas\ntracers. The [CII] $158 {\\rm \\mu m}$ line has recently emerged as a key probe\nof the cold ISM and star formation in the early Universe. We investigate\nwhether the resolved [CII]-SFR and KS relations established at low redshift\nremain valid at $4 < z < 6$ by analysing 13 main-sequence galaxies from the\nALPINE and CRISTAL surveys, using multi-wavelength data (HST, JWST, ALMA) at\n$\\sim2$ kpc resolution. We perform pixel-by-pixel spectral energy distribution\n(SED) modelling with CIGALE on resolution-homogenised images. We develop a\nstatistical framework to fit the [CII]-SFR relation that accounts for pixel\ncovariance and compare our results to classical fitting methods. We test two\n[CII]-to-gas conversion prescriptions to assess their impact on inferred gas\nsurface densities and depletion times. We find a resolved [CII]-SFR relation\nwith a slope of $0.87 \\pm 0.15$ and intrinsic scatter of $0.19 \\pm 0.03$ dex,\nwhich is shallower and tighter than previous studies at $z\\sim5$. The resolved\nKS relation is highly sensitive to the [CII]-to-gas conversion factor: using a\nfixed global $\\alpha_{\\rm [CII]}$ yields depletion times of $0.5$-$1$ Gyr,\nwhile a surface brightness-dependent $W_{\\rm [CII]}$, places some galaxies with\nhigh gas density in the starburst regime ($<0.1$ Gyr). Future inputs from both\nsimulations and observations are required to better understand how the\n[CII]-to-gas conversion factor depends on local ISM properties. We need to\nbreak this fundamental limit to properly study the KS relation at $z\\gtrsim4$.",
      "published_date": "2025-08-18",
      "content_hash": "98dbecd3f1af26cff8f08acd26c17941",
      "api_data": {
        "authors": [
          "C. Accard",
          "M. Béthermin",
          "M. Boquien",
          "V. Buat",
          "L. Vallini",
          "F. Renaud",
          "K. Kraljic",
          "M. Aravena",
          "P. Cassata",
          "E. da Cunha",
          "P. Dam",
          "I. de Looze",
          "M. Dessauges-Zavadsky",
          "Y. Dubois",
          "A. Faisst",
          "Y. Fudamoto",
          "M. Ginolfi",
          "C. Gruppioni",
          "S. Han",
          "R. Herrera-Camus",
          "H. Inami",
          "A. M. Koekemoer",
          "B. C. Lemaux",
          "J. Li",
          "Y. Li",
          "B. Mobasher",
          "J. Molina",
          "A. Nanni",
          "M. Palla",
          "F. Pozzi",
          "M. Relaño",
          "M. Romano",
          "P. Sawant",
          "J. Spilker",
          "A. Tsujita",
          "E. Veraldi",
          "V. Villanueva",
          "W. Wang",
          "S. K. Yi",
          "G. Zamorani"
        ],
        "pdf_url": "http://arxiv.org/pdf/2508.13136v1",
        "journal_ref": null,
        "doi": null
      }
    },
    {
      "title": "MuDRiC: Multi-Dialect Reasoning for Arabic Commonsense Validation",
      "link": "http://arxiv.org/abs/2508.13130v1",
      "source": "ArXiv Computer Vision",
      "source_type": "arxiv",
      "category": "Computer Vision",
      "summary": "Commonsense validation evaluates whether a sentence aligns with everyday\nhuman understanding, a critical capability for developing robust natural\nlanguage understanding systems. While substantial progress has been made in\nEnglish, the task remains underexplored in Arabic, particularly given its rich\nlinguistic diversity. Existing Arabic resources have primarily focused on\nModern Standard Arabic (MSA), leaving regional dialects underrepresented\ndespite their prevalence in spoken contexts. To bridge this gap, we present two\nkey contributions: (i) we introduce MuDRiC, an extended Arabic commonsense\ndataset incorporating multiple dialects, and (ii) a novel method adapting Graph\nConvolutional Networks (GCNs) to Arabic commonsense reasoning, which enhances\nsemantic relationship modeling for improved commonsense validation. Our\nexperimental results demonstrate that this approach achieves superior\nperformance in Arabic commonsense validation. Our work enhances Arabic natural\nlanguage understanding by providing both a foundational dataset and a novel\nmethod for handling its complex variations. To the best of our knowledge, we\nrelease the first Arabic multi-dialect commonsense reasoning dataset.",
      "published_date": "2025-08-18",
      "content_hash": "aa8e6747dca48eba2bd9eb3a6d7b5669",
      "api_data": {
        "authors": [
          "Kareem Elozeiri",
          "Mervat Abassy",
          "Preslav Nakov",
          "Yuxia Wang"
        ],
        "pdf_url": "http://arxiv.org/pdf/2508.13130v1",
        "journal_ref": null,
        "doi": null
      }
    },
    {
      "title": "Modeling wind farm noise emission and propagation: effects of flow layout",
      "link": "http://arxiv.org/abs/2508.13128v1",
      "source": "ArXiv Computer Vision",
      "source_type": "arxiv",
      "category": "Computer Vision",
      "summary": "This study demonstrates how wind farm flow physics influence noise generation\nand downstream propagation through numerical simulations. The flow field is\nmodeled using large-eddy simulations (LES), and the time-averaged output serves\nas input to acoustic models that predict wind turbine noise. In the first\nturbine row, turbulence-induced noise (TIN) and trailing edge noise (TEN)\ncontribute equally, with TIN dominating at low frequencies and TEN at higher\nfrequencies. Downstream, TEN decreases due to lower wind speeds, while TIN\nmostly persists due to increased turbulence dissipation. These effects are more\npronounced in aligned wind farms, where stronger wake interactions occur, than\nin staggered layouts. However, staggered farms produce more noise overall\nbecause turbines operate at higher wind speeds.Additionally, wind farm flow\nsignificantly affects sound propagation downwind. The wake superposition\nmodifies sound focusing leading to different amplification area than for an\nisolated turbine. For a staggered layout it particularly shows enhanced sound\nfocusing downwind due to the position of the turbine wakes. This leads to\nhigher sound levels and higher amplitude modulation downwind for the wind farm\ncompared to an aligned layout. These phenomena are not captured by models based\non isolated turbines. These findings underscore the importance of integrating\nflow and acoustic models to more accurately assess the environmental impact of\nwind farms.",
      "published_date": "2025-08-18",
      "content_hash": "16abff34a15b60c311523ad2e7a377ca",
      "api_data": {
        "authors": [
          "J. Colas",
          "A. Emmanuelli",
          "D. Dragna",
          "R. J. A. M. Stevens"
        ],
        "pdf_url": "http://arxiv.org/pdf/2508.13128v1",
        "journal_ref": null,
        "doi": null
      }
    },
    {
      "title": "Mastering Cosmological Amplitudes Using Generalized Ramanujan's Theorem",
      "link": "http://arxiv.org/abs/2508.13126v1",
      "source": "ArXiv Computer Vision",
      "source_type": "arxiv",
      "category": "Computer Vision",
      "summary": "We present a systematic method for computing cosmological amplitudes,\nincluding in-in correlators and wavefunction coefficients, in FRW spacetime.\nSpecializing to cases with conformally-coupled external scalars and massive\nscalar exchanges, we introduce a decomposition into massive family trees, which\ncapture the nested time structure common to these observables. We then evaluate\nthese building blocks using the Method of Brackets (MoB), a multivariate\nextension of Ramanujan's master theorem that operates directly on the\nintegrand, translating integrals into discrete summations via a compact set of\nalgebraic rules. This yields infinite series representations valid across the\nfull space of external momenta and internal energies. We also develop\nFeynman-like diagrammatic rules that map interaction graphs to summand\nstructures, enabling efficient and scalable computation. The resulting\nexpressions make time evolution manifest, smoothly interpolate to the conformal\nlimit, and are well suited for both numerical evaluation and analytic analysis\nof massive field effects in cosmology.",
      "published_date": "2025-08-18",
      "content_hash": "b7c3a4bf462b1e9cf21e8ee0d2bbd808",
      "api_data": {
        "authors": [
          "Prashanth Raman",
          "Qinglin Yang"
        ],
        "pdf_url": "http://arxiv.org/pdf/2508.13126v1",
        "journal_ref": null,
        "doi": null
      }
    },
    {
      "title": "Strain-induced Ettingshausen effect in spin-orbit coupled noncentrosymmetric metals",
      "link": "http://arxiv.org/abs/2508.13147v1",
      "source": "ArXiv NLP Papers",
      "source_type": "arxiv",
      "category": "Natural Language Processing",
      "summary": "Elastic deformations couple with electronic degrees of freedom in materials\nto generate gauge fields that lead to interesting transport properties.\nRecently, it has been well studied that strain-induced chiral magnetic fields\nin Weyl semimetals lead to interesting magnetotransport induced by the chiral\nanomaly (CA). Recent studies have revealed that CA is not necessarily only a\nWeyl-node property, but is rather a Fermi surface property, and is also present\nin a more general class of materials, for example, in spin orbit-coupled\nnoncentrosymmetric metals (SOC-NCMs). The interplay of strain, CA, and charge\nand thermomagnetic transport in SOC-NCMs, however, remains unexplored. Here we\nresolve this gap. Using a tight-binding model for SOC-NCMs, we first\ndemonstrate that strain in SOC-NCMs induces anisotropy in the spin-orbit\ncoupling and generates an axial electric field. Then, using the quasi-classical\nBoltzmann transport formalism with momentum-dependent intraband and interband\nscattering processes, we show that strain in the presence of external magnetic\nfield can generate temperature gradients via the Nernst-Ettingshausen effect,\nwhose direction and behavior depends the on interplay of multiple factors: the\nangle between the applied strain and magnetic field, the presence of the chiral\nanomaly, the Lorentz force, and the strength of interband scattering. We\nfurther reveal that time-reversal symmetry breaking in the presence of an\nexternal magnetic field generates the Berry-curvature-driven anomalous\nEttingshausen effect, which is qualitatively distinct from the conventional\nLorentz-force-driven counterpart. In light of recent and forthcoming\ntheoretical and experimental advances in the field of SOC-NCMs, we find our\nstudy to be particularly timely and relevant.",
      "published_date": "2025-08-18",
      "content_hash": "9979ac7dbca8a04b362b6f96942317f6",
      "api_data": {
        "authors": [
          "Gautham Varma K",
          "Azaz Ahmad",
          "Gargee Sharma"
        ],
        "pdf_url": "http://arxiv.org/pdf/2508.13147v1",
        "journal_ref": null,
        "doi": null
      }
    },
    {
      "title": "Topological invariant for finite systems in the presence of disorder",
      "link": "http://arxiv.org/abs/2508.13146v1",
      "source": "ArXiv NLP Papers",
      "source_type": "arxiv",
      "category": "Natural Language Processing",
      "summary": "Topological invariants, rigorously defined only in the thermodynamic limit,\nhave been generalized to topological indicators applicable to finite-size\ndisordered systems. However, in many experimentally relevant situations, such\nas semiconductor-superconductor (SM-SC) hybrid nanowires hosting Majorana zero\nmodes, the interplay between strong disorder and finite-size effects renders\nthese indicators (e.g., the so-called topological visibility) biased and\nill-defined, significantly limiting their usefulness. In this paper, we propose\nthe topological invariant rigorously defined for an infinite system constructed\nby periodically repeating the original finite disordered system, as a\ntopological indicator. Using the one-dimensional SM-SC hybrid nanowire as an\nexample, we show that this general and transparent approach yields faithful\ntopological indicators free from the biases affecting commonly used finite-size\nindicators, capturing the nature (topological or trivial) of the phase at\ngeneric points in parameter space, and providing a reliable tool for\ninterpreting experimental results.",
      "published_date": "2025-08-18",
      "content_hash": "eb78edf70112a0af986036d2e8addcb0",
      "api_data": {
        "authors": [
          "Robert Eissele",
          "Binayyak B. Roy",
          "Sumanta Tewari",
          "Tudor D. Stanescu"
        ],
        "pdf_url": "http://arxiv.org/pdf/2508.13146v1",
        "journal_ref": null,
        "doi": null
      }
    },
    {
      "title": "Influencia de fatores organizacionais e sociais na etapa de levantamento de requisitos",
      "link": "http://arxiv.org/abs/2508.13134v1",
      "source": "ArXiv NLP Papers",
      "source_type": "arxiv",
      "category": "Natural Language Processing",
      "summary": "The most critical and fragile stage of a software development project is\nrequirements gathering. Because of this, Requirements Engineering has been\nevolving its techniques to minimize the challenges faced by Requirements\nAnalysts. However, few studies consider the humanistic relationships and\nbehaviors of those involved in this stage. This article presents a survey of\nsome studies conducted at this stage that consider non-technical factors such\nas emotions, organizational environment, and social context.",
      "published_date": "2025-08-18",
      "content_hash": "bfa932ac930e7b04822ed184e7a39bd4",
      "api_data": {
        "authors": [
          "Glauber da Rocha Balthazar",
          "Marcia Ito"
        ],
        "pdf_url": "http://arxiv.org/pdf/2508.13134v1",
        "journal_ref": "ISSN:2175-1897, 2011",
        "doi": null
      }
    }
  ]
}
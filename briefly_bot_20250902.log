2025-09-02 10:40:18,460 - __main__ - INFO - Briefly Bot logging initialized
2025-09-02 10:40:18,460 - __main__ - INFO - üöÄ Briefly Bot - AI/ML News Aggregator
2025-09-02 10:40:18,460 - __main__ - INFO - ==================================================
2025-09-02 10:40:18,460 - __main__ - INFO - üìÖ Started at: 2025-09-02 10:40:18
2025-09-02 10:40:18,460 - __main__ - INFO - üîß Dry run: No
2025-09-02 10:40:18,460 - __main__ - INFO - üìä Max articles: 10
2025-09-02 10:40:18,460 - __main__ - INFO - üß† LLM Provider: openai
2025-09-02 10:40:18,460 - __main__ - INFO - üì∫ Target channel: C09AUAZCQR1
2025-09-02 10:40:18,461 - __main__ - INFO - ==================================================
2025-09-02 10:40:18,461 - __main__ - INFO - üöÄ Starting Briefly Bot...
2025-09-02 10:40:18,461 - __main__ - INFO - ============================================================
2025-09-02 10:40:18,461 - __main__ - INFO - üîß Initializing services...
2025-09-02 10:40:18,461 - slackbot.services.aggregation_service - INFO - Initializing AggregationService
2025-09-02 10:40:18,461 - slackbot.collectors.base_collector - INFO - Initialized collector: ArXiv Collector
2025-09-02 10:40:18,461 - slackbot.collectors.arxiv_collector - INFO - Loaded 4 ArXiv sources
2025-09-02 10:40:18,461 - slackbot.collectors.arxiv_collector - INFO - ArXiv client available
2025-09-02 10:40:18,461 - slackbot.services.aggregation_service - INFO - ‚úÖ ArXiv collector initialized successfully
2025-09-02 10:40:18,461 - slackbot.collectors.base_collector - INFO - Initialized collector: NewsAPI Collector
2025-09-02 10:40:18,462 - slackbot.collectors.newsapi_org_collector - INFO - Loaded 4 NewsAPI sources
2025-09-02 10:40:18,462 - slackbot.collectors.newsapi_org_collector - INFO - NewsAPI client initialized successfully
2025-09-02 10:40:18,462 - slackbot.services.aggregation_service - INFO - ‚úÖ NewsAPI collector initialized successfully
2025-09-02 10:40:18,462 - slackbot.collectors.base_collector - INFO - Initialized collector: RSS Collector
2025-09-02 10:40:18,462 - slackbot.collectors.rss_collector - INFO - üì° Loaded 30 default RSS sources
2025-09-02 10:40:18,462 - slackbot.collectors.rss_collector - INFO - ‚úÖ RSS Collector initialized with 30 sources
2025-09-02 10:40:18,462 - slackbot.services.aggregation_service - INFO - ‚úÖ RSS collector initialized successfully
2025-09-02 10:40:18,462 - slackbot.collectors.base_collector - INFO - Initialized CollectorManager
2025-09-02 10:40:18,462 - slackbot.services.aggregation_service - INFO - üìä AggregationService initialized with 3 collectors
2025-09-02 10:40:18,462 - slackbot.services.summarizer_service - INFO - Initializing ContentProcessingService with provider: openai
2025-09-02 10:40:19,426 - slackbot.summarizer.tldr_summarizer - INFO - Initialized OpenAI TLDR summarizer with model: gpt-3.5-turbo
2025-09-02 10:40:19,481 - slackbot.summarizer.tldr_summarizer - INFO - Initialized Gemini fallback with model: gemini-1.5-flash
2025-09-02 10:40:19,481 - slackbot.services.summarizer_service - INFO - ‚úÖ Summarizer initialized successfully with openai
2025-09-02 10:40:19,481 - slackbot.utils.reranker - INFO - Initializing ArticleReranker
2025-09-02 10:40:19,481 - slackbot.services.summarizer_service - INFO - ‚úÖ Article reranker initialized successfully
2025-09-02 10:40:19,481 - slackbot.services.publisher_service - INFO - Initializing PublisherService with default platform: slack
2025-09-02 10:40:19,575 - slack_bolt.App - DEBUG - Sending a request - url: https://slack.com/api/auth.test, query_params: {}, body_params: {}, files: {}, json_body: None, headers: {'Content-Type': 'application/x-www-form-urlencoded', 'Authorization': '(redacted)', 'User-Agent': 'Bolt/1.23.0 Python/3.11.13 slackclient/3.36.0 Linux/6.8.0-65-generic'}
2025-09-02 10:40:20,131 - slack_bolt.App - DEBUG - Received the following response - status: 200, headers: {'date': 'Tue, 02 Sep 2025 05:10:19 GMT', 'server': 'Apache', 'vary': 'Accept-Encoding', 'x-slack-req-id': '66b7a5ee759b4a2936f0098d78d46e92', 'x-content-type-options': 'nosniff', 'x-xss-protection': '0', 'pragma': 'no-cache', 'cache-control': 'private, no-cache, no-store, must-revalidate', 'expires': 'Sat, 26 Jul 1997 05:00:00 GMT', 'content-type': 'application/json; charset=utf-8', 'x-oauth-scopes': 'chat:write,files:write', 'access-control-expose-headers': 'x-slack-req-id, retry-after', 'access-control-allow-headers': 'slack-route, x-slack-version-ts, x-b3-traceid, x-b3-spanid, x-b3-parentspanid, x-b3-sampled, x-b3-flags', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'referrer-policy': 'no-referrer', 'x-slack-unique-id': 'aLZ8O06YA5sNQ4tiXXolJAAAADw', 'x-slack-backend': 'r', 'access-control-allow-origin': '*', 'content-length': '208', 'via': '1.1 slack-prod.tinyspeck.com, envoy-www-iad-piwfunkn,envoy-edge-bom-dsvglnhz', 'x-envoy-attempt-count': '1', 'x-envoy-upstream-service-time': '259', 'x-backend': 'main_normal main_canary_with_overflow main_control_with_overflow', 'x-server': 'slack-www-hhvm-main-iad-srub', 'x-slack-shared-secret-outcome': 'no-match', 'x-edge-backend': 'envoy-www', 'timing-allow-origin': '*', 'x-slack-edge-shared-secret-outcome': 'no-match', 'connection': 'close'}, body: {"ok":true,"url":"https:\/\/keyvaluesystems.slack.com\/","team":"KeyValue Software Systems","user":"briefly","team_id":"T4LJBDMDY","user_id":"U09BG266092","bot_id":"B09BG26606Q","is_enterprise_install":false}
2025-09-02 10:40:20,132 - slackbot.slack.publisher - INFO - Slack publisher initialized successfully
2025-09-02 10:40:20,132 - slackbot.services.publisher_service - INFO - ‚úÖ Slack publisher initialized successfully
2025-09-02 10:40:20,133 - slackbot.services.publisher_service - INFO - üì§ PublisherService initialized with 1 publishers
2025-09-02 10:40:20,133 - __main__ - INFO - ‚úÖ All services initialized successfully
2025-09-02 10:40:20,133 - __main__ - INFO - 
üì∞ Step 2: Collecting News
2025-09-02 10:40:20,133 - __main__ - INFO - ----------------------------------------
2025-09-02 10:40:20,133 - __main__ - INFO - üîç Starting news collection...
2025-09-02 10:40:20,134 - slackbot.services.aggregation_service - INFO - üéØ Collecting 10 articles with balanced sources: True
2025-09-02 10:40:20,134 - slackbot.services.aggregation_service - INFO - üîç Collecting from arxiv
2025-09-02 10:40:23,285 - slackbot.collectors.arxiv_collector - INFO - Fetched 20 papers from ArXiv AI Papers
2025-09-02 10:40:25,039 - slackbot.collectors.arxiv_collector - INFO - Fetched 8 papers from ArXiv Computer Vision
2025-09-02 10:40:26,928 - slackbot.collectors.arxiv_collector - INFO - Fetched 6 papers from ArXiv NLP Papers
2025-09-02 10:40:28,035 - slackbot.collectors.arxiv_collector - INFO - Fetched 2 papers from ArXiv Robotics
2025-09-02 10:40:28,036 - slackbot.collectors.arxiv_collector - INFO - Collected 36 total papers from ArXiv Collector
2025-09-02 10:40:28,036 - slackbot.services.aggregation_service - INFO - ‚úÖ Collected 36 articles from arxiv
2025-09-02 10:40:28,036 - slackbot.services.aggregation_service - INFO - üìä arxiv: collected 4 articles
2025-09-02 10:40:28,036 - slackbot.services.aggregation_service - INFO - üîç Collecting from newsapi
2025-09-02 10:40:28,036 - slackbot.collectors.newsapi_org_collector - INFO - NewsAPI params for Tech News AI: {'q': 'artificial intelligence OR AI', 'category': 'technology', 'language': 'en', 'country': 'us', 'page_size': 15}
2025-09-02 10:40:29,296 - slackbot.collectors.newsapi_org_collector - INFO - No results with category for Tech News AI, trying broader search...
2025-09-02 10:40:30,139 - slackbot.collectors.newsapi_org_collector - INFO - NewsAPI response for Tech News AI: status=ok, totalResults=17049, articles=15
2025-09-02 10:40:30,139 - slackbot.collectors.newsapi_org_collector - INFO - Fetched 15 articles from Tech News AI
2025-09-02 10:40:30,140 - slackbot.collectors.newsapi_org_collector - INFO - NewsAPI params for Business AI News: {'q': 'AI', 'category': 'business', 'language': 'en', 'country': 'us', 'page_size': 10}
2025-09-02 10:40:31,861 - slackbot.collectors.newsapi_org_collector - INFO - NewsAPI response for Business AI News: status=ok, totalResults=28, articles=10
2025-09-02 10:40:31,861 - slackbot.collectors.newsapi_org_collector - INFO - Fetched 10 articles from Business AI News
2025-09-02 10:40:31,862 - slackbot.collectors.newsapi_org_collector - INFO - NewsAPI params for Science AI News: {'q': 'AI', 'category': 'science', 'language': 'en', 'country': 'us', 'page_size': 10}
2025-09-02 10:40:32,365 - slackbot.collectors.newsapi_org_collector - INFO - NewsAPI response for Science AI News: status=ok, totalResults=23, articles=10
2025-09-02 10:40:32,365 - slackbot.collectors.newsapi_org_collector - INFO - Fetched 10 articles from Science AI News
2025-09-02 10:40:32,366 - slackbot.collectors.newsapi_org_collector - INFO - NewsAPI params for Health AI News: {'q': 'AI', 'category': 'health', 'language': 'en', 'country': 'us', 'page_size': 10}
2025-09-02 10:40:33,624 - slackbot.collectors.newsapi_org_collector - INFO - NewsAPI response for Health AI News: status=ok, totalResults=36, articles=9
2025-09-02 10:40:33,625 - slackbot.collectors.newsapi_org_collector - INFO - Fetched 9 articles from Health AI News
2025-09-02 10:40:33,626 - slackbot.collectors.newsapi_org_collector - INFO - Collected 44 total articles from NewsAPI Collector
2025-09-02 10:40:33,626 - slackbot.services.aggregation_service - INFO - ‚úÖ Collected 44 articles from newsapi
2025-09-02 10:40:33,626 - slackbot.services.aggregation_service - INFO - üìä newsapi: collected 3 articles
2025-09-02 10:40:33,627 - slackbot.services.aggregation_service - INFO - üîç Collecting from rss
2025-09-02 10:40:33,627 - slackbot.collectors.rss_collector - INFO - üì° Collecting articles from 30 RSS sources...
2025-09-02 10:40:33,627 - slackbot.collectors.rss_collector - INFO - üì° Fetching RSS feed: TechCrunch AI
2025-09-02 10:40:33,869 - slackbot.collectors.rss_collector - INFO - ‚úÖ Fetched 15 articles from TechCrunch AI
2025-09-02 10:40:33,870 - slackbot.collectors.rss_collector - INFO - üì° Fetching RSS feed: Medium AI
2025-09-02 10:40:34,716 - slackbot.collectors.rss_collector - INFO - ‚úÖ Fetched 10 articles from Medium AI
2025-09-02 10:40:34,716 - slackbot.collectors.rss_collector - INFO - üì° Fetching RSS feed: Medium Artificial Intelligence
2025-09-02 10:40:35,504 - slackbot.collectors.rss_collector - INFO - ‚úÖ Fetched 10 articles from Medium Artificial Intelligence
2025-09-02 10:40:35,505 - slackbot.collectors.rss_collector - INFO - üì° Fetching RSS feed: Medium Machine Learning
2025-09-02 10:40:36,248 - slackbot.collectors.rss_collector - INFO - ‚úÖ Fetched 10 articles from Medium Machine Learning
2025-09-02 10:40:36,248 - slackbot.collectors.rss_collector - INFO - üì° Fetching RSS feed: Medium Deep Learning
2025-09-02 10:40:37,096 - slackbot.collectors.rss_collector - INFO - ‚úÖ Fetched 10 articles from Medium Deep Learning
2025-09-02 10:40:37,096 - slackbot.collectors.rss_collector - INFO - üì° Fetching RSS feed: Medium Neural Networks
2025-09-02 10:40:37,519 - slackbot.collectors.rss_collector - INFO - ‚úÖ Fetched 10 articles from Medium Neural Networks
2025-09-02 10:40:37,519 - slackbot.collectors.rss_collector - INFO - üì° Fetching RSS feed: Medium Computer Vision
2025-09-02 10:40:38,100 - slackbot.collectors.rss_collector - INFO - ‚úÖ Fetched 10 articles from Medium Computer Vision
2025-09-02 10:40:38,100 - slackbot.collectors.rss_collector - INFO - üì° Fetching RSS feed: Medium NLP
2025-09-02 10:40:38,572 - slackbot.collectors.rss_collector - WARNING - ‚ö†Ô∏è No entries found in RSS feed: Medium NLP
2025-09-02 10:40:38,573 - slackbot.collectors.rss_collector - INFO - üì° Fetching RSS feed: Medium Software Development
2025-09-02 10:40:39,032 - slackbot.collectors.rss_collector - INFO - ‚úÖ Fetched 10 articles from Medium Software Development
2025-09-02 10:40:39,032 - slackbot.collectors.rss_collector - INFO - üì° Fetching RSS feed: Medium Programming
2025-09-02 10:40:40,230 - slackbot.collectors.rss_collector - INFO - ‚úÖ Fetched 10 articles from Medium Programming
2025-09-02 10:40:40,230 - slackbot.collectors.rss_collector - INFO - üì° Fetching RSS feed: Medium Python
2025-09-02 10:40:40,682 - slackbot.collectors.rss_collector - INFO - ‚úÖ Fetched 10 articles from Medium Python
2025-09-02 10:40:40,682 - slackbot.collectors.rss_collector - INFO - üì° Fetching RSS feed: Medium JavaScript
2025-09-02 10:40:41,552 - slackbot.collectors.rss_collector - INFO - ‚úÖ Fetched 10 articles from Medium JavaScript
2025-09-02 10:40:41,552 - slackbot.collectors.rss_collector - INFO - üì° Fetching RSS feed: Medium Data Science
2025-09-02 10:40:41,992 - slackbot.collectors.rss_collector - INFO - ‚úÖ Fetched 10 articles from Medium Data Science
2025-09-02 10:40:41,992 - slackbot.collectors.rss_collector - INFO - üì° Fetching RSS feed: Medium RAG
2025-09-02 10:40:42,428 - slackbot.collectors.rss_collector - WARNING - ‚ö†Ô∏è No entries found in RSS feed: Medium RAG
2025-09-02 10:40:42,428 - slackbot.collectors.rss_collector - INFO - üì° Fetching RSS feed: Medium Agentic AI
2025-09-02 10:40:43,100 - slackbot.collectors.rss_collector - INFO - ‚úÖ Fetched 8 articles from Medium Agentic AI
2025-09-02 10:40:43,100 - slackbot.collectors.rss_collector - INFO - üì° Fetching RSS feed: Medium LangChain
2025-09-02 10:40:43,544 - slackbot.collectors.rss_collector - INFO - ‚úÖ Fetched 8 articles from Medium LangChain
2025-09-02 10:40:43,544 - slackbot.collectors.rss_collector - INFO - üì° Fetching RSS feed: Medium Vector Database
2025-09-02 10:40:44,749 - slackbot.collectors.rss_collector - INFO - ‚úÖ Fetched 8 articles from Medium Vector Database
2025-09-02 10:40:44,749 - slackbot.collectors.rss_collector - INFO - üì° Fetching RSS feed: Medium LLM
2025-09-02 10:40:45,169 - slackbot.collectors.rss_collector - INFO - ‚úÖ Fetched 8 articles from Medium LLM
2025-09-02 10:40:45,169 - slackbot.collectors.rss_collector - INFO - üì° Fetching RSS feed: Medium OpenAI
2025-09-02 10:40:45,623 - slackbot.collectors.rss_collector - INFO - ‚úÖ Fetched 8 articles from Medium OpenAI
2025-09-02 10:40:45,623 - slackbot.collectors.rss_collector - INFO - üì° Fetching RSS feed: Medium API Development
2025-09-02 10:40:46,326 - slackbot.collectors.rss_collector - INFO - ‚úÖ Fetched 8 articles from Medium API Development
2025-09-02 10:40:46,327 - slackbot.collectors.rss_collector - INFO - üì° Fetching RSS feed: Medium DevOps
2025-09-02 10:40:46,855 - slackbot.collectors.rss_collector - INFO - ‚úÖ Fetched 8 articles from Medium DevOps
2025-09-02 10:40:46,855 - slackbot.collectors.rss_collector - INFO - üì° Fetching RSS feed: Medium Cloud Computing
2025-09-02 10:40:47,507 - slackbot.collectors.rss_collector - INFO - ‚úÖ Fetched 8 articles from Medium Cloud Computing
2025-09-02 10:40:47,507 - slackbot.collectors.rss_collector - INFO - üì° Fetching RSS feed: VentureBeat AI
2025-09-02 10:40:47,757 - slackbot.collectors.rss_collector - WARNING - ‚ö†Ô∏è RSS parsing issues for VentureBeat AI: <unknown>:2:39: not well-formed (invalid token)
2025-09-02 10:40:47,757 - slackbot.collectors.rss_collector - WARNING - ‚ö†Ô∏è No entries found in RSS feed: VentureBeat AI
2025-09-02 10:40:47,757 - slackbot.collectors.rss_collector - INFO - üì° Fetching RSS feed: MIT Technology Review AI
2025-09-02 10:40:48,615 - slackbot.collectors.rss_collector - WARNING - ‚ö†Ô∏è RSS parsing issues for MIT Technology Review AI: <unknown>:2:0: syntax error
2025-09-02 10:40:48,615 - slackbot.collectors.rss_collector - WARNING - ‚ö†Ô∏è No entries found in RSS feed: MIT Technology Review AI
2025-09-02 10:40:48,615 - slackbot.collectors.rss_collector - INFO - üì° Fetching RSS feed: Ars Technica AI
2025-09-02 10:40:50,175 - slackbot.collectors.rss_collector - INFO - ‚úÖ Fetched 8 articles from Ars Technica AI
2025-09-02 10:40:50,175 - slackbot.collectors.rss_collector - INFO - üì° Fetching RSS feed: Wired Technology
2025-09-02 10:40:50,376 - slackbot.collectors.rss_collector - INFO - ‚úÖ Fetched 6 articles from Wired Technology
2025-09-02 10:40:50,377 - slackbot.collectors.rss_collector - INFO - üì° Fetching RSS feed: The Verge AI
2025-09-02 10:40:51,030 - slackbot.collectors.rss_collector - WARNING - ‚ö†Ô∏è No entries found in RSS feed: The Verge AI
2025-09-02 10:40:51,030 - slackbot.collectors.rss_collector - INFO - üì° Fetching RSS feed: AI News
2025-09-02 10:40:53,403 - slackbot.collectors.rss_collector - INFO - ‚úÖ Fetched 10 articles from AI News
2025-09-02 10:40:53,403 - slackbot.collectors.rss_collector - INFO - üì° Fetching RSS feed: Synced AI
2025-09-02 10:40:53,833 - slackbot.collectors.rss_collector - INFO - ‚úÖ Fetched 8 articles from Synced AI
2025-09-02 10:40:53,833 - slackbot.collectors.rss_collector - INFO - üì° Fetching RSS feed: DeepAI
2025-09-02 10:40:54,217 - slackbot.collectors.rss_collector - WARNING - ‚ö†Ô∏è RSS parsing issues for DeepAI: <unknown>:24:2: mismatched tag
2025-09-02 10:40:54,217 - slackbot.collectors.rss_collector - WARNING - ‚ö†Ô∏è No entries found in RSS feed: DeepAI
2025-09-02 10:40:54,217 - slackbot.collectors.rss_collector - INFO - ‚úÖ RSS collection complete: 3 articles
2025-09-02 10:40:54,217 - slackbot.services.aggregation_service - INFO - ‚úÖ Collected 3 articles from rss
2025-09-02 10:40:54,217 - slackbot.services.aggregation_service - INFO - üìä rss: collected 3 articles
2025-09-02 10:40:54,218 - slackbot.services.aggregation_service - INFO - ‚úÖ Balanced collection complete: 10 articles from 3 sources
2025-09-02 10:40:54,218 - __main__ - INFO - ‚úÖ Successfully collected 10 articles
2025-09-02 10:40:54,218 - __main__ - INFO -   1. The Demon is in Ambiguity: Revisiting Situation Recognition ...
2025-09-02 10:40:54,218 - __main__ - INFO -      Source: ArXiv AI Papers (arxiv)
2025-09-02 10:40:54,218 - __main__ - INFO -      Category: Research Papers
2025-09-02 10:40:54,218 - __main__ - INFO -   2. Achieving Hilbert-Schmidt Independence Under R√©nyi Different...
2025-09-02 10:40:54,218 - __main__ - INFO -      Source: ArXiv AI Papers (arxiv)
2025-09-02 10:40:54,218 - __main__ - INFO -      Category: Research Papers
2025-09-02 10:40:54,218 - __main__ - INFO -   3. QR-LoRA: QR-Based Low-Rank Adaptation for Efficient Fine-Tun...
2025-09-02 10:40:54,218 - __main__ - INFO -      Source: ArXiv AI Papers (arxiv)
2025-09-02 10:40:54,218 - __main__ - INFO -      Category: Research Papers
2025-09-02 10:40:54,218 - __main__ - INFO - 
üß† Step 3: Creating TLDR Summaries
2025-09-02 10:40:54,218 - __main__ - INFO - ----------------------------------------
2025-09-02 10:40:54,218 - __main__ - INFO - üß† Starting TLDR summarization...
2025-09-02 10:40:54,219 - slackbot.services.summarizer_service - INFO - üîÑ Reranking 10 articles using strategy: smart
2025-09-02 10:40:54,219 - slackbot.utils.reranker - INFO - üîÑ Reranking 10 articles using strategy: smart
2025-09-02 10:40:54,227 - slackbot.utils.reranker - INFO - ‚úÖ Reranking complete. Top article: newsapi - Tech News AI
2025-09-02 10:40:54,228 - slackbot.services.summarizer_service - INFO - üìä Reranking complete. Top source: newsapi
2025-09-02 10:40:54,228 - slackbot.services.summarizer_service - INFO -   newsapi: 3 articles
2025-09-02 10:40:54,228 - slackbot.services.summarizer_service - INFO -   rss: 3 articles
2025-09-02 10:40:54,228 - slackbot.services.summarizer_service - INFO -   arxiv: 4 articles
2025-09-02 10:40:54,228 - slackbot.services.summarizer_service - INFO - üéØ Using summarization strategy: individual
2025-09-02 10:40:54,228 - slackbot.services.summarizer_service - INFO - üìù Batch summarizing 10 articles
2025-09-02 10:40:54,228 - slackbot.services.summarizer_service - INFO -   Processing 1/10: Predicting the next flood: ‚ÄòIt‚Äôs a very hard thing...
2025-09-02 10:40:54,228 - slackbot.services.summarizer_service - INFO - üìù Creating TLDR for article: Predicting the next flood: ‚ÄòIt‚Äôs a very hard thing...
2025-09-02 10:40:54,261 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-011bd248-6816-42d7-a748-fd70e93da297', 'json_data': {'messages': [{'content': 'You are an expert AI news analyst creating TLDR summaries. Focus on the key facts, why it matters, and make it engaging for busy professionals. Keep it concise and actionable.', 'role': 'system'}, {'content': 'Create a TLDR summary for this article:\n\nTitle: Predicting the next flood: ‚ÄòIt‚Äôs a very hard thing to be scared in your own home‚Äô\nContent: Cork county was under an orange weather warning on the day that a one-in-227-year flooding event hit the town of Midleton, which submerged the bottom floors of 682 properties in dark, sludgy water. \r‚Ä¶ [+7316 chars]\n\nThe output should be formatted as a JSON instance that conforms to the JSON schema below.\n\nAs an example, for the schema {"properties": {"foo": {"title": "Foo", "description": "a list of strings", "type": "array", "items": {"type": "string"}}}, "required": ["foo"]}\nthe object {"foo": ["bar", "baz"]} is a well-formatted instance of the schema. The object {"properties": {"foo": ["bar", "baz"]}} is not well-formatted.\n\nHere is the output schema:\n```\n{"description": "Structured TLDR output for individual articles.", "properties": {"tldr": {"description": "2-3 sentence TLDR summary of the article", "title": "Tldr", "type": "string"}, "key_facts": {"description": "3-5 key facts or takeaways", "items": {"type": "string"}, "title": "Key Facts", "type": "array"}, "why_matters": {"description": "1-2 sentences explaining why this matters to AI/ML professionals", "title": "Why Matters", "type": "string"}, "reading_time": {"description": "Estimated reading time (e.g., \'2 min read\')", "title": "Reading Time", "type": "string"}, "difficulty": {"description": "Content difficulty level: \'Beginner\', \'Intermediate\', or \'Advanced\'", "title": "Difficulty", "type": "string"}}, "required": ["tldr", "key_facts", "why_matters", "reading_time", "difficulty"]}\n```', 'role': 'user'}], 'model': 'gpt-3.5-turbo', 'max_completion_tokens': 2048, 'stream': False, 'temperature': 0.3}}
2025-09-02 10:40:54,272 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-02 10:40:54,272 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
2025-09-02 10:40:54,339 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x76e1cc2c2d90>
2025-09-02 10:40:54,340 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x76e1cd0df020> server_hostname='api.openai.com' timeout=None
2025-09-02 10:40:54,366 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x76e1cc2a1050>
2025-09-02 10:40:54,367 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-02 10:40:54,367 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-09-02 10:40:54,367 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-02 10:40:54,367 - httpcore.http11 - DEBUG - send_request_body.complete
2025-09-02 10:40:54,367 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-02 10:40:56,784 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 02 Sep 2025 05:10:56 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'keyvalue-rtv23o'), (b'openai-processing-ms', b'1615'), (b'openai-project', b'proj_whQdFja0l3II6fu7PPtC7wv5'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'1618'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'50000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'49999548'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'0s'), (b'x-request-id', b'req_7882f7c58004477bb7af67dc648872b8'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=ecmQzHn30mlWjsPMnZUZmaTf.RTiQMa5bY_JkA.p7Ro-1756789856-1.0.1.1-XOiVH0i1t7pbW6nsMlQ5cZJNdEzys5lhnaheKrPUDhP_0zGURNs3HGQDlsaH6gxr2BSZuHGpy3aRxTmDuGmhX7_dnnTHfuxdcbs2cdxQHoo; path=/; expires=Tue, 02-Sep-25 05:40:56 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=bGI_FTfIwaqU1ruxD9.cx.miLe8XVeB8GugvAiX2wdM-1756789856767-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'978a80edd9db7ec1-MAA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-02 10:40:56,785 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-02 10:40:56,786 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-02 10:40:56,787 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-09-02 10:40:56,787 - httpcore.http11 - DEBUG - response_closed.started
2025-09-02 10:40:56,788 - httpcore.http11 - DEBUG - response_closed.complete
2025-09-02 10:40:56,788 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Tue, 02 Sep 2025 05:10:56 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'keyvalue-rtv23o'), ('openai-processing-ms', '1615'), ('openai-project', 'proj_whQdFja0l3II6fu7PPtC7wv5'), ('openai-version', '2020-10-01'), ('x-envoy-upstream-service-time', '1618'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '50000000'), ('x-ratelimit-remaining-requests', '9999'), ('x-ratelimit-remaining-tokens', '49999548'), ('x-ratelimit-reset-requests', '6ms'), ('x-ratelimit-reset-tokens', '0s'), ('x-request-id', 'req_7882f7c58004477bb7af67dc648872b8'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=ecmQzHn30mlWjsPMnZUZmaTf.RTiQMa5bY_JkA.p7Ro-1756789856-1.0.1.1-XOiVH0i1t7pbW6nsMlQ5cZJNdEzys5lhnaheKrPUDhP_0zGURNs3HGQDlsaH6gxr2BSZuHGpy3aRxTmDuGmhX7_dnnTHfuxdcbs2cdxQHoo; path=/; expires=Tue, 02-Sep-25 05:40:56 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=bGI_FTfIwaqU1ruxD9.cx.miLe8XVeB8GugvAiX2wdM-1756789856767-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '978a80edd9db7ec1-MAA'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')])
2025-09-02 10:40:56,789 - openai._base_client - DEBUG - request_id: req_7882f7c58004477bb7af67dc648872b8
2025-09-02 10:40:56,830 - slackbot.services.summarizer_service - INFO - ‚úÖ TLDR created successfully for article
2025-09-02 10:40:56,830 - slackbot.services.summarizer_service - INFO -     ‚úÖ Summary created using openai
2025-09-02 10:40:56,830 - slackbot.services.summarizer_service - INFO -   Processing 2/10: How one AI startup is helping rice farmers battle ...
2025-09-02 10:40:56,830 - slackbot.services.summarizer_service - INFO - üìù Creating TLDR for article: How one AI startup is helping rice farmers battle ...
2025-09-02 10:40:56,832 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-ce3845b6-4768-45e4-8ecc-bb294f1154ca', 'json_data': {'messages': [{'content': 'You are an expert AI news analyst creating TLDR summaries. Focus on the key facts, why it matters, and make it engaging for busy professionals. Keep it concise and actionable.', 'role': 'system'}, {'content': 'Create a TLDR summary for this article:\n\nTitle: How one AI startup is helping rice farmers battle climate change\nContent: Mitti Labs is working with The Nature Conservancy to expand the use of climate-friendly rice farming practices in India. The startup uses its AI to verify reductions in methane emissions.\n\nThe output should be formatted as a JSON instance that conforms to the JSON schema below.\n\nAs an example, for the schema {"properties": {"foo": {"title": "Foo", "description": "a list of strings", "type": "array", "items": {"type": "string"}}}, "required": ["foo"]}\nthe object {"foo": ["bar", "baz"]} is a well-formatted instance of the schema. The object {"properties": {"foo": ["bar", "baz"]}} is not well-formatted.\n\nHere is the output schema:\n```\n{"description": "Structured TLDR output for individual articles.", "properties": {"tldr": {"description": "2-3 sentence TLDR summary of the article", "title": "Tldr", "type": "string"}, "key_facts": {"description": "3-5 key facts or takeaways", "items": {"type": "string"}, "title": "Key Facts", "type": "array"}, "why_matters": {"description": "1-2 sentences explaining why this matters to AI/ML professionals", "title": "Why Matters", "type": "string"}, "reading_time": {"description": "Estimated reading time (e.g., \'2 min read\')", "title": "Reading Time", "type": "string"}, "difficulty": {"description": "Content difficulty level: \'Beginner\', \'Intermediate\', or \'Advanced\'", "title": "Difficulty", "type": "string"}}, "required": ["tldr", "key_facts", "why_matters", "reading_time", "difficulty"]}\n```', 'role': 'user'}], 'model': 'gpt-3.5-turbo', 'max_completion_tokens': 2048, 'stream': False, 'temperature': 0.3}}
2025-09-02 10:40:56,833 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-02 10:40:56,833 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-02 10:40:56,833 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-09-02 10:40:56,833 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-02 10:40:56,833 - httpcore.http11 - DEBUG - send_request_body.complete
2025-09-02 10:40:56,833 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-02 10:40:59,610 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 02 Sep 2025 05:10:59 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'keyvalue-rtv23o'), (b'openai-processing-ms', b'1152'), (b'openai-project', b'proj_whQdFja0l3II6fu7PPtC7wv5'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'1157'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'50000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'49999560'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'0s'), (b'x-request-id', b'req_3068e52a6108406f8c130561cf0f46aa'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'978a80fd483d7ec1-MAA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-02 10:40:59,611 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-02 10:40:59,611 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-02 10:40:59,869 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-09-02 10:40:59,870 - httpcore.http11 - DEBUG - response_closed.started
2025-09-02 10:40:59,870 - httpcore.http11 - DEBUG - response_closed.complete
2025-09-02 10:40:59,870 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Tue, 02 Sep 2025 05:10:59 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'keyvalue-rtv23o', 'openai-processing-ms': '1152', 'openai-project': 'proj_whQdFja0l3II6fu7PPtC7wv5', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '1157', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '50000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '49999560', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '0s', 'x-request-id': 'req_3068e52a6108406f8c130561cf0f46aa', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '978a80fd483d7ec1-MAA', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-02 10:40:59,870 - openai._base_client - DEBUG - request_id: req_3068e52a6108406f8c130561cf0f46aa
2025-09-02 10:40:59,877 - slackbot.services.summarizer_service - INFO - ‚úÖ TLDR created successfully for article
2025-09-02 10:40:59,877 - slackbot.services.summarizer_service - INFO -     ‚úÖ Summary created using openai
2025-09-02 10:40:59,877 - slackbot.services.summarizer_service - INFO -   Processing 3/10: Harvard dropouts to launch ‚Äòalways on‚Äô AI smart gl...
2025-09-02 10:40:59,877 - slackbot.services.summarizer_service - INFO - üìù Creating TLDR for article: Harvard dropouts to launch ‚Äòalways on‚Äô AI smart gl...
2025-09-02 10:40:59,879 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-d62020d8-9695-4671-b3b0-8e4865b1ed2b', 'json_data': {'messages': [{'content': 'You are an expert AI news analyst creating TLDR summaries. Focus on the key facts, why it matters, and make it engaging for busy professionals. Keep it concise and actionable.', 'role': 'system'}, {'content': 'Create a TLDR summary for this article:\n\nTitle: Harvard dropouts to launch ‚Äòalways on‚Äô AI smart glasses that listen and record every conversation\nContent: After developing a facial-recognition app for Meta‚Äôs Ray-Ban glasses and doxing random people, two former Harvard students are now launching a startup that makes smart glasses with an always-on microphone.\n\nThe output should be formatted as a JSON instance that conforms to the JSON schema below.\n\nAs an example, for the schema {"properties": {"foo": {"title": "Foo", "description": "a list of strings", "type": "array", "items": {"type": "string"}}}, "required": ["foo"]}\nthe object {"foo": ["bar", "baz"]} is a well-formatted instance of the schema. The object {"properties": {"foo": ["bar", "baz"]}} is not well-formatted.\n\nHere is the output schema:\n```\n{"description": "Structured TLDR output for individual articles.", "properties": {"tldr": {"description": "2-3 sentence TLDR summary of the article", "title": "Tldr", "type": "string"}, "key_facts": {"description": "3-5 key facts or takeaways", "items": {"type": "string"}, "title": "Key Facts", "type": "array"}, "why_matters": {"description": "1-2 sentences explaining why this matters to AI/ML professionals", "title": "Why Matters", "type": "string"}, "reading_time": {"description": "Estimated reading time (e.g., \'2 min read\')", "title": "Reading Time", "type": "string"}, "difficulty": {"description": "Content difficulty level: \'Beginner\', \'Intermediate\', or \'Advanced\'", "title": "Difficulty", "type": "string"}}, "required": ["tldr", "key_facts", "why_matters", "reading_time", "difficulty"]}\n```', 'role': 'user'}], 'model': 'gpt-3.5-turbo', 'max_completion_tokens': 2048, 'stream': False, 'temperature': 0.3}}
2025-09-02 10:40:59,879 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-02 10:40:59,880 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-02 10:40:59,880 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-09-02 10:40:59,880 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-02 10:40:59,880 - httpcore.http11 - DEBUG - send_request_body.complete
2025-09-02 10:40:59,880 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-02 10:41:02,024 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 02 Sep 2025 05:11:01 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'keyvalue-rtv23o'), (b'openai-processing-ms', b'1353'), (b'openai-project', b'proj_whQdFja0l3II6fu7PPtC7wv5'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'1357'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'50000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'49999546'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'0s'), (b'x-request-id', b'req_1f3180ce9edb439ba318f9bf7208843e'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'978a811049ba7ec1-MAA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-02 10:41:02,025 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-02 10:41:02,026 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-02 10:41:02,026 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-09-02 10:41:02,027 - httpcore.http11 - DEBUG - response_closed.started
2025-09-02 10:41:02,027 - httpcore.http11 - DEBUG - response_closed.complete
2025-09-02 10:41:02,027 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Tue, 02 Sep 2025 05:11:01 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'keyvalue-rtv23o', 'openai-processing-ms': '1353', 'openai-project': 'proj_whQdFja0l3II6fu7PPtC7wv5', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '1357', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '50000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '49999546', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '0s', 'x-request-id': 'req_1f3180ce9edb439ba318f9bf7208843e', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '978a811049ba7ec1-MAA', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-02 10:41:02,028 - openai._base_client - DEBUG - request_id: req_1f3180ce9edb439ba318f9bf7208843e
2025-09-02 10:41:02,063 - slackbot.services.summarizer_service - INFO - ‚úÖ TLDR created successfully for article
2025-09-02 10:41:02,063 - slackbot.services.summarizer_service - INFO -     ‚úÖ Summary created using openai
2025-09-02 10:41:02,064 - slackbot.services.summarizer_service - INFO -   Processing 4/10: Meta to add 100MW of solar power from US gear...
2025-09-02 10:41:02,064 - slackbot.services.summarizer_service - INFO - üìù Creating TLDR for article: Meta to add 100MW of solar power from US gear...
2025-09-02 10:41:02,067 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-c780cb75-21cf-4d9c-83c0-679f9e3ca0d9', 'json_data': {'messages': [{'content': 'You are an expert AI news analyst creating TLDR summaries. Focus on the key facts, why it matters, and make it engaging for busy professionals. Keep it concise and actionable.', 'role': 'system'}, {'content': 'Create a TLDR summary for this article:\n\nTitle: Meta to add 100MW of solar power from US gear\nContent: The social media company is adding another tranche of solar to power a new AI data center in South Carolina.\n\nThe output should be formatted as a JSON instance that conforms to the JSON schema below.\n\nAs an example, for the schema {"properties": {"foo": {"title": "Foo", "description": "a list of strings", "type": "array", "items": {"type": "string"}}}, "required": ["foo"]}\nthe object {"foo": ["bar", "baz"]} is a well-formatted instance of the schema. The object {"properties": {"foo": ["bar", "baz"]}} is not well-formatted.\n\nHere is the output schema:\n```\n{"description": "Structured TLDR output for individual articles.", "properties": {"tldr": {"description": "2-3 sentence TLDR summary of the article", "title": "Tldr", "type": "string"}, "key_facts": {"description": "3-5 key facts or takeaways", "items": {"type": "string"}, "title": "Key Facts", "type": "array"}, "why_matters": {"description": "1-2 sentences explaining why this matters to AI/ML professionals", "title": "Why Matters", "type": "string"}, "reading_time": {"description": "Estimated reading time (e.g., \'2 min read\')", "title": "Reading Time", "type": "string"}, "difficulty": {"description": "Content difficulty level: \'Beginner\', \'Intermediate\', or \'Advanced\'", "title": "Difficulty", "type": "string"}}, "required": ["tldr", "key_facts", "why_matters", "reading_time", "difficulty"]}\n```', 'role': 'user'}], 'model': 'gpt-3.5-turbo', 'max_completion_tokens': 2048, 'stream': False, 'temperature': 0.3}}
2025-09-02 10:41:02,068 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-02 10:41:02,069 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-02 10:41:02,069 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-09-02 10:41:02,069 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-02 10:41:02,070 - httpcore.http11 - DEBUG - send_request_body.complete
2025-09-02 10:41:02,070 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-02 10:41:04,230 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 02 Sep 2025 05:11:04 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'keyvalue-rtv23o'), (b'openai-processing-ms', b'1440'), (b'openai-project', b'proj_whQdFja0l3II6fu7PPtC7wv5'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'1445'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'50000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'49999585'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'0s'), (b'x-request-id', b'req_ed31be6284ad49758915723b0ce4fc5e'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'978a811dff9f7ec1-MAA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-02 10:41:04,231 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-02 10:41:04,232 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-02 10:41:04,235 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-09-02 10:41:04,236 - httpcore.http11 - DEBUG - response_closed.started
2025-09-02 10:41:04,236 - httpcore.http11 - DEBUG - response_closed.complete
2025-09-02 10:41:04,236 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Tue, 02 Sep 2025 05:11:04 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'keyvalue-rtv23o', 'openai-processing-ms': '1440', 'openai-project': 'proj_whQdFja0l3II6fu7PPtC7wv5', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '1445', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '50000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '49999585', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '0s', 'x-request-id': 'req_ed31be6284ad49758915723b0ce4fc5e', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '978a811dff9f7ec1-MAA', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-02 10:41:04,237 - openai._base_client - DEBUG - request_id: req_ed31be6284ad49758915723b0ce4fc5e
2025-09-02 10:41:04,256 - slackbot.services.summarizer_service - INFO - ‚úÖ TLDR created successfully for article
2025-09-02 10:41:04,256 - slackbot.services.summarizer_service - INFO -     ‚úÖ Summary created using openai
2025-09-02 10:41:04,257 - slackbot.services.summarizer_service - INFO -   Processing 5/10: QR-LoRA: QR-Based Low-Rank Adaptation for Efficien...
2025-09-02 10:41:04,257 - slackbot.services.summarizer_service - INFO - üìù Creating TLDR for article: QR-LoRA: QR-Based Low-Rank Adaptation for Efficien...
2025-09-02 10:41:04,263 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-77bece22-5818-4ce3-8e4c-860947c05a28', 'json_data': {'messages': [{'content': 'You are an expert AI news analyst creating TLDR summaries. Focus on the key facts, why it matters, and make it engaging for busy professionals. Keep it concise and actionable.', 'role': 'system'}, {'content': 'Create a TLDR summary for this article:\n\nTitle: QR-LoRA: QR-Based Low-Rank Adaptation for Efficient Fine-Tuning of Large Language Models\nContent: The growing scale of Large Language Models (LLMs) has necessitated the\ndevelopment of parameter-efficient fine-tuning techniques. Low-Rank Adaptation\n(LoRA) has emerged as a promising approach, reducing the number of trainable\nparameters by applying low-rank updates to pretrained weights. While standard\nLoRA learns both update factors directly, several recent variants first\ninitialize those matrices via an SVD of the pretrained weights -- an operation\nthat can be expensive on large models and yields singular vectors that are not\nalways easy to interpret. In this work, we extract an orthonormal basis from\nthe pretrained weight matrix using QR decomposition with column pivoting, and\nthen express the LoRA update as a linear combination of these basis vectors --\ntraining only the scalar coefficients, which imposes clear structure on\nadaptation and drastically reduces parameter count. Experiments across GLUE\ntasks show that QR-LoRA matches or exceeds the performance of full fine-tuning,\nstandard LoRA, and SVD-LoRA (LoRA with update matrices initialized via singular\nvalue decomposition) with as few as 601 parameters -- a reduction of over 1000x\ncompared to full fine-tuning and 77x fewer than typical LoRA setups.\n\nThe output should be formatted as a JSON instance that conforms to the JSON schema below.\n\nAs an example, for the schema {"properties": {"foo": {"title": "Foo", "description": "a list of strings", "type": "array", "items": {"type": "string"}}}, "required": ["foo"]}\nthe object {"foo": ["bar", "baz"]} is a well-formatted instance of the schema. The object {"properties": {"foo": ["bar", "baz"]}} is not well-formatted.\n\nHere is the output schema:\n```\n{"description": "Structured TLDR output for individual articles.", "properties": {"tldr": {"description": "2-3 sentence TLDR summary of the article", "title": "Tldr", "type": "string"}, "key_facts": {"description": "3-5 key facts or takeaways", "items": {"type": "string"}, "title": "Key Facts", "type": "array"}, "why_matters": {"description": "1-2 sentences explaining why this matters to AI/ML professionals", "title": "Why Matters", "type": "string"}, "reading_time": {"description": "Estimated reading time (e.g., \'2 min read\')", "title": "Reading Time", "type": "string"}, "difficulty": {"description": "Content difficulty level: \'Beginner\', \'Intermediate\', or \'Advanced\'", "title": "Difficulty", "type": "string"}}, "required": ["tldr", "key_facts", "why_matters", "reading_time", "difficulty"]}\n```', 'role': 'user'}], 'model': 'gpt-3.5-turbo', 'max_completion_tokens': 2048, 'stream': False, 'temperature': 0.3}}
2025-09-02 10:41:04,264 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-02 10:41:04,264 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-02 10:41:04,265 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-09-02 10:41:04,265 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-02 10:41:04,265 - httpcore.http11 - DEBUG - send_request_body.complete
2025-09-02 10:41:04,266 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-02 10:41:07,109 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 02 Sep 2025 05:11:07 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'keyvalue-rtv23o'), (b'openai-processing-ms', b'2235'), (b'openai-project', b'proj_whQdFja0l3II6fu7PPtC7wv5'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'2239'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'50000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'49999295'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'0s'), (b'x-request-id', b'req_65f92847d7b743379d5995b4807c4b57'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'978a812bbe177ec1-MAA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-02 10:41:07,109 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-02 10:41:07,110 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-02 10:41:07,110 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-09-02 10:41:07,110 - httpcore.http11 - DEBUG - response_closed.started
2025-09-02 10:41:07,110 - httpcore.http11 - DEBUG - response_closed.complete
2025-09-02 10:41:07,110 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Tue, 02 Sep 2025 05:11:07 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'keyvalue-rtv23o', 'openai-processing-ms': '2235', 'openai-project': 'proj_whQdFja0l3II6fu7PPtC7wv5', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '2239', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '50000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '49999295', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '0s', 'x-request-id': 'req_65f92847d7b743379d5995b4807c4b57', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '978a812bbe177ec1-MAA', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-02 10:41:07,111 - openai._base_client - DEBUG - request_id: req_65f92847d7b743379d5995b4807c4b57
2025-09-02 10:41:07,120 - slackbot.services.summarizer_service - INFO - ‚úÖ TLDR created successfully for article
2025-09-02 10:41:07,120 - slackbot.services.summarizer_service - INFO -     ‚úÖ Summary created using openai
2025-09-02 10:41:07,120 - slackbot.services.summarizer_service - INFO -   Processing 6/10: Epsilon-saturation for stable graphs and Littlesto...
2025-09-02 10:41:07,120 - slackbot.services.summarizer_service - INFO - üìù Creating TLDR for article: Epsilon-saturation for stable graphs and Littlesto...
2025-09-02 10:41:07,122 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-3696b4fb-314d-4c2d-bed3-f65ab762a6f6', 'json_data': {'messages': [{'content': 'You are an expert AI news analyst creating TLDR summaries. Focus on the key facts, why it matters, and make it engaging for busy professionals. Keep it concise and actionable.', 'role': 'system'}, {'content': 'Create a TLDR summary for this article:\n\nTitle: Epsilon-saturation for stable graphs and Littlestone classes\nContent: Any Littlestone class, or stable graph, has finite sets which function as\n``virtual elements\'\': these can be seen from the learning side as representing\nhypotheses which are expressible as weighted majority opinions of hypotheses in\nthe class, and from the model-theoretic side as an approximate finitary version\nof realizing types. We introduce and study the epsilon-saturation of a\nLittlestone class, or stable graph, which is essentially the closure of the\nclass under inductively adding all such virtual elements. We characterize this\nclosure and prove that under reasonable choices of parameters, it remains\nLittlestone (or stable), though not always of the same Littlestone dimension.\nThis highlights some surprising phenomena having to do with regimes of epsilon\nand the relation between Littlestone/stability and VC dimension.\n\nThe output should be formatted as a JSON instance that conforms to the JSON schema below.\n\nAs an example, for the schema {"properties": {"foo": {"title": "Foo", "description": "a list of strings", "type": "array", "items": {"type": "string"}}}, "required": ["foo"]}\nthe object {"foo": ["bar", "baz"]} is a well-formatted instance of the schema. The object {"properties": {"foo": ["bar", "baz"]}} is not well-formatted.\n\nHere is the output schema:\n```\n{"description": "Structured TLDR output for individual articles.", "properties": {"tldr": {"description": "2-3 sentence TLDR summary of the article", "title": "Tldr", "type": "string"}, "key_facts": {"description": "3-5 key facts or takeaways", "items": {"type": "string"}, "title": "Key Facts", "type": "array"}, "why_matters": {"description": "1-2 sentences explaining why this matters to AI/ML professionals", "title": "Why Matters", "type": "string"}, "reading_time": {"description": "Estimated reading time (e.g., \'2 min read\')", "title": "Reading Time", "type": "string"}, "difficulty": {"description": "Content difficulty level: \'Beginner\', \'Intermediate\', or \'Advanced\'", "title": "Difficulty", "type": "string"}}, "required": ["tldr", "key_facts", "why_matters", "reading_time", "difficulty"]}\n```', 'role': 'user'}], 'model': 'gpt-3.5-turbo', 'max_completion_tokens': 2048, 'stream': False, 'temperature': 0.3}}
2025-09-02 10:41:07,123 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-02 10:41:07,123 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-02 10:41:07,124 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-09-02 10:41:07,124 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-02 10:41:07,124 - httpcore.http11 - DEBUG - send_request_body.complete
2025-09-02 10:41:07,124 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-02 10:41:09,338 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 02 Sep 2025 05:11:09 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'keyvalue-rtv23o'), (b'openai-processing-ms', b'1476'), (b'openai-project', b'proj_whQdFja0l3II6fu7PPtC7wv5'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'1483'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'50000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'49999400'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'0s'), (b'x-request-id', b'req_ae0a73d6a3a342e4a8c0b505d61a70b6'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'978a813d9f757ec1-MAA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-02 10:41:09,339 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-02 10:41:09,339 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-02 10:41:09,340 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-09-02 10:41:09,341 - httpcore.http11 - DEBUG - response_closed.started
2025-09-02 10:41:09,341 - httpcore.http11 - DEBUG - response_closed.complete
2025-09-02 10:41:09,341 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Tue, 02 Sep 2025 05:11:09 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'keyvalue-rtv23o', 'openai-processing-ms': '1476', 'openai-project': 'proj_whQdFja0l3II6fu7PPtC7wv5', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '1483', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '50000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '49999400', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '0s', 'x-request-id': 'req_ae0a73d6a3a342e4a8c0b505d61a70b6', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '978a813d9f757ec1-MAA', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-02 10:41:09,342 - openai._base_client - DEBUG - request_id: req_ae0a73d6a3a342e4a8c0b505d61a70b6
2025-09-02 10:41:09,369 - slackbot.services.summarizer_service - INFO - ‚úÖ TLDR created successfully for article
2025-09-02 10:41:09,369 - slackbot.services.summarizer_service - INFO -     ‚úÖ Summary created using openai
2025-09-02 10:41:09,369 - slackbot.services.summarizer_service - INFO -   Processing 7/10: The Demon is in Ambiguity: Revisiting Situation Re...
2025-09-02 10:41:09,369 - slackbot.services.summarizer_service - INFO - üìù Creating TLDR for article: The Demon is in Ambiguity: Revisiting Situation Re...
2025-09-02 10:41:09,373 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-db003f25-cce5-4f36-8bbe-58791581a912', 'json_data': {'messages': [{'content': 'You are an expert AI news analyst creating TLDR summaries. Focus on the key facts, why it matters, and make it engaging for busy professionals. Keep it concise and actionable.', 'role': 'system'}, {'content': 'Create a TLDR summary for this article:\n\nTitle: The Demon is in Ambiguity: Revisiting Situation Recognition with Single Positive Multi-Label Learning\nContent: Context recognition (SR) is a fundamental task in computer vision that aims\nto extract structured semantic summaries from images by identifying key events\nand their associated entities. Specifically, given an input image, the model\nmust first classify the main visual events (verb classification), then identify\nthe participating entities and their semantic roles (semantic role labeling),\nand finally localize these entities in the image (semantic role localization).\nExisting methods treat verb classification as a single-label problem, but we\nshow through a comprehensive analysis that this formulation fails to address\nthe inherent ambiguity in visual event recognition, as multiple verb categories\nmay reasonably describe the same image. This paper makes three key\ncontributions: First, we reveal through empirical analysis that verb\nclassification is inherently a multi-label problem due to the ubiquitous\nsemantic overlap between verb categories. Second, given the impracticality of\nfully annotating large-scale datasets with multiple labels, we propose to\nreformulate verb classification as a single positive multi-label learning\n(SPMLL) problem - a novel perspective in SR research. Third, we design a\ncomprehensive multi-label evaluation benchmark for SR that is carefully\ndesigned to fairly evaluate model performance in a multi-label setting. To\naddress the challenges of SPMLL, we futher develop the Graph Enhanced Verb\nMultilayer Perceptron (GE-VerbMLP), which combines graph neural networks to\ncapture label correlations and adversarial training to optimize decision\nboundaries. Extensive experiments on real-world datasets show that our approach\nachieves more than 3\\% MAP improvement while remaining competitive on\ntraditional top-1 and top-5 accuracy metrics.\n\nThe output should be formatted as a JSON instance that conforms to the JSON schema below.\n\nAs an example, for the schema {"properties": {"foo": {"title": "Foo", "description": "a list of strings", "type": "array", "items": {"type": "string"}}}, "required": ["foo"]}\nthe object {"foo": ["bar", "baz"]} is a well-formatted instance of the schema. The object {"properties": {"foo": ["bar", "baz"]}} is not well-formatted.\n\nHere is the output schema:\n```\n{"description": "Structured TLDR output for individual articles.", "properties": {"tldr": {"description": "2-3 sentence TLDR summary of the article", "title": "Tldr", "type": "string"}, "key_facts": {"description": "3-5 key facts or takeaways", "items": {"type": "string"}, "title": "Key Facts", "type": "array"}, "why_matters": {"description": "1-2 sentences explaining why this matters to AI/ML professionals", "title": "Why Matters", "type": "string"}, "reading_time": {"description": "Estimated reading time (e.g., \'2 min read\')", "title": "Reading Time", "type": "string"}, "difficulty": {"description": "Content difficulty level: \'Beginner\', \'Intermediate\', or \'Advanced\'", "title": "Difficulty", "type": "string"}}, "required": ["tldr", "key_facts", "why_matters", "reading_time", "difficulty"]}\n```', 'role': 'user'}], 'model': 'gpt-3.5-turbo', 'max_completion_tokens': 2048, 'stream': False, 'temperature': 0.3}}
2025-09-02 10:41:09,374 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-02 10:41:09,374 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-02 10:41:09,375 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-09-02 10:41:09,375 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-02 10:41:09,375 - httpcore.http11 - DEBUG - send_request_body.complete
2025-09-02 10:41:09,375 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-02 10:41:12,329 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 02 Sep 2025 05:11:12 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'keyvalue-rtv23o'), (b'openai-processing-ms', b'2627'), (b'openai-project', b'proj_whQdFja0l3II6fu7PPtC7wv5'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'2631'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'50000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'49999154'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'1ms'), (b'x-request-id', b'req_6632516ce44043628826e579bb92d09f'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'978a814bab557ec1-MAA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-02 10:41:12,331 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-02 10:41:12,331 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-02 10:41:12,332 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-09-02 10:41:12,333 - httpcore.http11 - DEBUG - response_closed.started
2025-09-02 10:41:12,333 - httpcore.http11 - DEBUG - response_closed.complete
2025-09-02 10:41:12,333 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Tue, 02 Sep 2025 05:11:12 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'keyvalue-rtv23o', 'openai-processing-ms': '2627', 'openai-project': 'proj_whQdFja0l3II6fu7PPtC7wv5', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '2631', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '50000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '49999154', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '1ms', 'x-request-id': 'req_6632516ce44043628826e579bb92d09f', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '978a814bab557ec1-MAA', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-02 10:41:12,334 - openai._base_client - DEBUG - request_id: req_6632516ce44043628826e579bb92d09f
2025-09-02 10:41:12,367 - slackbot.summarizer.tldr_summarizer - ERROR - Error creating article TLDR with openai: Failed to parse ArticleTLDR from completion {"description": "Structured TLDR output for individual articles.", "properties": {"tldr": {"description": "2-3 sentence TLDR summary of the article", "title": "Tldr", "type": "string"}, "key_facts": {"description": "3-5 key facts or takeaways", "items": {"type": "string"}, "title": "Key Facts", "type": "array"}, "why_matters": {"description": "1-2 sentences explaining why this matters to AI/ML professionals", "title": "Why Matters", "type": "string"}, "reading_time": {"description": "Estimated reading time (e.g., '2 min read')", "title": "Reading Time", "type": "string"}, "difficulty": {"description": "Content difficulty level: 'Beginner', 'Intermediate', or 'Advanced'", "title": "Difficulty", "type": "string"}}, "required": ["tldr", "key_facts", "why_matters", "reading_time", "difficulty"]}. Got: 5 validation errors for ArticleTLDR
tldr
  Field required [type=missing, input_value={'description': 'Structur...ng_time', 'difficulty']}, input_type=dict]
    For further information visit https://errors.pydantic.dev/2.11/v/missing
key_facts
  Field required [type=missing, input_value={'description': 'Structur...ng_time', 'difficulty']}, input_type=dict]
    For further information visit https://errors.pydantic.dev/2.11/v/missing
why_matters
  Field required [type=missing, input_value={'description': 'Structur...ng_time', 'difficulty']}, input_type=dict]
    For further information visit https://errors.pydantic.dev/2.11/v/missing
reading_time
  Field required [type=missing, input_value={'description': 'Structur...ng_time', 'difficulty']}, input_type=dict]
    For further information visit https://errors.pydantic.dev/2.11/v/missing
difficulty
  Field required [type=missing, input_value={'description': 'Structur...ng_time', 'difficulty']}, input_type=dict]
    For further information visit https://errors.pydantic.dev/2.11/v/missing
For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE 
2025-09-02 10:41:12,367 - slackbot.services.summarizer_service - INFO - ‚úÖ TLDR created successfully for article
2025-09-02 10:41:12,367 - slackbot.services.summarizer_service - INFO -     ‚úÖ Summary created using openai
2025-09-02 10:41:12,367 - slackbot.services.summarizer_service - INFO -   Processing 8/10: Achieving Hilbert-Schmidt Independence Under R√©nyi...
2025-09-02 10:41:12,368 - slackbot.services.summarizer_service - INFO - üìù Creating TLDR for article: Achieving Hilbert-Schmidt Independence Under R√©nyi...
2025-09-02 10:41:12,371 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-e3da870c-6e08-436e-93cd-f2c32c663072', 'json_data': {'messages': [{'content': 'You are an expert AI news analyst creating TLDR summaries. Focus on the key facts, why it matters, and make it engaging for busy professionals. Keep it concise and actionable.', 'role': 'system'}, {'content': 'Create a TLDR summary for this article:\n\nTitle: Achieving Hilbert-Schmidt Independence Under R√©nyi Differential Privacy for Fair and Private Data Generation\nContent: As privacy regulations such as the GDPR and HIPAA and responsibility\nframeworks for artificial intelligence such as the AI Act gain traction, the\nethical and responsible use of real-world data faces increasing constraints.\nSynthetic data generation has emerged as a promising solution to risk-aware\ndata sharing and model development, particularly for tabular datasets that are\nfoundational to sensitive domains such as healthcare. To address both privacy\nand fairness concerns in this setting, we propose FLIP (Fair Latent\nIntervention under Privacy guarantees), a transformer-based variational\nautoencoder augmented with latent diffusion to generate heterogeneous tabular\ndata. Unlike the typical setup in fairness-aware data generation, we assume a\ntask-agnostic setup, not reliant on a fixed, defined downstream task, thus\noffering broader applicability. To ensure privacy, FLIP employs R\\\'enyi\ndifferential privacy (RDP) constraints during training and addresses fairness\nin the input space with RDP-compatible balanced sampling that accounts for\ngroup-specific noise levels across multiple sampling rates. In the latent\nspace, we promote fairness by aligning neuron activation patterns across\nprotected groups using Centered Kernel Alignment (CKA), a similarity measure\nextending the Hilbert-Schmidt Independence Criterion (HSIC). This alignment\nencourages statistical independence between latent representations and the\nprotected feature. Empirical results demonstrate that FLIP effectively provides\nsignificant fairness improvements for task-agnostic fairness and across diverse\ndownstream tasks under differential privacy constraints.\n\nThe output should be formatted as a JSON instance that conforms to the JSON schema below.\n\nAs an example, for the schema {"properties": {"foo": {"title": "Foo", "description": "a list of strings", "type": "array", "items": {"type": "string"}}}, "required": ["foo"]}\nthe object {"foo": ["bar", "baz"]} is a well-formatted instance of the schema. The object {"properties": {"foo": ["bar", "baz"]}} is not well-formatted.\n\nHere is the output schema:\n```\n{"description": "Structured TLDR output for individual articles.", "properties": {"tldr": {"description": "2-3 sentence TLDR summary of the article", "title": "Tldr", "type": "string"}, "key_facts": {"description": "3-5 key facts or takeaways", "items": {"type": "string"}, "title": "Key Facts", "type": "array"}, "why_matters": {"description": "1-2 sentences explaining why this matters to AI/ML professionals", "title": "Why Matters", "type": "string"}, "reading_time": {"description": "Estimated reading time (e.g., \'2 min read\')", "title": "Reading Time", "type": "string"}, "difficulty": {"description": "Content difficulty level: \'Beginner\', \'Intermediate\', or \'Advanced\'", "title": "Difficulty", "type": "string"}}, "required": ["tldr", "key_facts", "why_matters", "reading_time", "difficulty"]}\n```', 'role': 'user'}], 'model': 'gpt-3.5-turbo', 'max_completion_tokens': 2048, 'stream': False, 'temperature': 0.3}}
2025-09-02 10:41:12,373 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-02 10:41:12,373 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-02 10:41:12,373 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-09-02 10:41:12,373 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-02 10:41:12,374 - httpcore.http11 - DEBUG - send_request_body.complete
2025-09-02 10:41:12,374 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-02 10:41:15,145 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 02 Sep 2025 05:11:15 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'keyvalue-rtv23o'), (b'openai-processing-ms', b'2330'), (b'openai-project', b'proj_whQdFja0l3II6fu7PPtC7wv5'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'2337'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'50000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'49999185'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'0s'), (b'x-request-id', b'req_34293a3863d843d392a96d2deadd1a4b'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'978a815e6b9c7ec1-MAA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-02 10:41:15,146 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-02 10:41:15,146 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-02 10:41:15,314 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-09-02 10:41:15,315 - httpcore.http11 - DEBUG - response_closed.started
2025-09-02 10:41:15,315 - httpcore.http11 - DEBUG - response_closed.complete
2025-09-02 10:41:15,315 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Tue, 02 Sep 2025 05:11:15 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'keyvalue-rtv23o', 'openai-processing-ms': '2330', 'openai-project': 'proj_whQdFja0l3II6fu7PPtC7wv5', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '2337', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '50000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '49999185', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '0s', 'x-request-id': 'req_34293a3863d843d392a96d2deadd1a4b', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '978a815e6b9c7ec1-MAA', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-02 10:41:15,316 - openai._base_client - DEBUG - request_id: req_34293a3863d843d392a96d2deadd1a4b
2025-09-02 10:41:15,352 - slackbot.summarizer.tldr_summarizer - ERROR - Error creating article TLDR with openai: Failed to parse ArticleTLDR from completion {"description": "Structured TLDR output for individual articles.", "properties": {"tldr": {"description": "2-3 sentence TLDR summary of the article", "title": "Tldr", "type": "string"}, "key_facts": {"description": "3-5 key facts or takeaways", "items": {"type": "string"}, "title": "Key Facts", "type": "array"}, "why_matters": {"description": "1-2 sentences explaining why this matters to AI/ML professionals", "title": "Why Matters", "type": "string"}, "reading_time": {"description": "Estimated reading time (e.g., '2 min read')", "title": "Reading Time", "type": "string"}, "difficulty": {"description": "Content difficulty level: 'Beginner', 'Intermediate', or 'Advanced'", "title": "Difficulty", "type": "string"}}, "required": ["tldr", "key_facts", "why_matters", "reading_time", "difficulty"]}. Got: 5 validation errors for ArticleTLDR
tldr
  Field required [type=missing, input_value={'description': 'Structur...ng_time', 'difficulty']}, input_type=dict]
    For further information visit https://errors.pydantic.dev/2.11/v/missing
key_facts
  Field required [type=missing, input_value={'description': 'Structur...ng_time', 'difficulty']}, input_type=dict]
    For further information visit https://errors.pydantic.dev/2.11/v/missing
why_matters
  Field required [type=missing, input_value={'description': 'Structur...ng_time', 'difficulty']}, input_type=dict]
    For further information visit https://errors.pydantic.dev/2.11/v/missing
reading_time
  Field required [type=missing, input_value={'description': 'Structur...ng_time', 'difficulty']}, input_type=dict]
    For further information visit https://errors.pydantic.dev/2.11/v/missing
difficulty
  Field required [type=missing, input_value={'description': 'Structur...ng_time', 'difficulty']}, input_type=dict]
    For further information visit https://errors.pydantic.dev/2.11/v/missing
For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE 
2025-09-02 10:41:15,352 - slackbot.services.summarizer_service - INFO - ‚úÖ TLDR created successfully for article
2025-09-02 10:41:15,352 - slackbot.services.summarizer_service - INFO -     ‚úÖ Summary created using openai
2025-09-02 10:41:15,353 - slackbot.services.summarizer_service - INFO -   Processing 9/10:  Reports: Transfer saga over, Liverpool pay ‚Ç¨150m ...
2025-09-02 10:41:15,353 - slackbot.services.summarizer_service - INFO - üìù Creating TLDR for article:  Reports: Transfer saga over, Liverpool pay ‚Ç¨150m ...
2025-09-02 10:41:15,356 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-f21b2bac-2a00-43a8-8fef-207a0abf1d60', 'json_data': {'messages': [{'content': 'You are an expert AI news analyst creating TLDR summaries. Focus on the key facts, why it matters, and make it engaging for busy professionals. Keep it concise and actionable.', 'role': 'system'}, {'content': 'Create a TLDR summary for this article:\n\nTitle:  Reports: Transfer saga over, Liverpool pay ‚Ç¨150m for star striker\nContent: The Reds seem unable to get enough of big names this transfer summer and have made the seemingly impossible possible: Liverpool and Newcastle United have agreed on a transfer for Alexander Isak. Acco‚Ä¶ [+909 chars]\n\nThe output should be formatted as a JSON instance that conforms to the JSON schema below.\n\nAs an example, for the schema {"properties": {"foo": {"title": "Foo", "description": "a list of strings", "type": "array", "items": {"type": "string"}}}, "required": ["foo"]}\nthe object {"foo": ["bar", "baz"]} is a well-formatted instance of the schema. The object {"properties": {"foo": ["bar", "baz"]}} is not well-formatted.\n\nHere is the output schema:\n```\n{"description": "Structured TLDR output for individual articles.", "properties": {"tldr": {"description": "2-3 sentence TLDR summary of the article", "title": "Tldr", "type": "string"}, "key_facts": {"description": "3-5 key facts or takeaways", "items": {"type": "string"}, "title": "Key Facts", "type": "array"}, "why_matters": {"description": "1-2 sentences explaining why this matters to AI/ML professionals", "title": "Why Matters", "type": "string"}, "reading_time": {"description": "Estimated reading time (e.g., \'2 min read\')", "title": "Reading Time", "type": "string"}, "difficulty": {"description": "Content difficulty level: \'Beginner\', \'Intermediate\', or \'Advanced\'", "title": "Difficulty", "type": "string"}}, "required": ["tldr", "key_facts", "why_matters", "reading_time", "difficulty"]}\n```', 'role': 'user'}], 'model': 'gpt-3.5-turbo', 'max_completion_tokens': 2048, 'stream': False, 'temperature': 0.3}}
2025-09-02 10:41:15,356 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-02 10:41:15,357 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-02 10:41:15,357 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-09-02 10:41:15,357 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-02 10:41:15,358 - httpcore.http11 - DEBUG - send_request_body.complete
2025-09-02 10:41:15,358 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-02 10:41:16,907 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 02 Sep 2025 05:11:16 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'keyvalue-rtv23o'), (b'openai-processing-ms', b'1091'), (b'openai-project', b'proj_whQdFja0l3II6fu7PPtC7wv5'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'1094'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'50000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'49999552'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'0s'), (b'x-request-id', b'req_346fd60a343b4497b0e061dfcf8b42d5'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'978a81710d427ec1-MAA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-02 10:41:16,908 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-02 10:41:16,909 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-02 10:41:16,928 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-09-02 10:41:16,928 - httpcore.http11 - DEBUG - response_closed.started
2025-09-02 10:41:16,929 - httpcore.http11 - DEBUG - response_closed.complete
2025-09-02 10:41:16,930 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Tue, 02 Sep 2025 05:11:16 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'keyvalue-rtv23o', 'openai-processing-ms': '1091', 'openai-project': 'proj_whQdFja0l3II6fu7PPtC7wv5', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '1094', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '50000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '49999552', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '0s', 'x-request-id': 'req_346fd60a343b4497b0e061dfcf8b42d5', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '978a81710d427ec1-MAA', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-02 10:41:16,930 - openai._base_client - DEBUG - request_id: req_346fd60a343b4497b0e061dfcf8b42d5
2025-09-02 10:41:16,950 - slackbot.services.summarizer_service - INFO - ‚úÖ TLDR created successfully for article
2025-09-02 10:41:16,951 - slackbot.services.summarizer_service - INFO -     ‚úÖ Summary created using openai
2025-09-02 10:41:16,951 - slackbot.services.summarizer_service - INFO -   Processing 10/10: ‚òïÔ∏è Vallecano pitch woes , Sergio Ramos in tune ...
2025-09-02 10:41:16,951 - slackbot.services.summarizer_service - INFO - üìù Creating TLDR for article: ‚òïÔ∏è Vallecano pitch woes , Sergio Ramos in tune ...
2025-09-02 10:41:16,955 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-297aee20-6be6-4f76-8449-8917a8971cc0', 'json_data': {'messages': [{'content': 'You are an expert AI news analyst creating TLDR summaries. Focus on the key facts, why it matters, and make it engaging for busy professionals. Keep it concise and actionable.', 'role': 'system'}, {'content': 'Create a TLDR summary for this article:\n\nTitle: ‚òïÔ∏è Vallecano pitch woes , Sergio Ramos in tune \nContent: Before hosting FC Barcelona, several videos of the Rayo Vallecano pitch circulated.\r\nIt\'s complicated to play on that...\r\nSergio Ramos Opens Up Through Music\xa0\r\nBesides being an outstanding defender, ‚Ä¶ [+627 chars]\n\nThe output should be formatted as a JSON instance that conforms to the JSON schema below.\n\nAs an example, for the schema {"properties": {"foo": {"title": "Foo", "description": "a list of strings", "type": "array", "items": {"type": "string"}}}, "required": ["foo"]}\nthe object {"foo": ["bar", "baz"]} is a well-formatted instance of the schema. The object {"properties": {"foo": ["bar", "baz"]}} is not well-formatted.\n\nHere is the output schema:\n```\n{"description": "Structured TLDR output for individual articles.", "properties": {"tldr": {"description": "2-3 sentence TLDR summary of the article", "title": "Tldr", "type": "string"}, "key_facts": {"description": "3-5 key facts or takeaways", "items": {"type": "string"}, "title": "Key Facts", "type": "array"}, "why_matters": {"description": "1-2 sentences explaining why this matters to AI/ML professionals", "title": "Why Matters", "type": "string"}, "reading_time": {"description": "Estimated reading time (e.g., \'2 min read\')", "title": "Reading Time", "type": "string"}, "difficulty": {"description": "Content difficulty level: \'Beginner\', \'Intermediate\', or \'Advanced\'", "title": "Difficulty", "type": "string"}}, "required": ["tldr", "key_facts", "why_matters", "reading_time", "difficulty"]}\n```', 'role': 'user'}], 'model': 'gpt-3.5-turbo', 'max_completion_tokens': 2048, 'stream': False, 'temperature': 0.3}}
2025-09-02 10:41:16,956 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-02 10:41:16,957 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-02 10:41:16,957 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-09-02 10:41:16,957 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-02 10:41:16,958 - httpcore.http11 - DEBUG - send_request_body.complete
2025-09-02 10:41:16,958 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-02 10:41:18,728 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 02 Sep 2025 05:11:18 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'keyvalue-rtv23o'), (b'openai-processing-ms', b'1420'), (b'openai-project', b'proj_whQdFja0l3II6fu7PPtC7wv5'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'1424'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'50000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'49999557'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'0s'), (b'x-request-id', b'req_5cb2f1f2e7014578b5a48de756406517'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'978a817b0fb37ec1-MAA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-02 10:41:18,729 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-02 10:41:18,730 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-02 10:41:18,952 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-09-02 10:41:18,952 - httpcore.http11 - DEBUG - response_closed.started
2025-09-02 10:41:18,952 - httpcore.http11 - DEBUG - response_closed.complete
2025-09-02 10:41:18,952 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Tue, 02 Sep 2025 05:11:18 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'keyvalue-rtv23o', 'openai-processing-ms': '1420', 'openai-project': 'proj_whQdFja0l3II6fu7PPtC7wv5', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '1424', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '50000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '49999557', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '0s', 'x-request-id': 'req_5cb2f1f2e7014578b5a48de756406517', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '978a817b0fb37ec1-MAA', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-02 10:41:18,952 - openai._base_client - DEBUG - request_id: req_5cb2f1f2e7014578b5a48de756406517
2025-09-02 10:41:18,958 - slackbot.services.summarizer_service - INFO - ‚úÖ TLDR created successfully for article
2025-09-02 10:41:18,958 - slackbot.services.summarizer_service - INFO -     ‚úÖ Summary created using openai
2025-09-02 10:41:18,958 - slackbot.services.summarizer_service - INFO - ‚úÖ Batch summarization complete: 10/10 successful
2025-09-02 10:41:18,958 - __main__ - INFO - ‚úÖ Successfully created 10 TLDR summaries
2025-09-02 10:41:18,958 - __main__ - INFO - 
üí¨ Step 4: Creating Slack Message
2025-09-02 10:41:18,958 - __main__ - INFO - ----------------------------------------
2025-09-02 10:41:18,958 - __main__ - INFO - üí¨ Creating Slack message...
2025-09-02 10:41:18,958 - __main__ - INFO - ‚úÖ Slack message created with 23 blocks
2025-09-02 10:41:18,958 - __main__ - INFO - 
üì§ Step 5: Publishing to Slack
2025-09-02 10:41:18,959 - __main__ - INFO - ----------------------------------------
2025-09-02 10:41:18,959 - __main__ - INFO - üì§ Publishing to Slack channel C09AUAZCQR1...
2025-09-02 10:41:18,959 - slackbot.services.publisher_service - INFO - üì§ Publishing message to slack
2025-09-02 10:41:18,959 - slack_bolt.App - DEBUG - Sending a request - url: https://slack.com/api/chat.postMessage, query_params: {}, body_params: {}, files: {}, json_body: {'channel': '#news-finder', 'text': 'üöÄ AI/ML News TLDR - 10 articles summarized', 'attachments': [], 'blocks': [{'type': 'header', 'text': {'type': 'plain_text', 'text': 'üöÄ AI/ML News TLDR - Daily Digest'}}, {'type': 'section', 'text': {'type': 'mrkdwn', 'text': "*Today's AI/ML News Summary*\nCollected 10 articles and created TLDR summaries."}}, {'type': 'divider'}, {'type': 'section', 'text': {'type': 'mrkdwn', 'text': '*1. The Demon is in Ambiguity: Revisiting Situation Recognition with Single Positive Multi-Label Learning*\nMidleton town in Cork county experienced a rare flooding event, affecting 682 properties. Residents faced significant damage and challenges due to the flood.\n\nüì∞ *Source:* ArXiv AI Papers | üè∑Ô∏è *Category:* Research Papers\n<http://arxiv.org/abs/2508.21816v1|Read more>'}}, {'type': 'divider'}, {'type': 'section', 'text': {'type': 'mrkdwn', 'text': '*2. Achieving Hilbert-Schmidt Independence Under R√©nyi Differential Privacy for Fair and Private Data Generation*\nMitti Labs collaborates with The Nature Conservancy to promote climate-friendly rice farming in India using AI to monitor methane emissions.\n\nüì∞ *Source:* ArXiv AI Papers | üè∑Ô∏è *Category:* Research Papers\n<http://arxiv.org/abs/2508.21815v1|Read more>'}}, {'type': 'divider'}, {'type': 'section', 'text': {'type': 'mrkdwn', 'text': '*3. QR-LoRA: QR-Based Low-Rank Adaptation for Efficient Fine-Tuning of Large Language Models*\nFormer Harvard students are launching smart glasses with an always-on microphone after controversial projects. The glasses record every conversation.\n\nüì∞ *Source:* ArXiv AI Papers | üè∑Ô∏è *Category:* Research Papers\n<http://arxiv.org/abs/2508.21810v1|Read more>'}}, {'type': 'divider'}, {'type': 'section', 'text': {'type': 'mrkdwn', 'text': '*4. Epsilon-saturation for stable graphs and Littlestone classes*\nMeta plans to install 100MW of solar power from US sources for a new AI data center in South Carolina.\n\nüì∞ *Source:* ArXiv AI Papers | üè∑Ô∏è *Category:* Research Papers\n<http://arxiv.org/abs/2508.21807v1|Read more>'}}, {'type': 'divider'}, {'type': 'section', 'text': {'type': 'mrkdwn', 'text': '*5.  Reports: Transfer saga over, Liverpool pay ‚Ç¨150m for star striker*\nQR-LoRA introduces a parameter-efficient fine-tuning technique for Large Language Models by using QR decomposition with column pivoting to reduce trainable parameters. It outperforms standard LoRA and SVD-LoRA with significantly fewer parameters.\n\nüì∞ *Source:* Tech News AI | üè∑Ô∏è *Category:* technology\n<https://onefootball.com/en/news/reports-transfer-saga-over-liverpool-pay-150m-for-star-striker-41597779|Read more>'}}, {'type': 'divider'}, {'type': 'section', 'text': {'type': 'mrkdwn', 'text': '*6. ‚òïÔ∏è Vallecano pitch woes , Sergio Ramos in tune *\nIntroduction and study of epsilon-saturation for Littlestone classes/stable graphs, showing closure under adding virtual elements, impacting Littlestone dimension and VC dimension.\n\nüì∞ *Source:* Tech News AI | üè∑Ô∏è *Category:* technology\n<https://onefootball.com/en/news/vallecano-pitch-woes-sergio-ramos-in-tune-41597756|Read more>'}}, {'type': 'divider'}, {'type': 'section', 'text': {'type': 'mrkdwn', 'text': '*7. Predicting the next flood: ‚ÄòIt‚Äôs a very hard thing to be scared in your own home‚Äô*\nüì∞ *The Demon is in Ambiguity: Revisiting Situation Recognition with Single Positive Multi-Label Learning*\n\nContext recognition (SR) is a fundamental task in computer vision that aims\nto extract structured semantic summaries from images by identifying key events\nand their associated entities. Specifically, given an input image, the model\nmust first classify the main visual events (verb classification), then identify\nthe participating entities and their semantic roles (semantic role labeling),\nand finally localize these entities in the image (semantic role localization).\nExisting methods treat verb classification as a single-label problem, but we\nshow through a comprehensive analysis that this formulation fails to address\nthe inherent ambiguity in visual event recognition, as multiple verb categories\nmay reasonably describe the same image. This paper makes three key\ncontributions: First, we reveal through empirical analysis that verb\nclassification is inherently a multi-label problem due to the ubiquitous\nsemantic overlap between verb categories. Second, given the impracticality of\nfully annotating large-scale datasets with multiple labels, we propose to\nreformulate verb classification as a single positive multi-label learning\n(SPMLL) problem - a novel perspective in SR research. Third, we design a\ncomprehensive multi-label evaluation benchmark for SR that is carefully\ndesigned to fairly evaluate model performance in a multi-label setting. To\naddress the challenges of SPMLL, we futher develop the Graph Enhanced Verb\nMultilayer Perceptron (GE-VerbMLP), which combines graph neural networks to\ncapture label correlations and adversarial training to optimize decision\nboundaries. Extensive experiments on real-world datasets show that our approach\nachieves more than 3\\% MAP improvement while remaining competitive on\ntraditional top-1 and top-5 accuracy metrics.\n\nüì∞ *Source:* Tech News AI | üè∑Ô∏è *Category:* technology\n<https://www.irishtimes.com/environment/2025/09/01/predicting-the-next-flood-its-a-very-hard-thing-to-be-scared-in-your-own-home/|Read more>'}}, {'type': 'divider'}, {'type': 'section', 'text': {'type': 'mrkdwn', 'text': "*8. How one AI startup is helping rice farmers battle climate change*\nüì∞ *Achieving Hilbert-Schmidt Independence Under R√©nyi Differential Privacy for Fair and Private Data Generation*\n\nAs privacy regulations such as the GDPR and HIPAA and responsibility\nframeworks for artificial intelligence such as the AI Act gain traction, the\nethical and responsible use of real-world data faces increasing constraints.\nSynthetic data generation has emerged as a promising solution to risk-aware\ndata sharing and model development, particularly for tabular datasets that are\nfoundational to sensitive domains such as healthcare. To address both privacy\nand fairness concerns in this setting, we propose FLIP (Fair Latent\nIntervention under Privacy guarantees), a transformer-based variational\nautoencoder augmented with latent diffusion to generate heterogeneous tabular\ndata. Unlike the typical setup in fairness-aware data generation, we assume a\ntask-agnostic setup, not reliant on a fixed, defined downstream task, thus\noffering broader applicability. To ensure privacy, FLIP employs R\\'enyi\ndifferential privacy (RDP) constraints during training and addresses fairness\nin the input space with RDP-compatible balanced sampling that accounts for\ngroup-specific noise levels across multiple sampling rates. In the latent\nspace, we promote fairness by aligning neuron activation patterns across\nprotected groups using Centered Kernel Alignment (CKA), a similarity measure\nextending the Hilbert-Schmidt Independence Criterion (HSIC). This alignment\nencourages statistical independence between latent representations and the\nprotected feature. Empirical results demonstrate that FLIP effectively provides\nsignificant fairness improvements for task-agnostic fairness and across diverse\ndownstream tasks under differential privacy constraints.\n\nüì∞ *Source:* TechCrunch AI | üè∑Ô∏è *Category:* AI/ML Technology\n<https://techcrunch.com/2025/08/26/how-one-ai-startup-is-helping-rice-farmers-battle-climate-change/|Read more>"}}, {'type': 'divider'}, {'type': 'section', 'text': {'type': 'mrkdwn', 'text': '*9. Harvard dropouts to launch ‚Äòalways on‚Äô AI smart glasses that listen and record every conversation*\nLiverpool pays ‚Ç¨150m for star striker Alexander Isak in a transfer with Newcastle United.\n\nüì∞ *Source:* TechCrunch AI | üè∑Ô∏è *Category:* AI/ML Technology\n<https://techcrunch.com/2025/08/20/harvard-dropouts-to-launch-always-on-ai-smart-glasses-that-listen-and-record-every-conversation/|Read more>'}}, {'type': 'divider'}, {'type': 'section', 'text': {'type': 'mrkdwn', 'text': '*10. Meta to add 100MW of solar power from US gear*\nRayo Vallecano faces pitch issues before match against FC Barcelona. Sergio Ramos shares his musical side.\n\nüì∞ *Source:* TechCrunch AI | üè∑Ô∏è *Category:* AI/ML Technology\n<https://techcrunch.com/2025/08/20/meta-to-add-100-mw-of-solar-power-from-u-s-gear/|Read more>'}}, {'type': 'context', 'elements': [{'type': 'mrkdwn', 'text': 'üìä *10* articles summarized ‚Ä¢ Generated at 10:41:18'}]}]}, headers: {'Content-Type': 'application/json;charset=utf-8', 'Authorization': '(redacted)', 'User-Agent': 'Bolt/1.23.0 Python/3.11.13 slackclient/3.36.0 Linux/6.8.0-65-generic'}
2025-09-02 10:41:19,842 - slack_bolt.App - DEBUG - Received the following response - status: 200, headers: {'date': 'Tue, 02 Sep 2025 05:11:19 GMT', 'server': 'Apache', 'vary': 'Accept-Encoding', 'x-slack-req-id': '2cc0b6055bb306f7c0fb59a37d17a263', 'x-content-type-options': 'nosniff', 'x-xss-protection': '0', 'pragma': 'no-cache', 'cache-control': 'private, no-cache, no-store, must-revalidate', 'expires': 'Sat, 26 Jul 1997 05:00:00 GMT', 'content-type': 'application/json; charset=utf-8', 'x-accepted-oauth-scopes': 'chat:write', 'x-oauth-scopes': 'chat:write,files:write', 'access-control-expose-headers': 'x-slack-req-id, retry-after', 'access-control-allow-headers': 'slack-route, x-slack-version-ts, x-b3-traceid, x-b3-spanid, x-b3-parentspanid, x-b3-sampled, x-b3-flags', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'referrer-policy': 'no-referrer', 'x-slack-unique-id': 'aLZ8d0hvMoBYAE0szcrylwAAADQ', 'x-slack-backend': 'r', 'access-control-allow-origin': '*', 'content-length': '9960', 'via': '1.1 slack-prod.tinyspeck.com, envoy-www-iad-jcwtctki,envoy-edge-bom-cpbluuxp', 'x-envoy-attempt-count': '1', 'x-envoy-upstream-service-time': '343', 'x-backend': 'main_normal main_canary_with_overflow main_control_with_overflow', 'x-server': 'slack-www-hhvm-main-iad-cxme', 'x-slack-shared-secret-outcome': 'no-match', 'x-edge-backend': 'envoy-www', 'timing-allow-origin': '*', 'x-slack-edge-shared-secret-outcome': 'no-match', 'connection': 'close'}, body: {"ok":true,"channel":"C09AUAZCQR1","ts":"1756789879.689599","message":{"user":"U09BG266092","type":"message","ts":"1756789879.689599","bot_id":"B09BG26606Q","app_id":"A09BBRCFEV8","text":":rocket: AI\/ML News TLDR - 10 articles summarized","team":"T4LJBDMDY","bot_profile":{"id":"B09BG26606Q","app_id":"A09BBRCFEV8","user_id":"U09BG266092","name":"Briefly","icons":{"image_36":"https:\/\/avatars.slack-edge.com\/2025-08-21\/9399655186801_62917fdb062b1fa75b31_36.png","image_48":"https:\/\/avatars.slack-edge.com\/2025-08-21\/9399655186801_62917fdb062b1fa75b31_48.png","image_72":"https:\/\/avatars.slack-edge.com\/2025-08-21\/9399655186801_62917fdb062b1fa75b31_72.png"},"deleted":false,"updated":1755759762,"team_id":"T4LJBDMDY"},"blocks":[{"type":"header","block_id":"\/oacN","text":{"type":"plain_text","text":":rocket: AI\/ML News TLDR - Daily Digest","emoji":true}},{"type":"section","block_id":"9xbyf","text":{"type":"mrkdwn","text":"*Today's AI\/ML News Summary*\nCollected 10 articles and created TLDR summaries.","verbatim":false}},{"type":"divider","block_id":"jUbKH"},{"type":"section","block_id":"l6FKa","text":{"type":"mrkdwn","text":"*1. The Demon is in Ambiguity: Revisiting Situation Recognition with Single Positive Multi-Label Learning*\nMidleton town in Cork county experienced a rare flooding event, affecting 682 properties. Residents faced significant damage and challenges due to the flood.\n\n:newspaper: *Source:* ArXiv AI Papers | :label: *Category:* Research Papers\n<http:\/\/arxiv.org\/abs\/2508.21816v1|Read more>","verbatim":false}},{"type":"divider","block_id":"M2hPF"},{"type":"section","block_id":"Zq4iP","text":{"type":"mrkdwn","text":"*2. Achieving Hilbert-Schmidt Independence Under R\u00e9nyi Differential Privacy for Fair and Private Data Generation*\nMitti Labs collaborates with The Nature Conservancy to promote climate-friendly rice farming in India using AI to monitor methane emissions.\n\n:newspaper: *Source:* ArXiv AI Papers | :label: *Category:* Research Papers\n<http:\/\/arxiv.org\/abs\/2508.21815v1|Read more>","verbatim":false}},{"type":"divider","block_id":"BFUnC"},{"type":"section","block_id":"qzvAm","text":{"type":"mrkdwn","text":"*3. QR-LoRA: QR-Based Low-Rank Adaptation for Efficient Fine-Tuning of Large Language Models*\nFormer Harvard students are launching smart glasses with an always-on microphone after controversial projects. The glasses record every conversation.\n\n:newspaper: *Source:* ArXiv AI Papers | :label: *Category:* Research Papers\n<http:\/\/arxiv.org\/abs\/2508.21810v1|Read more>","verbatim":false}},{"type":"divider","block_id":"3dapj"},{"type":"section","block_id":"tSBtY","text":{"type":"mrkdwn","text":"*4. Epsilon-saturation for stable graphs and Littlestone classes*\nMeta plans to install 100MW of solar power from US sources for a new AI data center in South Carolina.\n\n:newspaper: *Source:* ArXiv AI Papers | :label: *Category:* Research Papers\n<http:\/\/arxiv.org\/abs\/2508.21807v1|Read more>","verbatim":false}},{"type":"divider","block_id":"vD+JX"},{"type":"section","block_id":"vBN9T","text":{"type":"mrkdwn","text":"*5.  Reports: Transfer saga over, Liverpool pay \u20ac150m for star striker*\nQR-LoRA introduces a parameter-efficient fine-tuning technique for Large Language Models by using QR decomposition with column pivoting to reduce trainable parameters. It outperforms standard LoRA and SVD-LoRA with significantly fewer parameters.\n\n:newspaper: *Source:* Tech News AI | :label: *Category:* technology\n<https:\/\/onefootball.com\/en\/news\/reports-transfer-saga-over-liverpool-pay-150m-for-star-striker-41597779|Read more>","verbatim":false}},{"type":"divider","block_id":"iIpHk"},{"type":"section","block_id":"G1mXr","text":{"type":"mrkdwn","text":"*6. :coffee: Vallecano pitch woes , Sergio Ramos in tune *\nIntroduction and study of epsilon-saturation for Littlestone classes\/stable graphs, showing closure under adding virtual elements, impacting Littlestone dimension and VC dimension.\n\n:newspaper: *Source:* Tech News AI | :label: *Category:* technology\n<https:\/\/onefootball.com\/en\/news\/vallecano-pitch-woes-sergio-ramos-in-tune-41597756|Read more>","verbatim":false}},{"type":"divider","block_id":"TBg7K"},{"type":"section","block_id":"XC5a6","text":{"type":"mrkdwn","text":"*7. Predicting the next flood: \u2018It\u2019s a very hard thing to be scared in your own home\u2019*\n:newspaper: *The Demon is in Ambiguity: Revisiting Situation Recognition with Single Positive Multi-Label Learning*\n\nContext recognition (SR) is a fundamental task in computer vision that aims\nto extract structured semantic summaries from images by identifying key events\nand their associated entities. Specifically, given an input image, the model\nmust first classify the main visual events (verb classification), then identify\nthe participating entities and their semantic roles (semantic role labeling),\nand finally localize these entities in the image (semantic role localization).\nExisting methods treat verb classification as a single-label problem, but we\nshow through a comprehensive analysis that this formulation fails to address\nthe inherent ambiguity in visual event recognition, as multiple verb categories\nmay reasonably describe the same image. This paper makes three key\ncontributions: First, we reveal through empirical analysis that verb\nclassification is inherently a multi-label problem due to the ubiquitous\nsemantic overlap between verb categories. Second, given the impracticality of\nfully annotating large-scale datasets with multiple labels, we propose to\nreformulate verb classification as a single positive multi-label learning\n(SPMLL) problem - a novel perspective in SR research. Third, we design a\ncomprehensive multi-label evaluation benchmark for SR that is carefully\ndesigned to fairly evaluate model performance in a multi-label setting. To\naddress the challenges of SPMLL, we futher develop the Graph Enhanced Verb\nMultilayer Perceptron (GE-VerbMLP), which combines graph neural networks to\ncapture label correlations and adversarial training to optimize decision\nboundaries. Extensive experiments on real-world datasets show that our approach\nachieves more than 3\\% MAP improvement while remaining competitive on\ntraditional top-1 and top-5 accuracy metrics.\n\n:newspaper: *Source:* Tech News AI | :label: *Category:* technology\n<https:\/\/www.irishtimes.com\/environment\/2025\/09\/01\/predicting-the-next-flood-its-a-very-hard-thing-to-be-scared-in-your-own-home\/|Read more>","verbatim":false}},{"type":"divider","block_id":"Ra2o4"},{"type":"section","block_id":"TjHe3","text":{"type":"mrkdwn","text":"*8. How one AI startup is helping rice farmers battle climate change*\n:newspaper: *Achieving Hilbert-Schmidt Independence Under R\u00e9nyi Differential Privacy for Fair and Private Data Generation*\n\nAs privacy regulations such as the GDPR and HIPAA and responsibility\nframeworks for artificial intelligence such as the AI Act gain traction, the\nethical and responsible use of real-world data faces increasing constraints.\nSynthetic data generation has emerged as a promising solution to risk-aware\ndata sharing and model development, particularly for tabular datasets that are\nfoundational to sensitive domains such as healthcare. To address both privacy\nand fairness concerns in this setting, we propose FLIP (Fair Latent\nIntervention under Privacy guarantees), a transformer-based variational\nautoencoder augmented with latent diffusion to generate heterogeneous tabular\ndata. Unlike the typical setup in fairness-aware data generation, we assume a\ntask-agnostic setup, not reliant on a fixed, defined downstream task, thus\noffering broader applicability. To ensure privacy, FLIP employs R\\'enyi\ndifferential privacy (RDP) constraints during training and addresses fairness\nin the input space with RDP-compatible balanced sampling that accounts for\ngroup-specific noise levels across multiple sampling rates. In the latent\nspace, we promote fairness by aligning neuron activation patterns across\nprotected groups using Centered Kernel Alignment (CKA), a similarity measure\nextending the Hilbert-Schmidt Independence Criterion (HSIC). This alignment\nencourages statistical independence between latent representations and the\nprotected feature. Empirical results demonstrate that FLIP effectively provides\nsignificant fairness improvements for task-agnostic fairness and across diverse\ndownstream tasks under differential privacy constraints.\n\n:newspaper: *Source:* TechCrunch AI | :label: *Category:* AI\/ML Technology\n<https:\/\/techcrunch.com\/2025\/08\/26\/how-one-ai-startup-is-helping-rice-farmers-battle-climate-change\/|Read more>","verbatim":false}},{"type":"divider","block_id":"f4tQU"},{"type":"section","block_id":"qkDPc","text":{"type":"mrkdwn","text":"*9. Harvard dropouts to launch \u2018always on\u2019 AI smart glasses that listen and record every conversation*\nLiverpool pays \u20ac150m for star striker Alexander Isak in a transfer with Newcastle United.\n\n:newspaper: *Source:* TechCrunch AI | :label: *Category:* AI\/ML Technology\n<https:\/\/techcrunch.com\/2025\/08\/20\/harvard-dropouts-to-launch-always-on-ai-smart-glasses-that-listen-and-record-every-conversation\/|Read more>","verbatim":false}},{"type":"divider","block_id":"LdMCq"},{"type":"section","block_id":"kFQ+A","text":{"type":"mrkdwn","text":"*10. Meta to add 100MW of solar power from US gear*\nRayo Vallecano faces pitch issues before match against FC Barcelona. Sergio Ramos shares his musical side.\n\n:newspaper: *Source:* TechCrunch AI | :label: *Category:* AI\/ML Technology\n<https:\/\/techcrunch.com\/2025\/08\/20\/meta-to-add-100-mw-of-solar-power-from-u-s-gear\/|Read more>","verbatim":false}},{"type":"context","block_id":"zNVR+","elements":[{"type":"mrkdwn","text":":bar_chart: *10* articles summarized \u2022 Generated at 10:41:18","verbatim":false}]}]}}
2025-09-02 10:41:19,843 - slackbot.slack.publisher - INFO - TLDR message published to #news-finder
2025-09-02 10:41:19,843 - slackbot.services.publisher_service - INFO - ‚úÖ Message published successfully to slack
2025-09-02 10:41:19,843 - __main__ - INFO - üéâ Successfully published to Slack!
2025-09-02 10:41:19,843 - __main__ - INFO - üì∫ Channel: C09AUAZCQR1
2025-09-02 10:41:19,843 - __main__ - INFO - üÜî Message ID: None
2025-09-02 10:41:19,844 - __main__ - INFO - 
üéâ Briefly Bot completed successfully!
2025-09-02 10:41:19,844 - __main__ - INFO - üìä Summary:
2025-09-02 10:41:19,844 - __main__ - INFO -   ‚Ä¢ Articles collected: 10
2025-09-02 10:41:19,844 - __main__ - INFO -   ‚Ä¢ TLDR summaries created: 10
2025-09-02 10:41:19,844 - __main__ - INFO -   ‚Ä¢ Published to Slack: C09AUAZCQR1
2025-09-02 10:41:19,847 - __main__ - INFO - ‚úÖ Briefly Bot completed successfully
2025-09-02 10:41:19,969 - httpcore.connection - DEBUG - close.started
2025-09-02 10:41:19,970 - httpcore.connection - DEBUG - close.complete
